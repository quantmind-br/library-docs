---
title: Vidu Q1
url: https://docs.z.ai/guides/video/vidu-q1.md
source: llms
fetched_at: 2026-01-24T11:23:25.777522282-03:00
rendered_js: false
word_count: 309
summary: This document introduces the Vidu Q1 video generation model, outlining its technical specifications, multi-modal generation capabilities, and practical applications in industries like film and advertising.
tags:
    - vidu-q1
    - video-generation
    - text-to-video
    - image-to-video
    - ai-model
    - computer-vision
    - api-integration
category: guide
---

> ## Documentation Index
> Fetch the complete documentation index at: https://docs.z.ai/llms.txt
> Use this file to discover all available pages before exploring further.

# Vidu Q1

## <Icon icon="rectangle-list" iconType="solid" color="#ffffff" size={36} />   Overview

Vidu Q1 is the next-generation video generation model from Vidu, designed for high-quality video creation. It consistently outputs 5-second, 24-frame, 1080P video clips. Through advanced optimization of visual clarity, Vidu Q1 delivers significantly enhanced image quality with notable improvements in issues such as hand distortion and frame jitter.

The model achieves photorealistic rendering that closely resembles real-world scenes, while maintaining stylistic accuracy in 2D animation. Transitions between the first and last frames are exceptionally smooth, making Vidu Q1 well-suited for demanding creative applications in film, advertising, and animated short productions.

<Tabs>
  <Tab title="viduq1-image">
    <CardGroup cols={2}>
      <Card title="Price" icon="circle-dollar" color="#ffffff">
        \$0.4 / video
      </Card>

      <Card title="Capability" icon="arrow-down-big-small" color="#ffffff">
        Image-to-Video Generation
      </Card>

      <Card title="Duration" icon="timer" color="#ffffff">
        5S
      </Card>

      <Card title="Clarity" icon="tv" color="#ffffff">
        1080P
      </Card>
    </CardGroup>
  </Tab>

  <Tab title="viduq1-start-end">
    <CardGroup cols={2}>
      <Card title="Price" icon="circle-dollar" color="#ffffff">
        \$0.4 / video
      </Card>

      <Card title="Capability" icon="arrow-down-big-small" color="#ffffff">
        Start and End Frame
      </Card>

      <Card title="Duration" icon="timer" color="#ffffff">
        5S
      </Card>

      <Card title="Clarity" icon="tv" color="#ffffff">
        1080P
      </Card>
    </CardGroup>
  </Tab>

  <Tab title="viduq1-text">
    <CardGroup cols={2}>
      <Card title="Price" icon="circle-dollar" color="#ffffff">
        \$0.4 / video
      </Card>

      <Card title="Capability" icon="arrow-down-big-small" color="#ffffff">
        Text-to-Video Generation
      </Card>

      <Card title="Duration" icon="timer" color="#ffffff">
        5S
      </Card>

      <Card title="Clarity" icon="tv" color="#ffffff">
        1080P
      </Card>
    </CardGroup>
  </Tab>
</Tabs>

## <Icon icon="arrow-down-big-smalt" iconType="solid" color="#ffffff" size={36} />   Capability Description

<CardGroup cols={1}>
  <Card title="Image-to-Video Generation" icon="image" color="#ffffff">
    Generate a video by providing a starting frame or both starting and ending frames along with corresponding text descriptions.
  </Card>

  <Card title="Start and End Frame" icon="frame" color="#ffffff">
    Support input of two images: the first uploaded image is treated as the starting frame, and the second as the ending frame. The model uses these images as input parameters to generate the video.
  </Card>

  <Card title="Text-to-Video Generation" icon="text" color="#ffffff">
    Generate a video from a text prompt; currently supports both a general style and an anime style optimized for animation.
  </Card>
</CardGroup>

<Tip>
  The URL link for the video generated by the model is valid for one day. Please save it as soon as possible if needed.
</Tip>

## <Icon icon="list" iconType="solid" color="#ffffff" size={36} />   Usage

<AccordionGroup>
  <Accordion title="Film Generation">
    * By inputting script excerpts, concept art, and other materials, users can generate promotional videos, visual effects shots, and auxiliary film assets
    * Delivers theatrical-level clarity and visual quality with complete frame details
    * Provides professional-grade video transitions with natural scene flow
  </Accordion>

  <Accordion title="Anime Production">
    * Input character designs and storyboard scripts to quickly generate 2D animated sequences and stylized anime shorts
    * Supports styles such as Chinese animation and Japanese anime
    * Enables storyline extension and creative regeneration of classic IPs
  </Accordion>

  <Accordion title="Short Drama Production">
    * Automatically generate short videos or micro-dramas from novel chapters or scripted scenes
    * Covers diverse genres such as romance, mystery, and historical drama
    * Optimized for multi-platform distribution needs
  </Accordion>

  <Accordion title="Advertising & Marketing">
    * Quickly generate highly engaging brand ads, e-commerce product videos, and interactive ads (e.g., virtual try-on) based on product images and feature descriptions
    * Supports adaptation to various platform dimensions and creative formats
  </Accordion>
</AccordionGroup>

## <Icon icon="bars-sort" iconType="solid" color="#ffffff" size={36} />   Resources

[API Documentation](/api-reference/video/cogvideox-3\&vidu): Learn how to call the API.

## <Icon icon="arrow-down-from-line" iconType="solid" color="#ffffff" size={36} />   Introducing ViduQ1

<Steps>
  <Step title="Cinematic-Level Visual Clarity" titleSize="h3">
    The model delivers a comprehensive upgrade in visual detail restoration.

    <video src="https://cdn.bigmodel.cn/static/platform/videos/usage-guide/vidu/q1-1.mp4" controls />
  </Step>

  <Step title="Precise Resolution of Visual Artifacts" stepNumber={2} titleSize="h3">
    Movements are smooth and natural—hand gestures during product demonstrations in e-commerce livestreams are accurately rendered and compliant. Visual jitter is minimized through dynamic frame interpolation technology, ensuring fluid and stable footage even in motion-heavy scenes such as running shots or vehicle perspectives.

    <video src="https://cdn.bigmodel.cn/static/platform/videos/usage-guide/vidu/q1-2.mp4" controls />
  </Step>

  <Step title="Multi-Style Artistic Expression" stepNumber={3} titleSize="h3">
    The realistic style aims for lifelike visuals—urban landscapes and character portraits in city promos are rendered with striking realism. The animated style focuses on authenticity, accurately capturing everything from the hand-drawn lines of Japanese anime to the saturated colors of Western cartoons. By inputting anime character designs, the model generates dynamic story segments that closely match the original IP’s visual style, boosting the efficiency of derivative content creation.

    <Tabs>
      <Tab title="Realistic Style">
        <video src="https://cdn.bigmodel.cn/static/platform/videos/usage-guide/vidu/q1-3.mp4" controls />
      </Tab>

      <Tab title="Animated Style">
        <video src="https://cdn.bigmodel.cn/static/platform/videos/usage-guide/vidu/q1-4.mp4" controls />
      </Tab>
    </Tabs>
  </Step>

  <Step title="Industry-Leading Transition Smoothness" stepNumber={4} titleSize="h3">
    The start and end frame transition technology reaches a new level, using dynamic frame prediction and style fusion algorithms to overcome the limitations of "mechanical stitching" in video transitions.

    <video src="https://cdn.bigmodel.cn/static/platform/videos/usage-guide/vidu/q1-5.mp4" controls />
  </Step>
</Steps>

## <Icon icon="rectangle-code" iconType="solid" color="#ffffff" size={36} />    Quick Start

### 1. Text-to-Video Generation

<Tabs>
  <Tab title="Curl">
    ```json  theme={null}
    curl --location --request POST 'https://api.z.ai/api/paas/v4/videos/generations' \
    --header 'Authorization: Bearer {your apikey}' \
    --header 'Content-Type: application/json' \
    --data-raw '{
        "model": "viduq1-text",
        "style": "anime",
        "prompt": "Peter Rabbit drives a small car along the road, his face filled with joy and happiness.",
        "duration": 5,
        "aspect_ratio": "16:9",
        "size": "1920x1080",
        "movement_amplitude": "auto"
    }'
    ```
  </Tab>

  <Tab title="Python">
    **Install SDK**

    ```bash  theme={null}
    # Install latest version
    pip install zai-sdk

    # Or specify version
    pip install zai-sdk==0.1.0
    ```

    **Verify Installation**

    ```python  theme={null}
    import zai
    print(zai.__version__)
    ```

    ```python  theme={null}
    from zai import ZaiClient

    client = ZaiClient(api_key="your-api-key")
    response = client.videos.generations(
        model="viduq1-text",
        prompt="Peter Rabbit driving a car, wandering on the road, with a happy and joyful expression on his face.",
        style="general",
        duration=5,
        aspect_ratio="16:9",
        size="1920x1080",
        movement_amplitude="auto"
    )

    print(response)
    ```
  </Tab>
</Tabs>

### 2. Image-to-Video Generation

<Tabs>
  <Tab title="Curl">
    ```json  theme={null}
    curl --location --request POST 'https://api.z.ai/api/paas/v4/videos/generations' \
    --header 'Authorization: Bearer {your apikey}' \
    --header 'Content-Type: application/json' \
    --data-raw '{
        "model":"viduq1-image",
        "image_url":"https://example.com/path/to/your/image.jpg",
        "prompt":"Peter Rabbit drives a small car along the road, his face filled with joy and happiness.",
        "duration":5,
        "size":"1920x1080",
        "movement_amplitude":"auto"
    }'
    ```
  </Tab>

  <Tab title="Python">
    **Install SDK**

    ```bash  theme={null}
    # Install latest version
    pip install zai-sdk

    # Or specify version
    pip install zai-sdk==0.1.0
    ```

    **Verify Installation**

    ```python  theme={null}
    import zai
    print(zai.__version__)
    ```

    ```python  theme={null}
    from zai import ZaiClient

    client = ZaiClient(api_key="your-api-key")
    response = client.videos.generations(
        model="viduq1-image",
        image_url="https://example.com/path/to/your/image.jpg",
        prompt="Peter Rabbit driving a car, wandering on the road, with a happy and joyful expression on his face.",
        duration=5,
        size="1920x1080",
        movement_amplitude="auto"
    )

    print(response)
    ```
  </Tab>
</Tabs>

### 3. Start and End Frame

<Tabs>
  <Tab title="Curl">
    ```json  theme={null}
    curl --location --request POST 'https://api.z.ai/api/paas/v4/videos/generations' \
    --header 'Authorization: Bearer {your apikey}' \
    --header 'Content-Type: application/json' \
    --data-raw '{
        "model":"viduq1-start-end",
        "image_url":["https://example.com/path/to/your/image.jpg","https://example.com/path/to/your/image1.jpg"],
        "prompt":"Peter Rabbit drives a small car along the road, his face filled with joy and happiness.",
        "duration":5,
        "size":"1920x1080",
        "movement_amplitude":"auto"
    }'
    ```
  </Tab>

  <Tab title="Python">
    **Install SDK**

    ```bash  theme={null}
    # Install latest version
    pip install zai-sdk

    # Or specify version
    pip install zai-sdk==0.1.0
    ```

    **Verify Installation**

    ```python  theme={null}
    import zai
    print(zai.__version__)
    ```

    ```python  theme={null}
    from zai import ZaiClient

    client = ZaiClient(api_key="your-api-key")
    # Define URLs for first frame and last frame
    sample_first_frame = "https://gd-hbimg.huaban.com/ccee58d77afe8f5e17a572246b1994f7e027657fe9e6-qD66In_fw1200webp"
    sample_last_frame = "https://gd-hbimg.huaban.com/cc2601d568a72d18d90b2cc7f1065b16b2d693f7fa3f7-hDAwNq_fw1200webp"

    # Video generation request (first and last frame mode)
    response = client.videos.generations(
        model="viduq1-start-end",
        image_url=[sample_first_frame, sample_last_frame],  # The first and last frame images
        prompt="Peter Rabbit driving a car, wandering on the road, with a happy and joyful expression on his face.",
        duration=5,  #Video duration (seconds)
        size="1920x1080",  # Video resolution
        movement_amplitude="auto",  # Movement amplitude
    )

    # Print the response result
    print(response)
    ```
  </Tab>
</Tabs>