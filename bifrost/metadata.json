{
  "generated_at": "2026-01-21T19:45:10.209479276-03:00",
  "source_url": "https://docs.getbifrost.ai/llms.txt",
  "strategy": "llms",
  "total_documents": 389,
  "documents": [
    {
      "file_path": "194-api-reference-anthropic-integration-cancel-batch-job-anthropic-format.md",
      "title": "Cancel batch job (Anthropic format)",
      "url": "https://docs.getbifrost.ai/api-reference/anthropic-integration/cancel-batch-job-anthropic-format.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:37:52.477222729-03:00",
      "description": "> Cancels a batch processing job.",
      "summary": "This document provides details for the API endpoint used to cancel an active batch processing job within the Anthropic-compatible integration.",
      "tags": [
        "anthropic",
        "batch-processing",
        "api-endpoint",
        "job-cancellation",
        "message-batches"
      ],
      "category": "api",
      "original_file_path": "api-reference-anthropic-integration-cancel-batch-job-anthropic-format.md"
    },
    {
      "file_path": "193-api-reference-anthropic-integration-create-batch-job-anthropic-format.md",
      "title": "Create batch job (Anthropic format)",
      "url": "https://docs.getbifrost.ai/api-reference/anthropic-integration/create-batch-job-anthropic-format.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:37:52.489615092-03:00",
      "description": "> Creates a batch processing job using Anthropic format. Use x-model-provider header to specify the provider.",
      "summary": "This document provides the API specification for creating batch processing jobs using the Anthropic-compatible message format via the Bifrost gateway.",
      "tags": [
        "anthropic-integration",
        "batch-processing",
        "api-gateway",
        "ai-inference",
        "message-batches"
      ],
      "category": "api",
      "original_file_path": "api-reference-anthropic-integration-create-batch-job-anthropic-format.md"
    },
    {
      "file_path": "198-api-reference-anthropic-integration-count-tokens-anthropic-format.md",
      "title": "Count tokens (Anthropic format)",
      "url": "https://docs.getbifrost.ai/api-reference/anthropic-integration/count-tokens-anthropic-format.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:37:52.563294972-03:00",
      "description": "> Counts the number of tokens in a message request.",
      "summary": "This document specifies the API endpoint for calculating the number of tokens in a message request using the Anthropic-compatible format.",
      "tags": [
        "anthropic",
        "token-counting",
        "api-integration",
        "bifrost-gateway",
        "llm-utilities"
      ],
      "category": "api",
      "original_file_path": "api-reference-anthropic-integration-count-tokens-anthropic-format.md"
    },
    {
      "file_path": "197-api-reference-anthropic-integration-create-completion-anthropic-legacy-format.md",
      "title": "Create completion (Anthropic legacy format)",
      "url": "https://docs.getbifrost.ai/api-reference/anthropic-integration/create-completion-anthropic-legacy-format.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:37:52.474073-03:00",
      "description": "> Creates a text completion using Anthropic's legacy Complete API. Supports streaming via SSE.",
      "summary": "This document defines the API endpoint for creating text completions using the legacy Anthropic format via the Bifrost gateway, including support for streaming and fallback models.",
      "tags": [
        "anthropic-api",
        "text-completion",
        "api-gateway",
        "legacy-format",
        "streaming-sse",
        "inference-api"
      ],
      "category": "api",
      "original_file_path": "api-reference-anthropic-integration-create-completion-anthropic-legacy-format.md"
    },
    {
      "file_path": "202-api-reference-anthropic-integration-create-message-anthropic-format.md",
      "title": "Create message (Anthropic format)",
      "url": "https://docs.getbifrost.ai/api-reference/anthropic-integration/create-message-anthropic-format.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:37:52.483652313-03:00",
      "description": "> Creates a message using Anthropic Messages API format. Supports streaming via SSE.",
      "summary": "This document defines the Bifrost API endpoint for creating messages using the Anthropic Messages API format, including support for streaming via Server-Sent Events (SSE). It details the request schema for model parameters, message structures, and various content types like text, images, and tool usage.",
      "tags": [
        "anthropic-api",
        "message-creation",
        "ai-inference",
        "streaming-sse",
        "api-integration",
        "bifrost-gateway"
      ],
      "category": "api",
      "original_file_path": "api-reference-anthropic-integration-create-message-anthropic-format.md"
    },
    {
      "file_path": "200-api-reference-anthropic-integration-get-file-content-anthropic-format.md",
      "title": "Get file content (Anthropic format)",
      "url": "https://docs.getbifrost.ai/api-reference/anthropic-integration/get-file-content-anthropic-format.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:37:58.137639663-03:00",
      "description": "> Retrieves file content. Returns raw binary file data when Accept header is set to application/octet-stream, or file metadata as JSON when Accept header is set to application/json.",
      "summary": "This document defines the API endpoint for retrieving file content or metadata using the Anthropic-compatible format, supporting both raw binary data and JSON responses.",
      "tags": [
        "anthropic-integration",
        "file-management",
        "api-endpoint",
        "bifrost-gateway",
        "binary-download"
      ],
      "category": "api",
      "original_file_path": "api-reference-anthropic-integration-get-file-content-anthropic-format.md"
    },
    {
      "file_path": "199-api-reference-anthropic-integration-delete-file-anthropic-format.md",
      "title": "Delete file (Anthropic format)",
      "url": "https://docs.getbifrost.ai/api-reference/anthropic-integration/delete-file-anthropic-format.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:37:57.632694889-03:00",
      "description": "> Deletes an uploaded file.",
      "summary": "This document provides the OpenAPI specification and endpoint details for deleting an uploaded file through the Bifrost gateway using the Anthropic-compatible format.",
      "tags": [
        "anthropic-integration",
        "file-management",
        "api-endpoint",
        "bifrost-gateway",
        "delete-file",
        "openapi-spec"
      ],
      "category": "api",
      "original_file_path": "api-reference-anthropic-integration-delete-file-anthropic-format.md"
    },
    {
      "file_path": "195-api-reference-anthropic-integration-list-batch-jobs-anthropic-format.md",
      "title": "List batch jobs (Anthropic format)",
      "url": "https://docs.getbifrost.ai/api-reference/anthropic-integration/list-batch-jobs-anthropic-format.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:37:58.304107424-03:00",
      "description": "> Lists batch processing jobs.",
      "summary": "This document specifies the API endpoint for retrieving a paginated list of batch processing jobs using the Anthropic-compatible format within the Bifrost gateway.",
      "tags": [
        "anthropic-api",
        "batch-processing",
        "message-batches",
        "api-reference",
        "pagination"
      ],
      "category": "api",
      "original_file_path": "api-reference-anthropic-integration-list-batch-jobs-anthropic-format.md"
    },
    {
      "file_path": "201-api-reference-anthropic-integration-list-files-anthropic-format.md",
      "title": "List files (Anthropic format)",
      "url": "https://docs.getbifrost.ai/api-reference/anthropic-integration/list-files-anthropic-format.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:37:58.639004353-03:00",
      "description": "> Lists uploaded files.",
      "summary": "This document provides the API specification for listing uploaded files using the Anthropic-compatible format within the Bifrost gateway.",
      "tags": [
        "anthropic-integration",
        "file-management",
        "list-files",
        "bifrost-api",
        "rest-api"
      ],
      "category": "api",
      "original_file_path": "api-reference-anthropic-integration-list-files-anthropic-format.md"
    },
    {
      "file_path": "196-api-reference-anthropic-integration-get-batch-results-anthropic-format.md",
      "title": "Get batch results (Anthropic format)",
      "url": "https://docs.getbifrost.ai/api-reference/anthropic-integration/get-batch-results-anthropic-format.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:37:57.792958944-03:00",
      "description": "> Retrieves results of a completed batch job.",
      "summary": "This document specifies the API endpoint for retrieving results from a completed batch job using the Anthropic-compatible format within the Bifrost gateway. It outlines the path parameters, request headers, and the resulting JSONL stream response format.",
      "tags": [
        "anthropic-integration",
        "batch-processing",
        "api-reference",
        "bifrost-gateway",
        "inference-api",
        "jsonl-results"
      ],
      "category": "api",
      "original_file_path": "api-reference-anthropic-integration-get-batch-results-anthropic-format.md"
    },
    {
      "file_path": "203-api-reference-anthropic-integration-list-models-anthropic-format.md",
      "title": "List models (Anthropic format)",
      "url": "https://docs.getbifrost.ai/api-reference/anthropic-integration/list-models-anthropic-format.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:38:02.659703572-03:00",
      "description": "> Lists available models in Anthropic format.",
      "summary": "This document specifies the API endpoint for retrieving a list of available AI models using the Anthropic-compatible format through the Bifrost gateway.",
      "tags": [
        "anthropic-integration",
        "model-listing",
        "api-specification",
        "bifrost-gateway",
        "ai-models"
      ],
      "category": "api",
      "original_file_path": "api-reference-anthropic-integration-list-models-anthropic-format.md"
    },
    {
      "file_path": "192-api-reference-anthropic-integration-retrieve-batch-job-anthropic-format.md",
      "title": "Retrieve batch job (Anthropic format)",
      "url": "https://docs.getbifrost.ai/api-reference/anthropic-integration/retrieve-batch-job-anthropic-format.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:38:03.040500299-03:00",
      "description": "> Retrieves details of a batch processing job.",
      "summary": "This document provides the API specification for retrieving the status and details of a batch processing job using the Anthropic-compatible format within the Bifrost gateway.",
      "tags": [
        "anthropic-integration",
        "batch-processing",
        "api-reference",
        "inference-gateway",
        "message-batches"
      ],
      "category": "api",
      "original_file_path": "api-reference-anthropic-integration-retrieve-batch-job-anthropic-format.md"
    },
    {
      "file_path": "204-api-reference-anthropic-integration-upload-file-anthropic-format.md",
      "title": "Upload file (Anthropic format)",
      "url": "https://docs.getbifrost.ai/api-reference/anthropic-integration/upload-file-anthropic-format.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:38:03.425395823-03:00",
      "description": "> Uploads a file. Use x-model-provider header to specify the provider.",
      "summary": "This document defines the API endpoint for uploading files using the Anthropic-compatible format through the Bifrost gateway. It specifies the required multipart/form-data parameters, headers, and expected response schema for file management.",
      "tags": [
        "anthropic-integration",
        "file-upload",
        "api-endpoint",
        "bifrost-gateway",
        "multipart-form-data"
      ],
      "category": "api",
      "original_file_path": "api-reference-anthropic-integration-upload-file-anthropic-format.md"
    },
    {
      "file_path": "121-api-reference-audio-create-transcription.md",
      "title": "Create transcription",
      "url": "https://docs.getbifrost.ai/api-reference/audio/create-transcription.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:38:04.207234661-03:00",
      "description": "> Transcribes audio into text in the input language.",
      "summary": "This document specifies the API endpoint for transcribing audio files into text using multiple AI providers through a unified interface.",
      "tags": [
        "audio-transcription",
        "speech-to-text",
        "ai-inference",
        "bifrost-api",
        "rest-api"
      ],
      "category": "api",
      "original_file_path": "api-reference-audio-create-transcription.md"
    },
    {
      "file_path": "120-api-reference-audio-create-speech.md",
      "title": "Create speech",
      "url": "https://docs.getbifrost.ai/api-reference/audio/create-speech.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:38:04.150886844-03:00",
      "description": "> Generates audio from the input text. Returns audio data or streams via SSE.",
      "summary": "This document defines the API endpoint for converting text into speech using various AI models through a unified gateway interface.",
      "tags": [
        "text-to-speech",
        "audio-generation",
        "speech-synthesis",
        "bifrost-api",
        "unified-inference"
      ],
      "category": "api",
      "original_file_path": "api-reference-audio-create-speech.md"
    },
    {
      "file_path": "124-api-reference-batch-cancel-a-batch-job.md",
      "title": "Cancel a batch job",
      "url": "https://docs.getbifrost.ai/api-reference/batch/cancel-a-batch-job.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:38:08.66288402-03:00",
      "description": "> Cancels a batch job.",
      "summary": "This document specifies the API endpoint and parameters required to cancel an ongoing batch job within the Bifrost gateway.",
      "tags": [
        "bifrost-api",
        "batch-processing",
        "job-cancellation",
        "ai-gateway",
        "api-reference",
        "batch-management"
      ],
      "category": "api",
      "original_file_path": "api-reference-batch-cancel-a-batch-job.md"
    },
    {
      "file_path": "123-api-reference-batch-create-a-batch-job.md",
      "title": "Create a batch job",
      "url": "https://docs.getbifrost.ai/api-reference/batch/create-a-batch-job.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:38:08.915874778-03:00",
      "description": "> Creates a batch job for asynchronous processing.",
      "summary": "This document provides the technical specification for the Bifrost API endpoint used to create batch jobs for asynchronous AI model inference. It outlines the request parameters, supported models, and response formats for handling large-scale processing tasks.",
      "tags": [
        "batch-processing",
        "asynchronous-inference",
        "api-reference",
        "ai-models",
        "bifrost-api",
        "openapi-specification"
      ],
      "category": "api",
      "original_file_path": "api-reference-batch-create-a-batch-job.md"
    },
    {
      "file_path": "126-api-reference-batch-get-batch-results.md",
      "title": "Get batch results",
      "url": "https://docs.getbifrost.ai/api-reference/batch/get-batch-results.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:38:10.07531243-03:00",
      "description": "> Retrieves results from a completed batch job.",
      "summary": "This document provides the API specification for retrieving results from a completed batch processing job across various AI providers using the Bifrost gateway.",
      "tags": [
        "batch-processing",
        "api-endpoint",
        "ai-inference",
        "batch-results"
      ],
      "category": "api",
      "original_file_path": "api-reference-batch-get-batch-results.md"
    },
    {
      "file_path": "122-api-reference-batch-retrieve-a-batch-job.md",
      "title": "Retrieve a batch job",
      "url": "https://docs.getbifrost.ai/api-reference/batch/retrieve-a-batch-job.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:38:10.937779153-03:00",
      "description": "> Retrieves a specific batch job by ID.",
      "summary": "This document defines the API endpoint for retrieving the status and detailed information of a specific batch job using its unique identifier and provider name.",
      "tags": [
        "batch-processing",
        "api-endpoint",
        "job-retrieval",
        "ai-gateway",
        "bifrost"
      ],
      "category": "api",
      "original_file_path": "api-reference-batch-retrieve-a-batch-job.md"
    },
    {
      "file_path": "125-api-reference-batch-list-batch-jobs.md",
      "title": "List batch jobs",
      "url": "https://docs.getbifrost.ai/api-reference/batch/list-batch-jobs.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:38:10.504396769-03:00",
      "description": "> Lists batch jobs for a provider.",
      "summary": "This document specifies the API endpoint for listing batch jobs from various AI providers through the Bifrost gateway.",
      "tags": [
        "batch-processing",
        "ai-inference",
        "api-reference",
        "bifrost-gateway",
        "multi-provider"
      ],
      "category": "api",
      "original_file_path": "api-reference-batch-list-batch-jobs.md"
    },
    {
      "file_path": "233-api-reference-bedrock-integration-cancel-batch-inference-job-bedrock-format.md",
      "title": "Cancel batch inference job (Bedrock format)",
      "url": "https://docs.getbifrost.ai/api-reference/bedrock-integration/cancel-batch-inference-job-bedrock-format.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:38:14.751349455-03:00",
      "description": "> Cancels a batch inference job using AWS Bedrock format.",
      "summary": "This document specifies the API endpoint for cancelling an active batch inference job using the AWS Bedrock-compatible format within the Bifrost gateway.",
      "tags": [
        "bedrock-integration",
        "batch-inference",
        "job-management",
        "api-endpoint",
        "bifrost-ai"
      ],
      "category": "api",
      "original_file_path": "api-reference-bedrock-integration-cancel-batch-inference-job-bedrock-format.md"
    },
    {
      "file_path": "232-api-reference-bedrock-integration-create-batch-inference-job-bedrock-format.md",
      "title": "Create batch inference job (Bedrock format)",
      "url": "https://docs.getbifrost.ai/api-reference/bedrock-integration/create-batch-inference-job-bedrock-format.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:38:15.553008907-03:00",
      "description": "> Creates a batch inference job using AWS Bedrock format.",
      "summary": "This document defines the API specification for creating batch inference jobs using the AWS Bedrock format within the Bifrost gateway, detailing request parameters and response schemas.",
      "tags": [
        "aws-bedrock",
        "batch-inference",
        "api-endpoint",
        "model-invocation",
        "bifrost-api"
      ],
      "category": "api",
      "original_file_path": "api-reference-bedrock-integration-create-batch-inference-job-bedrock-format.md"
    },
    {
      "file_path": "236-api-reference-bedrock-integration-invoke-model-bedrock-format.md",
      "title": "Invoke model (Bedrock format)",
      "url": "https://docs.getbifrost.ai/api-reference/bedrock-integration/invoke-model-bedrock-format.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:38:15.598282179-03:00",
      "description": "> Invokes a model using AWS Bedrock InvokeModel API format. Accepts raw model-specific request body.",
      "summary": "This document describes the Bifrost API endpoint for invoking AI models using the AWS Bedrock InvokeModel format, allowing for raw model-specific request bodies.",
      "tags": [
        "aws-bedrock",
        "model-inference",
        "api-reference",
        "llm-gateway",
        "rest-api"
      ],
      "category": "api",
      "original_file_path": "api-reference-bedrock-integration-invoke-model-bedrock-format.md"
    },
    {
      "file_path": "237-api-reference-bedrock-integration-invoke-model-with-streaming-bedrock-format.md",
      "title": "Invoke model with streaming (Bedrock format)",
      "url": "https://docs.getbifrost.ai/api-reference/bedrock-integration/invoke-model-with-streaming-bedrock-format.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:38:15.861156526-03:00",
      "description": "> Invokes a model with streaming using AWS Bedrock InvokeModelWithResponseStream API format.",
      "summary": "This document defines the API endpoint for invoking AI models with streaming responses using the AWS Bedrock InvokeModelWithResponseStream format. It details the request body parameters for various model providers and the event stream response structure.",
      "tags": [
        "bedrock-integration",
        "streaming-api",
        "ai-inference",
        "openapi-spec",
        "aws-bedrock",
        "model-invocation"
      ],
      "category": "api",
      "original_file_path": "api-reference-bedrock-integration-invoke-model-with-streaming-bedrock-format.md"
    },
    {
      "file_path": "235-api-reference-bedrock-integration-converse-with-model-bedrock-format.md",
      "title": "Converse with model (Bedrock format)",
      "url": "https://docs.getbifrost.ai/api-reference/bedrock-integration/converse-with-model-bedrock-format.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:38:15.415913938-03:00",
      "description": "> Sends messages to a model using AWS Bedrock Converse API format.",
      "summary": "This document defines the API specification for interacting with AI models through the Bifrost gateway using the AWS Bedrock Converse format.",
      "tags": [
        "bedrock-integration",
        "aws-bedrock",
        "converse-api",
        "ai-inference",
        "bifrost-api",
        "api-endpoint"
      ],
      "category": "api",
      "original_file_path": "api-reference-bedrock-integration-converse-with-model-bedrock-format.md"
    },
    {
      "file_path": "234-api-reference-bedrock-integration-list-batch-inference-jobs-bedrock-format.md",
      "title": "List batch inference jobs (Bedrock format)",
      "url": "https://docs.getbifrost.ai/api-reference/bedrock-integration/list-batch-inference-jobs-bedrock-format.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:38:18.695020476-03:00",
      "description": "> Lists batch inference jobs using AWS Bedrock format.",
      "summary": "This document provides the API specification for listing batch inference jobs using the AWS Bedrock format through the Bifrost gateway.",
      "tags": [
        "bedrock",
        "batch-inference",
        "aws-bedrock",
        "api-reference",
        "model-invocation"
      ],
      "category": "api",
      "original_file_path": "api-reference-bedrock-integration-list-batch-inference-jobs-bedrock-format.md"
    },
    {
      "file_path": "127-api-reference-cache-clear-cache-by-cache-key.md",
      "title": "Clear cache by cache key",
      "url": "https://docs.getbifrost.ai/api-reference/cache/clear-cache-by-cache-key.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:38:21.134448663-03:00",
      "description": "> Clears a cache entry by its direct cache key.",
      "summary": "This document defines the API endpoint for clearing a specific cache entry from the Bifrost gateway using its unique cache key.",
      "tags": [
        "cache-management",
        "api-endpoint",
        "delete-method",
        "bifrost-gateway",
        "cache-key"
      ],
      "category": "api",
      "original_file_path": "api-reference-cache-clear-cache-by-cache-key.md"
    },
    {
      "file_path": "231-api-reference-bedrock-integration-retrieve-batch-inference-job-bedrock-format.md",
      "title": "Retrieve batch inference job (Bedrock format)",
      "url": "https://docs.getbifrost.ai/api-reference/bedrock-integration/retrieve-batch-inference-job-bedrock-format.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:38:20.056892799-03:00",
      "description": "> Retrieves a batch inference job using AWS Bedrock format.",
      "summary": "This document specifies the API endpoint for retrieving the details and status of a batch inference job using the AWS Bedrock-compatible format.",
      "tags": [
        "bedrock-integration",
        "batch-inference",
        "api-reference",
        "aws-bedrock",
        "job-management"
      ],
      "category": "api",
      "original_file_path": "api-reference-bedrock-integration-retrieve-batch-inference-job-bedrock-format.md"
    },
    {
      "file_path": "238-api-reference-bedrock-integration-stream-converse-with-model-bedrock-format.md",
      "title": "Stream converse with model (Bedrock format)",
      "url": "https://docs.getbifrost.ai/api-reference/bedrock-integration/stream-converse-with-model-bedrock-format.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:38:20.850862248-03:00",
      "description": "> Streams messages from a model using AWS Bedrock Converse API format.",
      "summary": "This document defines the API endpoint for streaming chat completions using the AWS Bedrock Converse format through the Bifrost gateway. It outlines the request parameters and message structures required for model interaction.",
      "tags": [
        "aws-bedrock",
        "streaming-api",
        "chat-completions",
        "ai-inference",
        "bifrost-gateway",
        "api-integration"
      ],
      "category": "api",
      "original_file_path": "api-reference-bedrock-integration-stream-converse-with-model-bedrock-format.md"
    },
    {
      "file_path": "128-api-reference-cache-clear-cache-by-request-id.md",
      "title": "Clear cache by request ID",
      "url": "https://docs.getbifrost.ai/api-reference/cache/clear-cache-by-request-id.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:38:21.38529691-03:00",
      "description": "> Clears cache entries associated with a specific request ID.",
      "summary": "This document provides the OpenAPI specification for an endpoint that allows users to delete cache entries associated with a specific request ID in the Bifrost gateway.",
      "tags": [
        "cache-management",
        "api-endpoint",
        "request-id",
        "bifrost-gateway",
        "data-cleanup"
      ],
      "category": "api",
      "original_file_path": "api-reference-cache-clear-cache-by-request-id.md"
    },
    {
      "file_path": "129-api-reference-chat-completions-create-a-chat-completion.md",
      "title": "Create a chat completion",
      "url": "https://docs.getbifrost.ai/api-reference/chat-completions/create-a-chat-completion.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:38:23.034681838-03:00",
      "description": "> Creates a completion for the provided messages. Supports streaming via SSE.",
      "summary": "This document defines the API endpoint for generating chat completions across multiple AI providers through a unified gateway. It details the request structure for messages, model selection, and streaming capabilities using the Bifrost inference format.",
      "tags": [
        "chat-completions",
        "ai-inference",
        "multi-provider",
        "unified-api",
        "openapi-specification",
        "llm-gateway"
      ],
      "category": "api",
      "original_file_path": "api-reference-chat-completions-create-a-chat-completion.md"
    },
    {
      "file_path": "250-api-reference-cohere-integration-create-embeddings-cohere-v2-format.md",
      "title": "Create embeddings (Cohere v2 format)",
      "url": "https://docs.getbifrost.ai/api-reference/cohere-integration/create-embeddings-cohere-v2-format.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:38:25.203391563-03:00",
      "description": "> Creates embeddings using Cohere v2 API format.",
      "summary": "This document provides the API specification for generating text and multimodal embeddings using the Cohere v2 compatible endpoint via the Bifrost gateway.",
      "tags": [
        "cohere-v2",
        "embeddings",
        "api-reference",
        "bifrost-gateway",
        "multimodal-ai"
      ],
      "category": "api",
      "original_file_path": "api-reference-cohere-integration-create-embeddings-cohere-v2-format.md"
    },
    {
      "file_path": "251-api-reference-cohere-integration-tokenize-text-cohere-format.md",
      "title": "Tokenize text (Cohere format)",
      "url": "https://docs.getbifrost.ai/api-reference/cohere-integration/tokenize-text-cohere-format.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:38:25.866651203-03:00",
      "description": "> Tokenizes text using Cohere v1 API format.",
      "summary": "This document provides the API specification for tokenizing text using the Cohere-compatible endpoint within the Bifrost gateway, detailing request parameters and response formats.",
      "tags": [
        "cohere-integration",
        "tokenization",
        "api-reference",
        "text-processing",
        "bifrost-gateway"
      ],
      "category": "api",
      "original_file_path": "api-reference-cohere-integration-tokenize-text-cohere-format.md"
    },
    {
      "file_path": "144-api-reference-configuration-force-pricing-sync.md",
      "title": "Force pricing sync",
      "url": "https://docs.getbifrost.ai/api-reference/configuration/force-pricing-sync.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:38:26.874032187-03:00",
      "description": "> Triggers an immediate pricing sync and resets the pricing sync timer.",
      "summary": "This document describes the API endpoint used to manually trigger an immediate synchronization of pricing data and reset the associated timer within the Bifrost gateway.",
      "tags": [
        "bifrost-api",
        "pricing-sync",
        "configuration-management",
        "api-endpoint",
        "gateway-administration"
      ],
      "category": "api",
      "original_file_path": "api-reference-configuration-force-pricing-sync.md"
    },
    {
      "file_path": "249-api-reference-cohere-integration-chat-with-model-cohere-v2-format.md",
      "title": "Chat with model (Cohere v2 format)",
      "url": "https://docs.getbifrost.ai/api-reference/cohere-integration/chat-with-model-cohere-v2-format.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:38:25.210781416-03:00",
      "description": "> Sends a chat request using Cohere v2 API format.",
      "summary": "This document provides the API specification for sending chat completion requests using the Cohere v2 format through the Bifrost gateway.",
      "tags": [
        "cohere-api",
        "chat-completion",
        "ai-gateway",
        "bifrost-api",
        "api-integration",
        "llm-inference"
      ],
      "category": "api",
      "original_file_path": "api-reference-cohere-integration-chat-with-model-cohere-v2-format.md"
    },
    {
      "file_path": "143-api-reference-configuration-update-configuration.md",
      "title": "Update configuration",
      "url": "https://docs.getbifrost.ai/api-reference/configuration/update-configuration.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:38:31.866596156-03:00",
      "description": "> Updates the Bifrost configuration. Supports hot-reloading of certain settings like drop_excess_requests. Some settings may require a restart to take effect.",
      "summary": "This document details the API endpoint for updating the Bifrost gateway configuration, supporting both hot-reloadable and restart-required settings for the AI inference gateway.",
      "tags": [
        "bifrost",
        "api-configuration",
        "gateway-management",
        "hot-reloading",
        "inference-gateway",
        "configuration-management"
      ],
      "category": "api",
      "original_file_path": "api-reference-configuration-update-configuration.md"
    },
    {
      "file_path": "147-api-reference-configuration-get-version.md",
      "title": "Get version",
      "url": "https://docs.getbifrost.ai/api-reference/configuration/get-version.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:38:31.26082657-03:00",
      "description": "> Returns the current Bifrost version information.",
      "summary": "This document specifies the API endpoint for retrieving the current version information of the Bifrost gateway service.",
      "tags": [
        "bifrost-api",
        "version-endpoint",
        "api-management",
        "system-metadata",
        "gateway-information"
      ],
      "category": "api",
      "original_file_path": "api-reference-configuration-get-version.md"
    },
    {
      "file_path": "142-api-reference-configuration-get-configuration.md",
      "title": "Get configuration",
      "url": "https://docs.getbifrost.ai/api-reference/configuration/get-configuration.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:38:30.228236528-03:00",
      "description": "> Retrieves the current Bifrost configuration including client config, framework config, auth config, and connection status for various stores.",
      "summary": "This document defines the GET /api/config endpoint used to retrieve the current Bifrost gateway configuration, including client settings, framework parameters, and authentication status.",
      "tags": [
        "bifrost",
        "api-configuration",
        "management-api",
        "gateway-settings",
        "ai-gateway"
      ],
      "category": "api",
      "original_file_path": "api-reference-configuration-get-configuration.md"
    },
    {
      "file_path": "145-api-reference-configuration-get-proxy-configuration.md",
      "title": "Get proxy configuration",
      "url": "https://docs.getbifrost.ai/api-reference/configuration/get-proxy-configuration.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:38:31.167926428-03:00",
      "description": "> Retrieves the current global proxy configuration.",
      "summary": "This document describes the API endpoint for retrieving the current global proxy configuration of the Bifrost gateway, including network settings and authentication details.",
      "tags": [
        "api-reference",
        "proxy-configuration",
        "bifrost-gateway",
        "network-settings",
        "http-proxy",
        "management-api"
      ],
      "category": "api",
      "original_file_path": "api-reference-configuration-get-proxy-configuration.md"
    },
    {
      "file_path": "146-api-reference-configuration-update-proxy-configuration.md",
      "title": "Update proxy configuration",
      "url": "https://docs.getbifrost.ai/api-reference/configuration/update-proxy-configuration.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:38:31.99582048-03:00",
      "description": "> Updates the global proxy configuration.",
      "summary": "This document provides the API specification for updating the global proxy settings of the Bifrost gateway, including protocol types, authentication, and specific application scopes.",
      "tags": [
        "bifrost-api",
        "proxy-configuration",
        "gateway-management",
        "network-settings",
        "http-proxy"
      ],
      "category": "api",
      "original_file_path": "api-reference-configuration-update-proxy-configuration.md"
    },
    {
      "file_path": "132-api-reference-files-delete-a-file.md",
      "title": "Delete a file",
      "url": "https://docs.getbifrost.ai/api-reference/files/delete-a-file.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:38:36.749086873-03:00",
      "description": "> Deletes a file.",
      "summary": "This document defines the API endpoint for deleting a specific file from a supported AI provider via the Bifrost gateway.",
      "tags": [
        "file-management",
        "delete-file",
        "api-endpoint",
        "bifrost-api",
        "ai-gateway"
      ],
      "category": "api",
      "original_file_path": "api-reference-files-delete-a-file.md"
    },
    {
      "file_path": "130-api-reference-count-tokens-count-tokens.md",
      "title": "Count tokens",
      "url": "https://docs.getbifrost.ai/api-reference/count-tokens/count-tokens.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:38:36.527789866-03:00",
      "description": "> Counts the number of tokens in the provided messages.",
      "summary": "This document provides the API specification for counting tokens in messages across various AI models using the Bifrost gateway. It details the request parameters, supported message roles, and content types required for accurate token calculation.",
      "tags": [
        "token-counting",
        "api-specification",
        "bifrost-api",
        "ai-inference",
        "token-usage",
        "message-processing"
      ],
      "category": "api",
      "original_file_path": "api-reference-count-tokens-count-tokens.md"
    },
    {
      "file_path": "133-api-reference-files-download-file-content.md",
      "title": "Download file content",
      "url": "https://docs.getbifrost.ai/api-reference/files/download-file-content.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:38:36.915993143-03:00",
      "description": "> Downloads the content of a file.",
      "summary": "This document describes the API endpoint used to retrieve and download the raw binary content of a file stored with a supported AI provider.",
      "tags": [
        "api-endpoint",
        "file-management",
        "file-download",
        "bifrost-api",
        "ai-gateway"
      ],
      "category": "api",
      "original_file_path": "api-reference-files-download-file-content.md"
    },
    {
      "file_path": "131-api-reference-embeddings-create-embeddings.md",
      "title": "Create embeddings",
      "url": "https://docs.getbifrost.ai/api-reference/embeddings/create-embeddings.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:38:36.618516138-03:00",
      "description": "> Creates an embedding vector representing the input text.",
      "summary": "This document specifies the API endpoint for generating embedding vectors from text or token inputs across multiple AI providers using a unified interface. It details the request parameters, supported input formats, and the structure of the resulting vector data.",
      "tags": [
        "embeddings",
        "api-reference",
        "ai-inference",
        "vector-generation",
        "bifrost-gateway",
        "nlp"
      ],
      "category": "api",
      "original_file_path": "api-reference-embeddings-create-embeddings.md"
    },
    {
      "file_path": "135-api-reference-files-list-files.md",
      "title": "List files",
      "url": "https://docs.getbifrost.ai/api-reference/files/list-files.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:38:37.091478049-03:00",
      "description": "> Lists files for a provider.",
      "summary": "This document defines the API endpoint for listing files from various AI providers through the Bifrost gateway, including request parameters and response schemas.",
      "tags": [
        "bifrost-api",
        "file-management",
        "api-endpoint",
        "ai-gateway",
        "openapi-spec"
      ],
      "category": "api",
      "original_file_path": "api-reference-files-list-files.md"
    },
    {
      "file_path": "134-api-reference-files-retrieve-file-metadata.md",
      "title": "Retrieve file metadata",
      "url": "https://docs.getbifrost.ai/api-reference/files/retrieve-file-metadata.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:38:40.433936537-03:00",
      "description": "> Retrieves metadata for a specific file.",
      "summary": "This document details the API endpoint for retrieving metadata and status information for a specific file across multiple AI providers.",
      "tags": [
        "api-reference",
        "file-management",
        "metadata-retrieval",
        "bifrost-api",
        "unified-interface"
      ],
      "category": "api",
      "original_file_path": "api-reference-files-retrieve-file-metadata.md"
    },
    {
      "file_path": "239-api-reference-genai-integration-count-tokens-gemini-format.md",
      "title": "Count tokens (Gemini format)",
      "url": "https://docs.getbifrost.ai/api-reference/genai-integration/count-tokens-gemini-format.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:38:42.032007233-03:00",
      "description": "> Counts tokens using Google Gemini API format.",
      "summary": "This document provides the OpenAPI specification for the Google Gemini-compatible token counting endpoint within the Bifrost API. It details the request structure, including content parts and model parameters, required to estimate token usage for generative AI models.",
      "tags": [
        "gemini-api",
        "token-counting",
        "google-genai",
        "bifrost-gateway",
        "llm-utilities",
        "api-specification"
      ],
      "category": "api",
      "original_file_path": "api-reference-genai-integration-count-tokens-gemini-format.md"
    },
    {
      "file_path": "136-api-reference-files-upload-a-file.md",
      "title": "Upload a file",
      "url": "https://docs.getbifrost.ai/api-reference/files/upload-a-file.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:38:41.42488108-03:00",
      "description": "> Uploads a file to be used with batch operations or other features.",
      "summary": "This document describes the API endpoint for uploading files to the Bifrost gateway to be used in batch operations, fine-tuning, and other AI model features across multiple providers.",
      "tags": [
        "file-upload",
        "bifrost-api",
        "api-endpoint",
        "batch-operations",
        "multipart-form-data",
        "ai-infrastructure"
      ],
      "category": "api",
      "original_file_path": "api-reference-files-upload-a-file.md"
    },
    {
      "file_path": "240-api-reference-genai-integration-embed-content-gemini-format.md",
      "title": "Embed content (Gemini format)",
      "url": "https://docs.getbifrost.ai/api-reference/genai-integration/embed-content-gemini-format.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:38:42.85284441-03:00",
      "description": "> Creates embeddings using Google Gemini API format.",
      "summary": "This document provides the OpenAPI specification for the Google Gemini-compatible embedding endpoint within the Bifrost API gateway, detailing how to generate embeddings using the GenAI format.",
      "tags": [
        "gemini-api",
        "embeddings",
        "bifrost-gateway",
        "google-genai",
        "openapi-spec",
        "vector-embeddings"
      ],
      "category": "api",
      "original_file_path": "api-reference-genai-integration-embed-content-gemini-format.md"
    },
    {
      "file_path": "242-api-reference-genai-integration-delete-file-gemini-format.md",
      "title": "Delete file (Gemini format)",
      "url": "https://docs.getbifrost.ai/api-reference/genai-integration/delete-file-gemini-format.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:38:42.586898565-03:00",
      "description": "> Deletes a file in Google Gemini API format.",
      "summary": "This document specifies the API endpoint for deleting files in Google Gemini format through the Bifrost gateway. It details the required path parameters and potential response codes for the deletion process.",
      "tags": [
        "gemini-api",
        "file-management",
        "bifrost-gateway",
        "genai-integration",
        "api-endpoint"
      ],
      "category": "api",
      "original_file_path": "api-reference-genai-integration-delete-file-gemini-format.md"
    },
    {
      "file_path": "244-api-reference-genai-integration-generate-content-gemini-format.md",
      "title": "Generate content (Gemini format)",
      "url": "https://docs.getbifrost.ai/api-reference/genai-integration/generate-content-gemini-format.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:38:46.026055977-03:00",
      "description": "> Generates content using Google Gemini API format. The model is specified in the URL path.",
      "summary": "This document specifies the API endpoint for generating content through the Google Gemini-compatible interface within the Bifrost gateway.",
      "tags": [
        "gemini-api",
        "google-genai",
        "content-generation",
        "api-integration",
        "bifrost-gateway",
        "inference-api"
      ],
      "category": "api",
      "original_file_path": "api-reference-genai-integration-generate-content-gemini-format.md"
    },
    {
      "file_path": "243-api-reference-genai-integration-list-files-gemini-format.md",
      "title": "List files (Gemini format)",
      "url": "https://docs.getbifrost.ai/api-reference/genai-integration/list-files-gemini-format.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:38:46.763072947-03:00",
      "description": "> Lists uploaded files in Google Gemini API format.",
      "summary": "This document provides the API specification for listing uploaded files in the Google Gemini compatible format through the Bifrost gateway.",
      "tags": [
        "gemini-api",
        "file-management",
        "google-genai",
        "bifrost-gateway",
        "api-integration"
      ],
      "category": "api",
      "original_file_path": "api-reference-genai-integration-list-files-gemini-format.md"
    },
    {
      "file_path": "245-api-reference-genai-integration-generate-image-gemini-format.md",
      "title": "Generate image (Gemini format)",
      "url": "https://docs.getbifrost.ai/api-reference/genai-integration/generate-image-gemini-format.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:38:46.483633464-03:00",
      "description": "> For Imagen models, use the `:predict` suffix (e.g., `imagen-3.0-generate-001:predict`). For Gemini models, use `:generateContent` with `generationConfig.responseModalities: [\"IMAGE\"]` in the request body.",
      "summary": "This document defines the API specification for generating images using Google's Gemini and Imagen models through the Bifrost gateway.",
      "tags": [
        "gemini",
        "imagen",
        "image-generation",
        "bifrost-api",
        "google-genai",
        "api-reference"
      ],
      "category": "api",
      "original_file_path": "api-reference-genai-integration-generate-image-gemini-format.md"
    },
    {
      "file_path": "246-api-reference-genai-integration-list-models-gemini-format.md",
      "title": "List models (Gemini format)",
      "url": "https://docs.getbifrost.ai/api-reference/genai-integration/list-models-gemini-format.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:38:47.610532792-03:00",
      "description": "> Lists available models in Google Gemini API format.",
      "summary": "This document defines the API endpoint for listing available AI models using the Google Gemini (GenAI) compatible format within the Bifrost gateway.",
      "tags": [
        "gemini-api",
        "model-listing",
        "bifrost",
        "genai-integration",
        "api-reference"
      ],
      "category": "api",
      "original_file_path": "api-reference-genai-integration-list-models-gemini-format.md"
    },
    {
      "file_path": "241-api-reference-genai-integration-retrieve-file-gemini-format.md",
      "title": "Retrieve file (Gemini format)",
      "url": "https://docs.getbifrost.ai/api-reference/genai-integration/retrieve-file-gemini-format.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:38:47.653990101-03:00",
      "description": "> Retrieves file metadata in Google Gemini API format.",
      "summary": "This document describes the API endpoint for retrieving file metadata in the Google Gemini format through the Bifrost gateway. It explains that the endpoint provides file details like size and state but requires the file URI for actual content access.",
      "tags": [
        "gemini-api",
        "file-management",
        "metadata-retrieval",
        "google-genai",
        "api-integration"
      ],
      "category": "api",
      "original_file_path": "api-reference-genai-integration-retrieve-file-gemini-format.md"
    },
    {
      "file_path": "247-api-reference-genai-integration-stream-generate-content-gemini-format.md",
      "title": "Stream generate content (Gemini format)",
      "url": "https://docs.getbifrost.ai/api-reference/genai-integration/stream-generate-content-gemini-format.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:38:50.544797312-03:00",
      "description": "> Streams content generation using Google Gemini API format. The model is specified in the URL path.",
      "summary": "This document defines the OpenAPI specification for streaming content generation using the Google Gemini-compatible endpoint within the Bifrost AI gateway. It details the request parameters and schema required to interact with Gemini models in a streaming format.",
      "tags": [
        "gemini-api",
        "streaming-content",
        "ai-gateway",
        "openapi-specification",
        "google-genai",
        "content-generation"
      ],
      "category": "api",
      "original_file_path": "api-reference-genai-integration-stream-generate-content-gemini-format.md"
    },
    {
      "file_path": "248-api-reference-genai-integration-upload-file-gemini-format.md",
      "title": "Upload file (Gemini format)",
      "url": "https://docs.getbifrost.ai/api-reference/genai-integration/upload-file-gemini-format.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:38:51.604197411-03:00",
      "description": "> Uploads a file using Google Gemini API format.",
      "summary": "This document describes the API endpoint for uploading files to Google Gemini via the Bifrost gateway using a multipart request format.",
      "tags": [
        "google-gemini",
        "file-upload",
        "multipart-upload",
        "genai-integration",
        "bifrost-api"
      ],
      "category": "api",
      "original_file_path": "api-reference-genai-integration-upload-file-gemini-format.md"
    },
    {
      "file_path": "156-api-reference-governance-create-team.md",
      "title": "Create team",
      "url": "https://docs.getbifrost.ai/api-reference/governance/create-team.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:38:52.161919114-03:00",
      "description": "> Creates a new team.",
      "summary": "This document defines the API specification for creating a new team in the Bifrost gateway, including parameters for team naming, customer association, and budget constraints.",
      "tags": [
        "bifrost-api",
        "governance",
        "team-management",
        "api-endpoint",
        "budget-configuration",
        "ai-gateway"
      ],
      "category": "api",
      "original_file_path": "api-reference-governance-create-team.md"
    },
    {
      "file_path": "150-api-reference-governance-create-customer.md",
      "title": "Create customer",
      "url": "https://docs.getbifrost.ai/api-reference/governance/create-customer.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:38:52.134384778-03:00",
      "description": "> Creates a new customer.",
      "summary": "This document specifies the API endpoint for creating a new customer within the Bifrost AI gateway, including options for setting budget limits and reset durations.",
      "tags": [
        "bifrost-api",
        "customer-management",
        "governance",
        "api-reference",
        "budget-configuration"
      ],
      "category": "api",
      "original_file_path": "api-reference-governance-create-customer.md"
    },
    {
      "file_path": "161-api-reference-governance-create-virtual-key.md",
      "title": "Create virtual key",
      "url": "https://docs.getbifrost.ai/api-reference/governance/create-virtual-key.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:38:53.594381956-03:00",
      "description": "> Creates a new virtual key with the specified configuration.",
      "summary": "This document provides the API specification for creating a virtual key, which includes configurations for provider weights, model access, usage budgets, and rate limits.",
      "tags": [
        "virtual-keys",
        "governance",
        "api-management",
        "rate-limiting",
        "budget-management",
        "ai-gateway"
      ],
      "category": "api",
      "original_file_path": "api-reference-governance-create-virtual-key.md"
    },
    {
      "file_path": "152-api-reference-governance-delete-customer.md",
      "title": "Delete customer",
      "url": "https://docs.getbifrost.ai/api-reference/governance/delete-customer.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:38:55.792029692-03:00",
      "description": "> Deletes a customer.",
      "summary": "This document details the API endpoint for deleting a customer within the Bifrost governance framework using a specific customer ID.",
      "tags": [
        "bifrost-api",
        "governance",
        "customer-management",
        "delete-operation",
        "api-endpoint"
      ],
      "category": "api",
      "original_file_path": "api-reference-governance-delete-customer.md"
    },
    {
      "file_path": "158-api-reference-governance-delete-team.md",
      "title": "Delete team",
      "url": "https://docs.getbifrost.ai/api-reference/governance/delete-team.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:38:56.835353084-03:00",
      "description": "> Deletes a team.",
      "summary": "This document provides the API specification for deleting a team from the Bifrost governance system using a specific team ID.",
      "tags": [
        "bifrost-api",
        "governance",
        "team-management",
        "delete-team",
        "rest-api"
      ],
      "category": "api",
      "original_file_path": "api-reference-governance-delete-team.md"
    },
    {
      "file_path": "149-api-reference-governance-get-customer.md",
      "title": "Get customer",
      "url": "https://docs.getbifrost.ai/api-reference/governance/get-customer.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:38:56.950021284-03:00",
      "description": "> Returns a specific customer by ID.",
      "summary": "This document describes the API endpoint for retrieving detailed configuration and budget information for a specific customer by their ID.",
      "tags": [
        "governance",
        "customer-management",
        "api-reference",
        "bifrost",
        "budget-tracking"
      ],
      "category": "api",
      "original_file_path": "api-reference-governance-get-customer.md"
    },
    {
      "file_path": "163-api-reference-governance-delete-virtual-key.md",
      "title": "Delete virtual key",
      "url": "https://docs.getbifrost.ai/api-reference/governance/delete-virtual-key.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:38:56.948042364-03:00",
      "description": "> Deletes a virtual key.",
      "summary": "This document specifies the API endpoint for deleting a virtual key within the Bifrost governance system using a unique identifier.",
      "tags": [
        "bifrost-api",
        "governance",
        "virtual-keys",
        "api-management",
        "delete-endpoint",
        "key-management"
      ],
      "category": "api",
      "original_file_path": "api-reference-governance-delete-virtual-key.md"
    },
    {
      "file_path": "155-api-reference-governance-get-team.md",
      "title": "Get team",
      "url": "https://docs.getbifrost.ai/api-reference/governance/get-team.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:38:59.221091879-03:00",
      "description": "> Returns a specific team by ID.",
      "summary": "This document provides technical details for the Bifrost API endpoint used to retrieve detailed configuration and budget information for a specific team using its unique identifier.",
      "tags": [
        "bifrost-api",
        "governance",
        "team-management",
        "api-endpoint",
        "rest-api"
      ],
      "category": "api",
      "original_file_path": "api-reference-governance-get-team.md"
    },
    {
      "file_path": "148-api-reference-governance-list-budgets.md",
      "title": "List budgets",
      "url": "https://docs.getbifrost.ai/api-reference/governance/list-budgets.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:39:01.286045192-03:00",
      "description": "> Returns a list of all budgets. Use the `from_memory` query parameter to get data from in-memory cache.",
      "summary": "This document provides the API specification for listing budgets within the Bifrost governance system, including details on retrieval from cache or database.",
      "tags": [
        "api-reference",
        "governance",
        "budgets",
        "bifrost-api",
        "resource-management"
      ],
      "category": "api",
      "original_file_path": "api-reference-governance-list-budgets.md"
    },
    {
      "file_path": "154-api-reference-governance-list-rate-limits.md",
      "title": "List rate limits",
      "url": "https://docs.getbifrost.ai/api-reference/governance/list-rate-limits.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:39:02.265368264-03:00",
      "description": "> Returns a list of all rate limits. Use the `from_memory` query parameter to get data from in-memory cache.",
      "summary": "This document defines the API endpoint for retrieving a list of all configured rate limits and their current usage statistics within the Bifrost gateway.",
      "tags": [
        "governance",
        "rate-limiting",
        "api-reference",
        "usage-tracking",
        "bifrost-api"
      ],
      "category": "api",
      "original_file_path": "api-reference-governance-list-rate-limits.md"
    },
    {
      "file_path": "160-api-reference-governance-get-virtual-key.md",
      "title": "Get virtual key",
      "url": "https://docs.getbifrost.ai/api-reference/governance/get-virtual-key.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:39:00.567587564-03:00",
      "description": "> Returns a specific virtual key by ID.",
      "summary": "This document provides the API specification for retrieving detailed configuration information for a specific virtual key using its unique identifier.",
      "tags": [
        "api-reference",
        "governance",
        "virtual-keys",
        "bifrost-api",
        "access-management"
      ],
      "category": "api",
      "original_file_path": "api-reference-governance-get-virtual-key.md"
    },
    {
      "file_path": "153-api-reference-governance-list-customers.md",
      "title": "List customers",
      "url": "https://docs.getbifrost.ai/api-reference/governance/list-customers.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:39:02.142743868-03:00",
      "description": "> Returns a list of all customers.",
      "summary": "This document specifies the GET /api/governance/customers endpoint, which retrieves a list of all customers along with their budget, team, and virtual key configurations.",
      "tags": [
        "api-reference",
        "governance",
        "customer-management",
        "bifrost",
        "json-api",
        "endpoint-documentation"
      ],
      "category": "api",
      "original_file_path": "api-reference-governance-list-customers.md"
    },
    {
      "file_path": "151-api-reference-governance-update-customer.md",
      "title": "Update customer",
      "url": "https://docs.getbifrost.ai/api-reference/governance/update-customer.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:39:06.504423506-03:00",
      "description": "> Updates an existing customer.",
      "summary": "This document provides the API specification for updating an existing customer's details, including their name and budget constraints within the Bifrost governance system.",
      "tags": [
        "bifrost-api",
        "customer-management",
        "governance",
        "api-endpoint",
        "budget-configuration",
        "http-put"
      ],
      "category": "api",
      "original_file_path": "api-reference-governance-update-customer.md"
    },
    {
      "file_path": "157-api-reference-governance-update-team.md",
      "title": "Update team",
      "url": "https://docs.getbifrost.ai/api-reference/governance/update-team.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:39:06.700483248-03:00",
      "description": "> Updates an existing team.",
      "summary": "This document provides the API specification for updating an existing team's information, including its name, customer association, and budget constraints within the Bifrost governance system.",
      "tags": [
        "bifrost-api",
        "governance",
        "team-management",
        "budget-configuration",
        "api-endpoint"
      ],
      "category": "api",
      "original_file_path": "api-reference-governance-update-team.md"
    },
    {
      "file_path": "164-api-reference-governance-list-virtual-keys.md",
      "title": "List virtual keys",
      "url": "https://docs.getbifrost.ai/api-reference/governance/list-virtual-keys.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:39:06.275749261-03:00",
      "description": "> Returns a list of all virtual keys with their configurations.",
      "summary": "This document specifies the API endpoint for retrieving a list of all virtual keys along with their configurations, provider settings, and budget limits.",
      "tags": [
        "governance",
        "virtual-keys",
        "api-endpoint",
        "bifrost-api",
        "access-management"
      ],
      "category": "api",
      "original_file_path": "api-reference-governance-list-virtual-keys.md"
    },
    {
      "file_path": "159-api-reference-governance-list-teams.md",
      "title": "List teams",
      "url": "https://docs.getbifrost.ai/api-reference/governance/list-teams.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:39:06.256077745-03:00",
      "description": "> Returns a list of all teams.",
      "summary": "This document provides the technical specification for the Bifrost API endpoint used to retrieve a list of all teams, including details on filtering parameters and response schemas.",
      "tags": [
        "bifrost-api",
        "governance",
        "team-management",
        "api-endpoint",
        "openapi-spec"
      ],
      "category": "api",
      "original_file_path": "api-reference-governance-list-teams.md"
    },
    {
      "file_path": "162-api-reference-governance-update-virtual-key.md",
      "title": "Update virtual key",
      "url": "https://docs.getbifrost.ai/api-reference/governance/update-virtual-key.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:39:09.364015929-03:00",
      "description": "> Updates an existing virtual key's configuration.",
      "summary": "This document describes the API endpoint for updating the configuration of an existing virtual key, including its provider settings, budget constraints, and rate limits.",
      "tags": [
        "governance",
        "virtual-keys",
        "api-management",
        "rate-limiting",
        "budget-management",
        "bifrost-api"
      ],
      "category": "api",
      "original_file_path": "api-reference-governance-update-virtual-key.md"
    },
    {
      "file_path": "138-api-reference-image-generations-generate-image.md",
      "title": "Generate image",
      "url": "https://docs.getbifrost.ai/api-reference/image-generations/generate-image.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:39:11.355113253-03:00",
      "description": "> Generates images from text prompts using the specified model.",
      "summary": "This document specifies the API endpoint for generating images from text prompts using various AI providers via the Bifrost unified interface. It details the request parameters for controlling image size, quality, style, and output format.",
      "tags": [
        "image-generation",
        "text-to-image",
        "bifrost-api",
        "api-endpoint",
        "multi-provider",
        "ai-inference"
      ],
      "category": "api",
      "original_file_path": "api-reference-image-generations-generate-image.md"
    },
    {
      "file_path": "137-api-reference-health-health-check.md",
      "title": "Health check",
      "url": "https://docs.getbifrost.ai/api-reference/health/health-check.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:39:11.206960993-03:00",
      "description": "> Returns the health status of the Bifrost server. Checks connectivity to config store, log store, and vector store if configured.",
      "summary": "This document describes the Bifrost health check endpoint, which verifies the server's operational status and its connectivity to configuration, log, and vector stores.",
      "tags": [
        "health-check",
        "api-monitoring",
        "server-status",
        "diagnostics",
        "bifrost-gateway"
      ],
      "category": "api",
      "original_file_path": "api-reference-health-health-check.md"
    },
    {
      "file_path": "252-api-reference-langchain-integration-chat-completions-langchain-openai-format.md",
      "title": "Chat completions (LangChain - OpenAI format)",
      "url": "https://docs.getbifrost.ai/api-reference/langchain-integration/chat-completions-langchain--openai-format.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:39:11.459685792-03:00",
      "description": "> Creates a chat completion using OpenAI-compatible format via LangChain.",
      "summary": "This document defines the API endpoint for generating chat completions via the LangChain framework using an OpenAI-compatible request format.",
      "tags": [
        "langchain-integration",
        "openai-compatibility",
        "chat-completions",
        "ai-inference",
        "rest-api"
      ],
      "category": "api",
      "original_file_path": "api-reference-langchain-integration-chat-completions-langchain-openai-format.md"
    },
    {
      "file_path": "253-api-reference-langchain-integration-chat-with-model-langchain-cohere-format.md",
      "title": "Chat with model (LangChain - Cohere format)",
      "url": "https://docs.getbifrost.ai/api-reference/langchain-integration/chat-with-model-langchain--cohere-format.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:39:12.237636703-03:00",
      "description": "> Sends a chat request using Cohere-compatible format via LangChain.",
      "summary": "This document specifies the API endpoint for performing chat completions using the Cohere-compatible format via LangChain through the Bifrost gateway.",
      "tags": [
        "langchain",
        "cohere",
        "chat-completions",
        "api-gateway",
        "ai-inference"
      ],
      "category": "api",
      "original_file_path": "api-reference-langchain-integration-chat-with-model-langchain-cohere-format.md"
    },
    {
      "file_path": "254-api-reference-langchain-integration-converse-with-model-langchain-bedrock-format.md",
      "title": "Converse with model (LangChain - Bedrock format)",
      "url": "https://docs.getbifrost.ai/api-reference/langchain-integration/converse-with-model-langchain--bedrock-format.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:39:13.729710364-03:00",
      "description": "> Sends messages using AWS Bedrock Converse-compatible format via LangChain.",
      "summary": "This document provides the API specification for a LangChain-compatible endpoint that facilitates model interactions using the AWS Bedrock Converse format.",
      "tags": [
        "langchain",
        "aws-bedrock",
        "converse-api",
        "inference",
        "api-integration"
      ],
      "category": "api",
      "original_file_path": "api-reference-langchain-integration-converse-with-model-langchain-bedrock-format.md"
    },
    {
      "file_path": "255-api-reference-langchain-integration-count-input-tokens-langchain-openai-format.md",
      "title": "Count input tokens (LangChain - OpenAI format)",
      "url": "https://docs.getbifrost.ai/api-reference/langchain-integration/count-input-tokens-langchain--openai-format.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:39:15.823574941-03:00",
      "description": "> Counts the number of tokens in a Responses API request via LangChain.",
      "summary": "This document defines an API endpoint for counting the number of input tokens in requests using the LangChain-OpenAI format. It specifies the request structure for various input types including messages, tool calls, and multimedia content.",
      "tags": [
        "langchain-integration",
        "openai-format",
        "token-counting",
        "input-tokens",
        "api-specification",
        "bifrost-gateway"
      ],
      "category": "api",
      "original_file_path": "api-reference-langchain-integration-count-input-tokens-langchain-openai-format.md"
    },
    {
      "file_path": "256-api-reference-langchain-integration-count-tokens-langchain-anthropic-format.md",
      "title": "Count tokens (LangChain - Anthropic format)",
      "url": "https://docs.getbifrost.ai/api-reference/langchain-integration/count-tokens-langchain--anthropic-format.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:39:15.963159415-03:00",
      "description": "> Counts tokens using Anthropic-compatible format via LangChain.",
      "summary": "This document provides the OpenAPI specification for an endpoint that counts tokens in messages using the Anthropic-compatible format via LangChain integration.",
      "tags": [
        "langchain",
        "anthropic",
        "token-counting",
        "api-reference",
        "bifrost"
      ],
      "category": "api",
      "original_file_path": "api-reference-langchain-integration-count-tokens-langchain-anthropic-format.md"
    },
    {
      "file_path": "257-api-reference-langchain-integration-create-embeddings-langchain-cohere-format.md",
      "title": "Create embeddings (LangChain - Cohere format)",
      "url": "https://docs.getbifrost.ai/api-reference/langchain-integration/create-embeddings-langchain--cohere-format.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:39:17.59720431-03:00",
      "description": "> Creates embeddings using Cohere-compatible format via LangChain.",
      "summary": "This document specifies the API endpoint for generating text and multimodal embeddings using the LangChain framework in a Cohere-compatible format.",
      "tags": [
        "langchain",
        "cohere",
        "embeddings",
        "api-reference",
        "multimodal",
        "text-processing"
      ],
      "category": "api",
      "original_file_path": "api-reference-langchain-integration-create-embeddings-langchain-cohere-format.md"
    },
    {
      "file_path": "260-api-reference-langchain-integration-create-message-langchain-anthropic-format.md",
      "title": "Create message (LangChain - Anthropic format)",
      "url": "https://docs.getbifrost.ai/api-reference/langchain-integration/create-message-langchain--anthropic-format.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:39:18.550749618-03:00",
      "description": "> Creates a message using Anthropic-compatible format via LangChain.",
      "summary": "This document defines the API specification for creating messages using the Anthropic-compatible format via LangChain within the Bifrost gateway.",
      "tags": [
        "langchain",
        "anthropic",
        "chat-completions",
        "api-gateway",
        "ai-inference"
      ],
      "category": "api",
      "original_file_path": "api-reference-langchain-integration-create-message-langchain-anthropic-format.md"
    },
    {
      "file_path": "258-api-reference-langchain-integration-create-embeddings-langchain-openai-format.md",
      "title": "Create embeddings (LangChain - OpenAI format)",
      "url": "https://docs.getbifrost.ai/api-reference/langchain-integration/create-embeddings-langchain--openai-format.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:39:18.198867743-03:00",
      "description": "> Creates embeddings using OpenAI-compatible format via LangChain.",
      "summary": "This document specifies the API endpoint for generating text embeddings using an OpenAI-compatible format optimized for LangChain integration. It outlines the request parameters, including model selection and input text, as well as the structure of the embedding response.",
      "tags": [
        "langchain",
        "openai-compatible",
        "embeddings",
        "api-specification",
        "bifrost",
        "ai-inference"
      ],
      "category": "api",
      "original_file_path": "api-reference-langchain-integration-create-embeddings-langchain-openai-format.md"
    },
    {
      "file_path": "263-api-reference-langchain-integration-create-response-langchain-openai-responses-api.md",
      "title": "Create response (LangChain - OpenAI Responses API)",
      "url": "https://docs.getbifrost.ai/api-reference/langchain-integration/create-response-langchain--openai-responses-api.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:39:20.559048079-03:00",
      "description": "> Creates a response using OpenAI Responses API format via LangChain. Supports streaming via SSE.",
      "summary": "This document specifies the API endpoint for creating AI model responses using the OpenAI format via LangChain, supporting both standard and streaming interactions.",
      "tags": [
        "langchain",
        "openai-api",
        "inference-gateway",
        "rest-api",
        "streaming-sse",
        "bifrost-api"
      ],
      "category": "api",
      "original_file_path": "api-reference-langchain-integration-create-response-langchain-openai-responses-api.md"
    },
    {
      "file_path": "264-api-reference-langchain-integration-create-speech-langchain-openai-tts.md",
      "title": "Create speech (LangChain - OpenAI TTS)",
      "url": "https://docs.getbifrost.ai/api-reference/langchain-integration/create-speech-langchain--openai-tts.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:39:20.634290218-03:00",
      "description": "> Generates audio from text using OpenAI TTS via LangChain.",
      "summary": "This document specifies the LangChain-compatible API endpoint for converting text to audio using OpenAI's Text-to-Speech models.",
      "tags": [
        "langchain",
        "openai-tts",
        "text-to-speech",
        "speech-synthesis",
        "api-endpoint"
      ],
      "category": "api",
      "original_file_path": "api-reference-langchain-integration-create-speech-langchain-openai-tts.md"
    },
    {
      "file_path": "269-api-reference-langchain-integration-create-transcription-langchain-openai-whisper.md",
      "title": "Create transcription (LangChain - OpenAI Whisper)",
      "url": "https://docs.getbifrost.ai/api-reference/langchain-integration/create-transcription-langchain--openai-whisper.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:39:21.745244919-03:00",
      "description": "> Transcribes audio into text using OpenAI Whisper via LangChain.",
      "summary": "This document specifies the API endpoint for transcribing audio into text using OpenAI Whisper via the LangChain framework on the Bifrost gateway.",
      "tags": [
        "langchain",
        "openai-whisper",
        "audio-transcription",
        "speech-to-text",
        "api-reference"
      ],
      "category": "api",
      "original_file_path": "api-reference-langchain-integration-create-transcription-langchain-openai-whisper.md"
    },
    {
      "file_path": "259-api-reference-langchain-integration-generate-content-langchain-gemini-format.md",
      "title": "Generate content (LangChain - Gemini format)",
      "url": "https://docs.getbifrost.ai/api-reference/langchain-integration/generate-content-langchain--gemini-format.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:39:23.659291278-03:00",
      "description": "> Generates content using Google Gemini-compatible format via LangChain.",
      "summary": "This document specifies the API endpoint for generating content using the Google Gemini format through the LangChain framework integration. It outlines the request structure for handling multi-modal inputs, including text, inline data, and model parameters within the Bifrost gateway.",
      "tags": [
        "langchain-integration",
        "google-gemini",
        "api-specification",
        "content-generation",
        "ai-gateway",
        "bifrost-api"
      ],
      "category": "api",
      "original_file_path": "api-reference-langchain-integration-generate-content-langchain-gemini-format.md"
    },
    {
      "file_path": "262-api-reference-langchain-integration-list-models-langchain-openai-format.md",
      "title": "List models (LangChain - OpenAI format)",
      "url": "https://docs.getbifrost.ai/api-reference/langchain-integration/list-models-langchain--openai-format.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:39:24.920006363-03:00",
      "description": "> Lists available models using OpenAI-compatible format via LangChain.",
      "summary": "This document provides the API specification for listing available AI models using an OpenAI-compatible format designed for LangChain integrations within the Bifrost gateway.",
      "tags": [
        "langchain",
        "openai-compatible",
        "api-reference",
        "model-listing",
        "bifrost",
        "ai-gateway"
      ],
      "category": "api",
      "original_file_path": "api-reference-langchain-integration-list-models-langchain-openai-format.md"
    },
    {
      "file_path": "261-api-reference-langchain-integration-list-models-langchain-gemini-format.md",
      "title": "List models (LangChain - Gemini format)",
      "url": "https://docs.getbifrost.ai/api-reference/langchain-integration/list-models-langchain--gemini-format.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:39:24.188437357-03:00",
      "description": "> Lists available models in Google Gemini API format via LangChain.",
      "summary": "This document defines the API endpoint for listing available AI models using the Google Gemini format via the LangChain integration. It details the request parameters and response structure, including model capabilities, token limits, and supported generation methods.",
      "tags": [
        "google-gemini",
        "langchain-integration",
        "api-reference",
        "model-listing",
        "bifrost-gateway",
        "ai-inference"
      ],
      "category": "api",
      "original_file_path": "api-reference-langchain-integration-list-models-langchain-gemini-format.md"
    },
    {
      "file_path": "265-api-reference-langchain-integration-stream-converse-with-model-langchain-bedrock-format.md",
      "title": "Stream converse with model (LangChain - Bedrock format)",
      "url": "https://docs.getbifrost.ai/api-reference/langchain-integration/stream-converse-with-model-langchain--bedrock-format.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:39:25.558484048-03:00",
      "description": "> Streams messages using AWS Bedrock Converse-compatible format via LangChain.",
      "summary": "This document defines an API endpoint for streaming conversational model responses using the AWS Bedrock Converse format via LangChain integration.",
      "tags": [
        "langchain",
        "aws-bedrock",
        "streaming-api",
        "ai-inference",
        "converse-stream"
      ],
      "category": "api",
      "original_file_path": "api-reference-langchain-integration-stream-converse-with-model-langchain-bedrock-format.md"
    },
    {
      "file_path": "266-api-reference-langchain-integration-stream-generate-content-langchain-gemini-format.md",
      "title": "Stream generate content (LangChain - Gemini format)",
      "url": "https://docs.getbifrost.ai/api-reference/langchain-integration/stream-generate-content-langchain--gemini-format.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:39:27.124627119-03:00",
      "description": "> Streams content generation using Google Gemini-compatible format via LangChain.",
      "summary": "This document defines the OpenAPI specification for streaming content generation using the Google Gemini-compatible format via LangChain. It details the request parameters and schema required to interact with Gemini models through the Bifrost AI gateway.",
      "tags": [
        "langchain",
        "gemini",
        "streaming",
        "content-generation",
        "api-reference",
        "google-genai"
      ],
      "category": "api",
      "original_file_path": "api-reference-langchain-integration-stream-generate-content-langchain-gemini-format.md"
    },
    {
      "file_path": "267-api-reference-langchain-integration-text-completions-langchain-openai-format.md",
      "title": "Text completions (LangChain - OpenAI format)",
      "url": "https://docs.getbifrost.ai/api-reference/langchain-integration/text-completions-langchain--openai-format.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:39:28.933218261-03:00",
      "description": "> Creates a text completion using OpenAI-compatible format via LangChain. This is the legacy completions API.",
      "summary": "This document specifies the legacy text completions API endpoint designed for LangChain integration using an OpenAI-compatible request format.",
      "tags": [
        "langchain",
        "openai-compatible",
        "text-completions",
        "api-reference",
        "legacy-api"
      ],
      "category": "api",
      "original_file_path": "api-reference-langchain-integration-text-completions-langchain-openai-format.md"
    },
    {
      "file_path": "268-api-reference-langchain-integration-tokenize-text-langchain-cohere-format.md",
      "title": "Tokenize text (LangChain - Cohere format)",
      "url": "https://docs.getbifrost.ai/api-reference/langchain-integration/tokenize-text-langchain--cohere-format.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:39:30.394056935-03:00",
      "description": "> Tokenizes text using Cohere-compatible format via LangChain.",
      "summary": "This document provides the API specification for tokenizing text strings into token IDs and strings using Cohere-compatible formatting via the LangChain integration.",
      "tags": [
        "langchain",
        "cohere",
        "tokenization",
        "api-reference",
        "bifrost-gateway",
        "text-processing"
      ],
      "category": "api",
      "original_file_path": "api-reference-langchain-integration-tokenize-text-langchain-cohere-format.md"
    },
    {
      "file_path": "270-api-reference-litellm-integration-chat-completions-litellm-openai-format.md",
      "title": "Chat completions (LiteLLM - OpenAI format)",
      "url": "https://docs.getbifrost.ai/api-reference/litellm-integration/chat-completions-litellm--openai-format.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:39:30.52190049-03:00",
      "description": "> Creates a chat completion using OpenAI-compatible format via LiteLLM.",
      "summary": "This document specifies the OpenAPI definition for the LiteLLM-compatible chat completion endpoint within the Bifrost API gateway, enabling multi-provider inference using OpenAI-formatted requests.",
      "tags": [
        "litellm",
        "chat-completions",
        "openai-format",
        "api-gateway",
        "inference-api"
      ],
      "category": "api",
      "original_file_path": "api-reference-litellm-integration-chat-completions-litellm-openai-format.md"
    },
    {
      "file_path": "271-api-reference-litellm-integration-chat-with-model-litellm-cohere-format.md",
      "title": "Chat with model (LiteLLM - Cohere format)",
      "url": "https://docs.getbifrost.ai/api-reference/litellm-integration/chat-with-model-litellm--cohere-format.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:39:30.897509184-03:00",
      "description": "> Sends a chat request using Cohere-compatible format via LiteLLM.",
      "summary": "This document specifies the API endpoint for performing chat completions using the Cohere-compatible format via the LiteLLM proxy on the Bifrost gateway.",
      "tags": [
        "litellm",
        "cohere",
        "chat-completion",
        "api-gateway",
        "ai-inference",
        "multi-provider"
      ],
      "category": "api",
      "original_file_path": "api-reference-litellm-integration-chat-with-model-litellm-cohere-format.md"
    },
    {
      "file_path": "272-api-reference-litellm-integration-converse-with-model-litellm-bedrock-format.md",
      "title": "Converse with model (LiteLLM - Bedrock format)",
      "url": "https://docs.getbifrost.ai/api-reference/litellm-integration/converse-with-model-litellm--bedrock-format.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:39:33.545788018-03:00",
      "description": "> Sends messages using AWS Bedrock Converse-compatible format via LiteLLM.",
      "summary": "This document provides the API specification for interacting with AI models using the AWS Bedrock Converse format via the LiteLLM proxy. It defines the endpoint structure, request parameters, and supported message content types including text, images, and documents.",
      "tags": [
        "litellm",
        "aws-bedrock",
        "api-specification",
        "ai-inference",
        "converse-api",
        "bifrost-gateway"
      ],
      "category": "api",
      "original_file_path": "api-reference-litellm-integration-converse-with-model-litellm-bedrock-format.md"
    },
    {
      "file_path": "273-api-reference-litellm-integration-count-input-tokens-litellm-openai-format.md",
      "title": "Count input tokens (LiteLLM - OpenAI format)",
      "url": "https://docs.getbifrost.ai/api-reference/litellm-integration/count-input-tokens-litellm--openai-format.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:39:34.263803229-03:00",
      "description": "> Counts the number of tokens in a Responses API request via LiteLLM.",
      "summary": "This document defines an API endpoint for calculating the number of input tokens in a LiteLLM-compatible OpenAI request format within the Bifrost gateway. It specifies the request structure and supported model identifiers for token counting across multiple AI providers.",
      "tags": [
        "litellm",
        "openai-format",
        "token-counting",
        "api-specification",
        "bifrost-api",
        "inference-gateway"
      ],
      "category": "api",
      "original_file_path": "api-reference-litellm-integration-count-input-tokens-litellm-openai-format.md"
    },
    {
      "file_path": "277-api-reference-litellm-integration-create-message-litellm-anthropic-format.md",
      "title": "Create message (LiteLLM - Anthropic format)",
      "url": "https://docs.getbifrost.ai/api-reference/litellm-integration/create-message-litellm--anthropic-format.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:39:35.493931589-03:00",
      "description": "> Creates a message using Anthropic-compatible format via LiteLLM.",
      "summary": "This document specifies the API endpoint for creating messages using the Anthropic-compatible format through the LiteLLM proxy integration.",
      "tags": [
        "litellm",
        "anthropic-format",
        "message-creation",
        "api-integration",
        "ai-inference",
        "bifrost-api"
      ],
      "category": "api",
      "original_file_path": "api-reference-litellm-integration-create-message-litellm-anthropic-format.md"
    },
    {
      "file_path": "274-api-reference-litellm-integration-create-embeddings-litellm-cohere-format.md",
      "title": "Create embeddings (LiteLLM - Cohere format)",
      "url": "https://docs.getbifrost.ai/api-reference/litellm-integration/create-embeddings-litellm--cohere-format.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:39:34.927232762-03:00",
      "description": "> Creates embeddings using Cohere-compatible format via LiteLLM.",
      "summary": "This document specifies the API endpoint for generating text and multimodal embeddings using the Cohere-compatible format via the LiteLLM integration.",
      "tags": [
        "litellm",
        "cohere",
        "embeddings",
        "api-proxy",
        "multimodal-embeddings"
      ],
      "category": "api",
      "original_file_path": "api-reference-litellm-integration-create-embeddings-litellm-cohere-format.md"
    },
    {
      "file_path": "275-api-reference-litellm-integration-create-embeddings-litellm-openai-format.md",
      "title": "Create embeddings (LiteLLM - OpenAI format)",
      "url": "https://docs.getbifrost.ai/api-reference/litellm-integration/create-embeddings-litellm--openai-format.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:39:35.261690438-03:00",
      "description": "> Creates embeddings using OpenAI-compatible format via LiteLLM.",
      "summary": "Provides the API specification for generating text embeddings using an OpenAI-compatible format through the LiteLLM proxy integration.",
      "tags": [
        "embeddings",
        "litellm",
        "openai-format",
        "api-reference",
        "bifrost"
      ],
      "category": "api",
      "original_file_path": "api-reference-litellm-integration-create-embeddings-litellm-openai-format.md"
    },
    {
      "file_path": "280-api-reference-litellm-integration-create-response-litellm-openai-responses-api.md",
      "title": "Create response (LiteLLM - OpenAI Responses API)",
      "url": "https://docs.getbifrost.ai/api-reference/litellm-integration/create-response-litellm--openai-responses-api.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:39:38.531900105-03:00",
      "description": "> Creates a response using OpenAI Responses API format via LiteLLM. Supports streaming via SSE.",
      "summary": "This document defines the API endpoint for generating model responses using the LiteLLM proxy with OpenAI-compatible formatting and SSE streaming support.",
      "tags": [
        "litellm",
        "openai-responses",
        "api-gateway",
        "inference",
        "streaming-sse"
      ],
      "category": "api",
      "original_file_path": "api-reference-litellm-integration-create-response-litellm-openai-responses-api.md"
    },
    {
      "file_path": "286-api-reference-litellm-integration-create-transcription-litellm-openai-whisper.md",
      "title": "Create transcription (LiteLLM - OpenAI Whisper)",
      "url": "https://docs.getbifrost.ai/api-reference/litellm-integration/create-transcription-litellm--openai-whisper.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:39:39.596568038-03:00",
      "description": "> Transcribes audio into text using OpenAI Whisper via LiteLLM.",
      "summary": "This document provides the API specification for transcribing audio files into text using the OpenAI Whisper model through the LiteLLM proxy integration.",
      "tags": [
        "audio-transcription",
        "litellm",
        "openai-whisper",
        "speech-to-text",
        "api-endpoint"
      ],
      "category": "api",
      "original_file_path": "api-reference-litellm-integration-create-transcription-litellm-openai-whisper.md"
    },
    {
      "file_path": "276-api-reference-litellm-integration-generate-content-litellm-gemini-format.md",
      "title": "Generate content (LiteLLM - Gemini format)",
      "url": "https://docs.getbifrost.ai/api-reference/litellm-integration/generate-content-litellm--gemini-format.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:39:39.618467756-03:00",
      "description": "> Generates content using Google Gemini-compatible format via LiteLLM.",
      "summary": "This document defines the API endpoint for generating AI content using the Google Gemini-compatible format through the LiteLLM integration.",
      "tags": [
        "litellm",
        "google-gemini",
        "content-generation",
        "api-reference",
        "ai-inference"
      ],
      "category": "api",
      "original_file_path": "api-reference-litellm-integration-generate-content-litellm-gemini-format.md"
    },
    {
      "file_path": "281-api-reference-litellm-integration-create-speech-litellm-openai-tts.md",
      "title": "Create speech (LiteLLM - OpenAI TTS)",
      "url": "https://docs.getbifrost.ai/api-reference/litellm-integration/create-speech-litellm--openai-tts.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:39:39.582307455-03:00",
      "description": "> Generates audio from text using OpenAI TTS via LiteLLM.",
      "summary": "This document provides the API specification for converting text into audio using OpenAI's Text-to-Speech models through the LiteLLM proxy interface.",
      "tags": [
        "litellm",
        "text-to-speech",
        "openai-tts",
        "api-reference",
        "audio-generation"
      ],
      "category": "api",
      "original_file_path": "api-reference-litellm-integration-create-speech-litellm-openai-tts.md"
    },
    {
      "file_path": "278-api-reference-litellm-integration-list-models-litellm-gemini-format.md",
      "title": "List models (LiteLLM - Gemini format)",
      "url": "https://docs.getbifrost.ai/api-reference/litellm-integration/list-models-litellm--gemini-format.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:39:40.397889367-03:00",
      "description": "> Lists available models in Google Gemini API format via LiteLLM.",
      "summary": "This document defines the REST API endpoint for listing available AI models through the LiteLLM proxy using the Google Gemini (GenAI) compatible format.",
      "tags": [
        "litellm",
        "gemini-api",
        "model-listing",
        "bifrost-api",
        "rest-api",
        "ai-gateway"
      ],
      "category": "api",
      "original_file_path": "api-reference-litellm-integration-list-models-litellm-gemini-format.md"
    },
    {
      "file_path": "279-api-reference-litellm-integration-list-models-litellm-openai-format.md",
      "title": "List models (LiteLLM - OpenAI format)",
      "url": "https://docs.getbifrost.ai/api-reference/litellm-integration/list-models-litellm--openai-format.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:39:42.792681523-03:00",
      "description": "> Lists available models using OpenAI-compatible format via LiteLLM.",
      "summary": "This document defines the API endpoint for retrieving a list of available AI models through the LiteLLM proxy using an OpenAI-compatible format.",
      "tags": [
        "litellm",
        "openai-compatible",
        "model-listing",
        "api-gateway",
        "bifrost-api"
      ],
      "category": "api",
      "original_file_path": "api-reference-litellm-integration-list-models-litellm-openai-format.md"
    },
    {
      "file_path": "283-api-reference-litellm-integration-stream-generate-content-litellm-gemini-format.md",
      "title": "Stream generate content (LiteLLM - Gemini format)",
      "url": "https://docs.getbifrost.ai/api-reference/litellm-integration/stream-generate-content-litellm--gemini-format.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:39:44.219743997-03:00",
      "description": "> Streams content generation using Google Gemini-compatible format via LiteLLM.",
      "summary": "This document provides the OpenAPI specification for streaming content generation using the Google Gemini-compatible format via the LiteLLM integration.",
      "tags": [
        "litellm",
        "google-gemini",
        "streaming-api",
        "openapi-spec",
        "ai-inference",
        "content-generation"
      ],
      "category": "api",
      "original_file_path": "api-reference-litellm-integration-stream-generate-content-litellm-gemini-format.md"
    },
    {
      "file_path": "284-api-reference-litellm-integration-text-completions-litellm-openai-format.md",
      "title": "Text completions (LiteLLM - OpenAI format)",
      "url": "https://docs.getbifrost.ai/api-reference/litellm-integration/text-completions-litellm--openai-format.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:39:44.337382434-03:00",
      "description": "> Creates a text completion using OpenAI-compatible format via LiteLLM. This is the legacy completions API.",
      "summary": "This document defines the legacy OpenAI-compatible text completions endpoint provided via LiteLLM for multi-provider AI model inference.",
      "tags": [
        "litellm",
        "openai-format",
        "text-completions",
        "api-gateway",
        "inference-api"
      ],
      "category": "api",
      "original_file_path": "api-reference-litellm-integration-text-completions-litellm-openai-format.md"
    },
    {
      "file_path": "285-api-reference-litellm-integration-tokenize-text-litellm-cohere-format.md",
      "title": "Tokenize text (LiteLLM - Cohere format)",
      "url": "https://docs.getbifrost.ai/api-reference/litellm-integration/tokenize-text-litellm--cohere-format.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:39:44.454502478-03:00",
      "description": "> Tokenizes text using Cohere-compatible format via LiteLLM.",
      "summary": "This document specifies the API endpoint for tokenizing text using the Cohere-compatible format via the LiteLLM integration.",
      "tags": [
        "litellm",
        "cohere",
        "tokenization",
        "api-reference",
        "bifrost-api",
        "text-processing"
      ],
      "category": "api",
      "original_file_path": "api-reference-litellm-integration-tokenize-text-litellm-cohere-format.md"
    },
    {
      "file_path": "282-api-reference-litellm-integration-stream-converse-with-model-litellm-bedrock-format.md",
      "title": "Stream converse with model (LiteLLM - Bedrock format)",
      "url": "https://docs.getbifrost.ai/api-reference/litellm-integration/stream-converse-with-model-litellm--bedrock-format.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:39:43.759497101-03:00",
      "description": "> Streams messages using AWS Bedrock Converse-compatible format via LiteLLM.",
      "summary": "This document provides the OpenAPI specification for streaming AI model conversations via the LiteLLM integration using the AWS Bedrock Converse format. It details the endpoint structure, request parameters, and message schemas for real-time inference.",
      "tags": [
        "litellm",
        "aws-bedrock",
        "streaming-api",
        "converse-stream",
        "ai-inference",
        "openapi-spec"
      ],
      "category": "api",
      "original_file_path": "api-reference-litellm-integration-stream-converse-with-model-litellm-bedrock-format.md"
    },
    {
      "file_path": "169-api-reference-logging-delete-logs.md",
      "title": "Delete logs",
      "url": "https://docs.getbifrost.ai/api-reference/logging/delete-logs.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:39:47.112703393-03:00",
      "description": "> Deletes logs by their IDs.",
      "summary": "This document defines the API endpoint for deleting logs by their unique identifiers within the Bifrost gateway management system.",
      "tags": [
        "bifrost-api",
        "log-management",
        "api-endpoint",
        "management-api",
        "openapi-specification"
      ],
      "category": "api",
      "original_file_path": "api-reference-logging-delete-logs.md"
    },
    {
      "file_path": "166-api-reference-logging-get-dropped-requests-count.md",
      "title": "Get dropped requests count",
      "url": "https://docs.getbifrost.ai/api-reference/logging/get-dropped-requests-count.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:39:48.754137093-03:00",
      "description": "> Returns the number of dropped requests.",
      "summary": "This document describes the API endpoint used to retrieve the total count of dropped requests from the Bifrost gateway for monitoring and logging purposes.",
      "tags": [
        "bifrost-api",
        "logging",
        "monitoring",
        "api-reference",
        "dropped-requests",
        "metrics"
      ],
      "category": "api",
      "original_file_path": "api-reference-logging-get-dropped-requests-count.md"
    },
    {
      "file_path": "167-api-reference-logging-get-log-statistics.md",
      "title": "Get log statistics",
      "url": "https://docs.getbifrost.ai/api-reference/logging/get-log-statistics.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:39:49.573444472-03:00",
      "description": "> Returns statistics for logs matching the specified filters.",
      "summary": "This document specifies the API endpoint for retrieving aggregated log statistics, including request counts, token usage, and costs based on various filters.",
      "tags": [
        "api-endpoint",
        "log-statistics",
        "analytics",
        "monitoring",
        "bifrost-api"
      ],
      "category": "api",
      "original_file_path": "api-reference-logging-get-log-statistics.md"
    },
    {
      "file_path": "165-api-reference-logging-get-available-filter-data.md",
      "title": "Get available filter data",
      "url": "https://docs.getbifrost.ai/api-reference/logging/get-available-filter-data.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:39:48.594159778-03:00",
      "description": "> Returns all unique filter data from logs (models, keys, virtual keys).",
      "summary": "This API endpoint retrieves unique metadata from logs, including available models and keys, to facilitate log filtering and search.",
      "tags": [
        "logging",
        "api-reference",
        "log-analytics",
        "filter-data",
        "bifrost-gateway",
        "metadata"
      ],
      "category": "api",
      "original_file_path": "api-reference-logging-get-available-filter-data.md"
    },
    {
      "file_path": "168-api-reference-logging-get-logs.md",
      "title": "Get logs",
      "url": "https://docs.getbifrost.ai/api-reference/logging/get-logs.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:39:49.575970849-03:00",
      "description": "> Retrieves logs with filtering, search, and pagination via query parameters.",
      "summary": "This document describes the API endpoint for retrieving gateway logs with support for advanced filtering, search, and pagination. It details how to use query parameters to filter logs by provider, model, status, cost, and time range.",
      "tags": [
        "logging-api",
        "bifrost-gateway",
        "log-management",
        "rest-api",
        "api-monitoring",
        "search-parameters"
      ],
      "category": "api",
      "original_file_path": "api-reference-logging-get-logs.md"
    },
    {
      "file_path": "171-api-reference-mcp-add-mcp-client.md",
      "title": "Add MCP client",
      "url": "https://docs.getbifrost.ai/api-reference/mcp/add-mcp-client.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:39:53.21531919-03:00",
      "description": "> Adds a new MCP client with the specified configuration.",
      "summary": "This document defines the API endpoint for adding and configuring Model Context Protocol (MCP) clients within the Bifrost gateway.",
      "tags": [
        "mcp-client",
        "model-context-protocol",
        "api-endpoint",
        "bifrost-gateway",
        "configuration-management"
      ],
      "category": "api",
      "original_file_path": "api-reference-mcp-add-mcp-client.md"
    },
    {
      "file_path": "170-api-reference-logging-recalculate-log-costs.md",
      "title": "Recalculate log costs",
      "url": "https://docs.getbifrost.ai/api-reference/logging/recalculate-log-costs.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:39:52.533089664-03:00",
      "description": "> Recomputes missing costs in batches. Processes logs with missing cost values and updates them based on current pricing data.",
      "summary": "This document defines an API endpoint for recomputing missing log costs in batches using current pricing data and various search filters.",
      "tags": [
        "logging",
        "cost-management",
        "batch-processing",
        "api-reference",
        "bifrost-api"
      ],
      "category": "api",
      "original_file_path": "api-reference-logging-recalculate-log-costs.md"
    },
    {
      "file_path": "173-api-reference-mcp-execute-mcp-tool.md",
      "title": "Execute MCP tool",
      "url": "https://docs.getbifrost.ai/api-reference/mcp/execute-mcp-tool.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:39:55.195658017-03:00",
      "description": "> Executes an MCP tool and returns the result.",
      "summary": "This document defines the API endpoint for executing Model Context Protocol (MCP) tools and retrieving results using chat or response formats.",
      "tags": [
        "mcp",
        "tool-execution",
        "api-reference",
        "model-context-protocol",
        "bifrost-api"
      ],
      "category": "api",
      "original_file_path": "api-reference-mcp-execute-mcp-tool.md"
    },
    {
      "file_path": "174-api-reference-mcp-list-mcp-clients.md",
      "title": "List MCP clients",
      "url": "https://docs.getbifrost.ai/api-reference/mcp/list-mcp-clients.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:39:55.358518004-03:00",
      "description": "> Returns a list of all configured MCP clients with their tools and connection state.",
      "summary": "This document defines the API endpoint for retrieving a list of all configured Model Context Protocol (MCP) clients, including their tools, connection states, and configuration details.",
      "tags": [
        "mcp",
        "api-management",
        "model-context-protocol",
        "bifrost-api",
        "client-configuration"
      ],
      "category": "api",
      "original_file_path": "api-reference-mcp-list-mcp-clients.md"
    },
    {
      "file_path": "172-api-reference-mcp-edit-mcp-client.md",
      "title": "Edit MCP client",
      "url": "https://docs.getbifrost.ai/api-reference/mcp/edit-mcp-client.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:39:54.827605284-03:00",
      "description": "> Updates an existing MCP client's configuration.",
      "summary": "This document provides the API specification for updating an existing Model Context Protocol (MCP) client configuration within the Bifrost gateway.",
      "tags": [
        "mcp",
        "api-reference",
        "model-context-protocol",
        "client-configuration",
        "bifrost-gateway",
        "endpoint-update"
      ],
      "category": "api",
      "original_file_path": "api-reference-mcp-edit-mcp-client.md"
    },
    {
      "file_path": "176-api-reference-mcp-remove-mcp-client.md",
      "title": "Remove MCP client",
      "url": "https://docs.getbifrost.ai/api-reference/mcp/remove-mcp-client.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:39:58.072940226-03:00",
      "description": "> Removes an MCP client from the configuration.",
      "summary": "This document provides the technical specification for the API endpoint used to remove a Model Context Protocol (MCP) client from the gateway configuration.",
      "tags": [
        "mcp",
        "mcp-client",
        "api-management",
        "bifrost",
        "delete-endpoint"
      ],
      "category": "api",
      "original_file_path": "api-reference-mcp-remove-mcp-client.md"
    },
    {
      "file_path": "175-api-reference-mcp-reconnect-mcp-client.md",
      "title": "Reconnect MCP client",
      "url": "https://docs.getbifrost.ai/api-reference/mcp/reconnect-mcp-client.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:39:57.995797236-03:00",
      "description": "> Reconnects an MCP client that is in an error or disconnected state.",
      "summary": "This document specifies the API endpoint for reconnecting a Model Context Protocol (MCP) client that has encountered an error or been disconnected.",
      "tags": [
        "mcp-client",
        "api-endpoint",
        "reconnect",
        "bifrost-api",
        "model-context-protocol"
      ],
      "category": "api",
      "original_file_path": "api-reference-mcp-reconnect-mcp-client.md"
    },
    {
      "file_path": "207-api-reference-openai-integration-cancel-batch-job-openai-format.md",
      "title": "Cancel batch job (OpenAI format)",
      "url": "https://docs.getbifrost.ai/api-reference/openai-integration/cancel-batch-job-openai-format.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:40:00.125547763-03:00",
      "description": "> Cancels a batch processing job.",
      "summary": "This document describes the API endpoint for canceling an active batch processing job using the OpenAI-compatible interface within the Bifrost gateway.",
      "tags": [
        "openai-integration",
        "batch-processing",
        "api-endpoint",
        "bifrost-gateway",
        "job-management"
      ],
      "category": "api",
      "original_file_path": "api-reference-openai-integration-cancel-batch-job-openai-format.md"
    },
    {
      "file_path": "139-api-reference-models-list-available-models.md",
      "title": "List available models",
      "url": "https://docs.getbifrost.ai/api-reference/models/list-available-models.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:39:59.730742567-03:00",
      "description": "> Lists available models. If provider is not specified, lists all models from all configured providers.",
      "summary": "This document provides the API specification for listing available AI models across multiple providers using the Bifrost gateway. It details the request parameters and response schema for retrieving model metadata, including context lengths and pricing information.",
      "tags": [
        "api-specification",
        "model-listing",
        "ai-gateway",
        "multi-provider",
        "bifrost-api",
        "rest-api"
      ],
      "category": "api",
      "original_file_path": "api-reference-models-list-available-models.md"
    },
    {
      "file_path": "211-api-reference-openai-integration-count-input-tokens.md",
      "title": "Count input tokens",
      "url": "https://docs.getbifrost.ai/api-reference/openai-integration/count-input-tokens.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:40:00.498891722-03:00",
      "description": "> Counts the number of tokens in a Responses API request.",
      "summary": "This document describes an API endpoint for counting the number of tokens in an OpenAI-compatible Responses API request within the Bifrost gateway.",
      "tags": [
        "token-counting",
        "openai-compatibility",
        "bifrost-api",
        "api-reference",
        "input-tokens"
      ],
      "category": "api",
      "original_file_path": "api-reference-openai-integration-count-input-tokens.md"
    },
    {
      "file_path": "206-api-reference-openai-integration-create-batch-job-openai-format.md",
      "title": "Create batch job (OpenAI format)",
      "url": "https://docs.getbifrost.ai/api-reference/openai-integration/create-batch-job-openai-format.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:40:02.138302621-03:00",
      "description": "> Creates a batch processing job.",
      "summary": "This document specifies the API endpoint for creating batch processing jobs using the OpenAI-compatible format within the Bifrost gateway.",
      "tags": [
        "openai-integration",
        "batch-processing",
        "api-reference",
        "bifrost",
        "inference-gateway"
      ],
      "category": "api",
      "original_file_path": "api-reference-openai-integration-create-batch-job-openai-format.md"
    },
    {
      "file_path": "209-api-reference-openai-integration-create-chat-completion-azure-openai.md",
      "title": "Create chat completion (Azure OpenAI)",
      "url": "https://docs.getbifrost.ai/api-reference/openai-integration/create-chat-completion-azure-openai.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:40:02.745231796-03:00",
      "description": "> Creates a chat completion using Azure OpenAI deployment.",
      "summary": "This document provides the API specification for creating chat completions using Azure OpenAI deployments via the Bifrost gateway. It details the required path parameters, request body structure, and message formats for model inference.",
      "tags": [
        "azure-openai",
        "chat-completions",
        "api-reference",
        "bifrost-gateway",
        "ai-inference",
        "openai-integration"
      ],
      "category": "api",
      "original_file_path": "api-reference-openai-integration-create-chat-completion-azure-openai.md"
    },
    {
      "file_path": "212-api-reference-openai-integration-create-embeddings-azure-openai.md",
      "title": "Create embeddings (Azure OpenAI)",
      "url": "https://docs.getbifrost.ai/api-reference/openai-integration/create-embeddings-azure-openai.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:40:04.767709986-03:00",
      "description": "> To find navigation and other pages in this documentation, fetch the llms.txt file at: https://docs.getbifrost.ai/llms.txt",
      "summary": "This document provides the OpenAPI specification for the Azure OpenAI embedding endpoint within the Bifrost API gateway, detailing request parameters and response schemas.",
      "tags": [
        "azure-openai",
        "embeddings",
        "api-reference",
        "bifrost-api",
        "text-processing"
      ],
      "category": "api",
      "original_file_path": "api-reference-openai-integration-create-embeddings-azure-openai.md"
    },
    {
      "file_path": "210-api-reference-openai-integration-create-chat-completion-openai-format.md",
      "title": "Create chat completion (OpenAI format)",
      "url": "https://docs.getbifrost.ai/api-reference/openai-integration/create-chat-completion-openai-format.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:40:04.75655596-03:00",
      "description": "> Creates a chat completion using OpenAI-compatible format. Supports streaming via SSE.",
      "summary": "This document provides the technical specification for the OpenAI-compatible chat completions endpoint, enabling unified AI model inference with support for streaming and multiple providers.",
      "tags": [
        "openai-compatibility",
        "chat-completions",
        "api-reference",
        "streaming-sse",
        "ai-inference"
      ],
      "category": "api",
      "original_file_path": "api-reference-openai-integration-create-chat-completion-openai-format.md"
    },
    {
      "file_path": "213-api-reference-openai-integration-create-embeddings-openai-format.md",
      "title": "Create embeddings (OpenAI format)",
      "url": "https://docs.getbifrost.ai/api-reference/openai-integration/create-embeddings-openai-format.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:40:05.869704122-03:00",
      "description": "> Creates embedding vectors for the input text.",
      "summary": "This document provides technical specifications for the OpenAI-compatible embeddings endpoint, detailing how to create embedding vectors for input text via the Bifrost gateway.",
      "tags": [
        "openai-integration",
        "embeddings",
        "api-reference",
        "vector-generation",
        "text-processing"
      ],
      "category": "api",
      "original_file_path": "api-reference-openai-integration-create-embeddings-openai-format.md"
    },
    {
      "file_path": "218-api-reference-openai-integration-create-image-azure-openai.md",
      "title": "Create image (Azure OpenAI)",
      "url": "https://docs.getbifrost.ai/api-reference/openai-integration/create-image-azure-openai.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:40:08.170330632-03:00",
      "description": "> Generates images from text prompts using Azure OpenAI deployment.",
      "summary": "This document specifies the API endpoint for generating images from text prompts using Azure OpenAI deployments through the Bifrost gateway.",
      "tags": [
        "azure-openai",
        "image-generation",
        "api-reference",
        "bifrost",
        "dall-e"
      ],
      "category": "api",
      "original_file_path": "api-reference-openai-integration-create-image-azure-openai.md"
    },
    {
      "file_path": "219-api-reference-openai-integration-create-image.md",
      "title": "Create image",
      "url": "https://docs.getbifrost.ai/api-reference/openai-integration/create-image.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:40:07.04732839-03:00",
      "description": "> Generates images from text prompts using OpenAI-compatible format.",
      "summary": "This document provides the API specification for generating images from text prompts using an OpenAI-compatible endpoint, including details on request parameters and streaming options.",
      "tags": [
        "openai-api",
        "image-generation",
        "text-to-image",
        "ai-inference",
        "api-reference",
        "bifrost"
      ],
      "category": "api",
      "original_file_path": "api-reference-openai-integration-create-image.md"
    },
    {
      "file_path": "222-api-reference-openai-integration-create-response-azure-openai.md",
      "title": "Create response (Azure OpenAI)",
      "url": "https://docs.getbifrost.ai/api-reference/openai-integration/create-response-azure-openai.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:40:08.670227778-03:00",
      "description": "> To find navigation and other pages in this documentation, fetch the llms.txt file at: https://docs.getbifrost.ai/llms.txt",
      "summary": "This document provides the OpenAPI specification for creating responses through Azure OpenAI deployments using the Bifrost gateway.",
      "tags": [
        "azure-openai",
        "bifrost-api",
        "api-reference",
        "ai-inference",
        "openai-integration"
      ],
      "category": "api",
      "original_file_path": "api-reference-openai-integration-create-response-azure-openai.md"
    },
    {
      "file_path": "223-api-reference-openai-integration-create-response-openai-responses-api.md",
      "title": "Create response (OpenAI Responses API)",
      "url": "https://docs.getbifrost.ai/api-reference/openai-integration/create-response-openai-responses-api.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:40:09.046482341-03:00",
      "description": "> Creates a response using OpenAI Responses API format. Supports streaming via SSE.",
      "summary": "This document defines the API endpoint for creating responses using the OpenAI Responses API format, supporting both standard and streaming interactions through the Bifrost gateway.",
      "tags": [
        "openai-integration",
        "responses-api",
        "ai-inference",
        "streaming-sse",
        "bifrost-api",
        "rest-api"
      ],
      "category": "api",
      "original_file_path": "api-reference-openai-integration-create-response-openai-responses-api.md"
    },
    {
      "file_path": "226-api-reference-openai-integration-create-text-completion-azure-openai.md",
      "title": "Create text completion (Azure OpenAI)",
      "url": "https://docs.getbifrost.ai/api-reference/openai-integration/create-text-completion-azure-openai.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:40:12.671060333-03:00",
      "description": "> To find navigation and other pages in this documentation, fetch the llms.txt file at: https://docs.getbifrost.ai/llms.txt",
      "summary": "This document provides the API specification for generating text completions using Azure OpenAI deployments through the Bifrost gateway.",
      "tags": [
        "azure-openai",
        "text-completions",
        "openapi-spec",
        "ai-inference",
        "bifrost-gateway"
      ],
      "category": "api",
      "original_file_path": "api-reference-openai-integration-create-text-completion-azure-openai.md"
    },
    {
      "file_path": "225-api-reference-openai-integration-create-speech-openai-tts.md",
      "title": "Create speech (OpenAI TTS)",
      "url": "https://docs.getbifrost.ai/api-reference/openai-integration/create-speech-openai-tts.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:40:12.586995747-03:00",
      "description": "> Generates audio from text using OpenAI TTS. Supports streaming via SSE when stream_format is set to 'sse'.",
      "summary": "This document defines the OpenAI-compatible text-to-speech endpoint for converting text into audio, supporting various output formats and SSE streaming. It details the request parameters such as model selection, voice options, and speed control within the Bifrost API framework.",
      "tags": [
        "openai-tts",
        "text-to-speech",
        "audio-generation",
        "speech-synthesis",
        "api-endpoint",
        "streaming-audio"
      ],
      "category": "api",
      "original_file_path": "api-reference-openai-integration-create-speech-openai-tts.md"
    },
    {
      "file_path": "227-api-reference-openai-integration-create-text-completion-openai-format.md",
      "title": "Create text completion (OpenAI format)",
      "url": "https://docs.getbifrost.ai/api-reference/openai-integration/create-text-completion-openai-format.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:40:13.261065727-03:00",
      "description": "> Creates a text completion using OpenAI-compatible format. This is the legacy completions API.",
      "summary": "This document provides the specification for the OpenAI-compatible legacy text completions API endpoint used to generate text responses from model prompts.",
      "tags": [
        "openai-compatible",
        "text-completion",
        "api-reference",
        "inference",
        "bifrost-gateway"
      ],
      "category": "api",
      "original_file_path": "api-reference-openai-integration-create-text-completion-openai-format.md"
    },
    {
      "file_path": "228-api-reference-openai-integration-create-transcription-azure-openai.md",
      "title": "Create transcription (Azure OpenAI)",
      "url": "https://docs.getbifrost.ai/api-reference/openai-integration/create-transcription-azure-openai.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:40:13.486263749-03:00",
      "description": "> To find navigation and other pages in this documentation, fetch the llms.txt file at: https://docs.getbifrost.ai/llms.txt",
      "summary": "This document defines the API endpoint for transcribing audio files using Azure OpenAI models through the Bifrost gateway, detailing the required parameters and response structure.",
      "tags": [
        "azure-openai",
        "transcription",
        "audio-processing",
        "speech-to-text",
        "api-endpoint",
        "bifrost"
      ],
      "category": "api",
      "original_file_path": "api-reference-openai-integration-create-transcription-azure-openai.md"
    },
    {
      "file_path": "224-api-reference-openai-integration-create-speech-azure-openai-tts.md",
      "title": "Create speech (Azure OpenAI TTS)",
      "url": "https://docs.getbifrost.ai/api-reference/openai-integration/create-speech-azure-openai-tts.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:40:11.717249857-03:00",
      "description": "> To find navigation and other pages in this documentation, fetch the llms.txt file at: https://docs.getbifrost.ai/llms.txt",
      "summary": "This document defines the OpenAPI specification for generating audio from text using the Azure OpenAI Text-to-Speech (TTS) service through the Bifrost gateway.",
      "tags": [
        "azure-openai",
        "text-to-speech",
        "api-specification",
        "speech-synthesis",
        "audio-generation"
      ],
      "category": "api",
      "original_file_path": "api-reference-openai-integration-create-speech-azure-openai-tts.md"
    },
    {
      "file_path": "229-api-reference-openai-integration-create-transcription-openai-whisper.md",
      "title": "Create transcription (OpenAI Whisper)",
      "url": "https://docs.getbifrost.ai/api-reference/openai-integration/create-transcription-openai-whisper.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:40:17.488108828-03:00",
      "description": "> Transcribes audio into text using OpenAI Whisper.",
      "summary": "This document provides technical specifications for the OpenAI Whisper transcription endpoint, which enables converting audio files into text through the Bifrost API gateway.",
      "tags": [
        "openai-whisper",
        "audio-transcription",
        "speech-to-text",
        "api-endpoint",
        "bifrost-gateway"
      ],
      "category": "api",
      "original_file_path": "api-reference-openai-integration-create-transcription-openai-whisper.md"
    },
    {
      "file_path": "214-api-reference-openai-integration-get-file-content-openai-format.md",
      "title": "Get file content (OpenAI format)",
      "url": "https://docs.getbifrost.ai/api-reference/openai-integration/get-file-content-openai-format.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:40:18.142985677-03:00",
      "description": "> Retrieves the content of an uploaded file.",
      "summary": "This document describes the API endpoint for retrieving the binary content of an uploaded file using the OpenAI-compatible interface.",
      "tags": [
        "openai-integration",
        "file-management",
        "api-reference",
        "bifrost-gateway",
        "rest-api"
      ],
      "category": "api",
      "original_file_path": "api-reference-openai-integration-get-file-content-openai-format.md"
    },
    {
      "file_path": "216-api-reference-openai-integration-delete-file-openai-format.md",
      "title": "Delete file (OpenAI format)",
      "url": "https://docs.getbifrost.ai/api-reference/openai-integration/delete-file-openai-format.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:40:17.918799332-03:00",
      "description": "> Deletes an uploaded file.",
      "summary": "This document describes the API endpoint for deleting uploaded files using an OpenAI-compatible format within the Bifrost gateway. It details the required file ID parameter, optional provider specification, and the structure of the successful deletion response.",
      "tags": [
        "openai-integration",
        "file-management",
        "api-reference",
        "bifrost-gateway",
        "file-deletion"
      ],
      "category": "api",
      "original_file_path": "api-reference-openai-integration-delete-file-openai-format.md"
    },
    {
      "file_path": "208-api-reference-openai-integration-list-batch-jobs-openai-format.md",
      "title": "List batch jobs (OpenAI format)",
      "url": "https://docs.getbifrost.ai/api-reference/openai-integration/list-batch-jobs-openai-format.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:40:18.525172821-03:00",
      "description": "> Lists batch processing jobs.",
      "summary": "This document describes the API endpoint for listing batch processing jobs using the OpenAI-compatible format within the Bifrost gateway. It provides details on request parameters such as pagination and provider filtering, along with the expected response structure.",
      "tags": [
        "openai-integration",
        "batch-processing",
        "api-endpoint",
        "bifrost-gateway",
        "inference-api"
      ],
      "category": "api",
      "original_file_path": "api-reference-openai-integration-list-batch-jobs-openai-format.md"
    },
    {
      "file_path": "217-api-reference-openai-integration-list-files-openai-format.md",
      "title": "List files (OpenAI format)",
      "url": "https://docs.getbifrost.ai/api-reference/openai-integration/list-files-openai-format.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:40:19.085118443-03:00",
      "description": "> Lists uploaded files.",
      "summary": "This document describes the API endpoint for listing uploaded files using the OpenAI-compatible interface provided by the Bifrost gateway. It details the supported query parameters for filtering results and the schema for the returned file metadata.",
      "tags": [
        "openai-integration",
        "file-management",
        "api-reference",
        "bifrost-gateway",
        "file-listing"
      ],
      "category": "api",
      "original_file_path": "api-reference-openai-integration-list-files-openai-format.md"
    },
    {
      "file_path": "220-api-reference-openai-integration-list-models-azure-openai.md",
      "title": "List models (Azure OpenAI)",
      "url": "https://docs.getbifrost.ai/api-reference/openai-integration/list-models-azure-openai.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:40:21.457163808-03:00",
      "description": "> To find navigation and other pages in this documentation, fetch the llms.txt file at: https://docs.getbifrost.ai/llms.txt",
      "summary": "This document defines the API specification for listing models associated with a specific Azure OpenAI deployment through the Bifrost gateway. It details the required parameters and the structure of the returned model metadata.",
      "tags": [
        "azure-openai",
        "bifrost-api",
        "list-models",
        "api-reference",
        "model-deployment"
      ],
      "category": "api",
      "original_file_path": "api-reference-openai-integration-list-models-azure-openai.md"
    },
    {
      "file_path": "221-api-reference-openai-integration-list-models-openai-format.md",
      "title": "List models (OpenAI format)",
      "url": "https://docs.getbifrost.ai/api-reference/openai-integration/list-models-openai-format.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:40:21.932938372-03:00",
      "description": "> Lists available models in OpenAI format.",
      "summary": "This document describes the API endpoint used to retrieve a list of available AI models in an OpenAI-compatible format through the Bifrost gateway.",
      "tags": [
        "openai-integration",
        "model-listing",
        "bifrost-api",
        "api-reference",
        "inference-gateway"
      ],
      "category": "api",
      "original_file_path": "api-reference-openai-integration-list-models-openai-format.md"
    },
    {
      "file_path": "205-api-reference-openai-integration-retrieve-batch-job-openai-format.md",
      "title": "Retrieve batch job (OpenAI format)",
      "url": "https://docs.getbifrost.ai/api-reference/openai-integration/retrieve-batch-job-openai-format.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:40:22.69273242-03:00",
      "description": "> Retrieves details of a batch processing job.",
      "summary": "This document specifies the API endpoint for retrieving detailed information and status of a batch processing job using the OpenAI-compatible format.",
      "tags": [
        "openai-integration",
        "batch-processing",
        "api-reference",
        "bifrost-gateway",
        "batch-retrieval"
      ],
      "category": "api",
      "original_file_path": "api-reference-openai-integration-retrieve-batch-job-openai-format.md"
    },
    {
      "file_path": "215-api-reference-openai-integration-retrieve-file-metadata-openai-format.md",
      "title": "Retrieve file metadata (OpenAI format)",
      "url": "https://docs.getbifrost.ai/api-reference/openai-integration/retrieve-file-metadata-openai-format.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:40:23.724726284-03:00",
      "description": "> Retrieves metadata for an uploaded file.",
      "summary": "This document describes the API endpoint for retrieving metadata for an uploaded file using the OpenAI-compatible format. It outlines the path parameters, query options, and the detailed schema of the file information returned by the Bifrost gateway.",
      "tags": [
        "openai-integration",
        "file-management",
        "api-reference",
        "metadata-retrieval",
        "bifrost-api"
      ],
      "category": "api",
      "original_file_path": "api-reference-openai-integration-retrieve-file-metadata-openai-format.md"
    },
    {
      "file_path": "230-api-reference-openai-integration-upload-file-openai-format.md",
      "title": "Upload file (OpenAI format)",
      "url": "https://docs.getbifrost.ai/api-reference/openai-integration/upload-file-openai-format.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:40:25.711770718-03:00",
      "description": "> Uploads a file for use with batch processing or other features.",
      "summary": "This document specifies the API endpoint for uploading files in an OpenAI-compatible format to be used for batch processing, fine-tuning, and other AI tasks. It details the required request parameters, supported file purposes, and optional cloud storage configurations.",
      "tags": [
        "openai-integration",
        "file-upload",
        "api-reference",
        "batch-processing",
        "bifrost-api",
        "cloud-storage"
      ],
      "category": "api",
      "original_file_path": "api-reference-openai-integration-upload-file-openai-format.md"
    },
    {
      "file_path": "177-api-reference-plugins-create-a-new-plugin.md",
      "title": "Create a new plugin",
      "url": "https://docs.getbifrost.ai/api-reference/plugins/create-a-new-plugin.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:40:26.777277255-03:00",
      "description": "> Creates a new plugin with the specified configuration.",
      "summary": "This document defines the API endpoint and specification for creating a new plugin within the Bifrost AI gateway, including request parameters and response schemas.",
      "tags": [
        "bifrost-api",
        "plugin-management",
        "openapi-spec",
        "rest-api",
        "ai-gateway"
      ],
      "category": "api",
      "original_file_path": "api-reference-plugins-create-a-new-plugin.md"
    },
    {
      "file_path": "179-api-reference-plugins-delete-a-plugin.md",
      "title": "Delete a plugin",
      "url": "https://docs.getbifrost.ai/api-reference/plugins/delete-a-plugin.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:40:26.970582211-03:00",
      "description": "> Removes a plugin from the configuration and stops it if running.",
      "summary": "This document specifies the API endpoint for removing a plugin from the Bifrost configuration and stopping its execution.",
      "tags": [
        "bifrost-api",
        "plugin-management",
        "gateway-configuration",
        "api-endpoint"
      ],
      "category": "api",
      "original_file_path": "api-reference-plugins-delete-a-plugin.md"
    },
    {
      "file_path": "180-api-reference-plugins-get-a-specific-plugin.md",
      "title": "Get a specific plugin",
      "url": "https://docs.getbifrost.ai/api-reference/plugins/get-a-specific-plugin.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:40:27.981658687-03:00",
      "description": "> Returns the configuration for a specific plugin.",
      "summary": "This document provides the API specification for retrieving the configuration details of a specific plugin within the Bifrost AI gateway.",
      "tags": [
        "bifrost-api",
        "plugin-management",
        "openapi-spec",
        "endpoint-reference",
        "gateway-configuration"
      ],
      "category": "api",
      "original_file_path": "api-reference-plugins-get-a-specific-plugin.md"
    },
    {
      "file_path": "181-api-reference-plugins-list-all-plugins.md",
      "title": "List all plugins",
      "url": "https://docs.getbifrost.ai/api-reference/plugins/list-all-plugins.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:40:29.092361668-03:00",
      "description": "> Returns a list of all plugins with their configurations and status.",
      "summary": "This document describes the API endpoint for retrieving a complete list of installed plugins, including their configuration settings, status, and metadata.",
      "tags": [
        "bifrost-api",
        "plugin-management",
        "rest-api",
        "gateway-monitoring",
        "plugin-configuration"
      ],
      "category": "api",
      "original_file_path": "api-reference-plugins-list-all-plugins.md"
    },
    {
      "file_path": "178-api-reference-plugins-update-a-plugin.md",
      "title": "Update a plugin",
      "url": "https://docs.getbifrost.ai/api-reference/plugins/update-a-plugin.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:40:31.148578765-03:00",
      "description": "> Updates a plugin's configuration. Will reload or stop the plugin based on enabled status.",
      "summary": "This document defines the API endpoint for updating a plugin's configuration, which manages the plugin's enabled status, file path, and specific settings.",
      "tags": [
        "plugins",
        "api-endpoint",
        "configuration-management",
        "bifrost-api",
        "gateway-management"
      ],
      "category": "api",
      "original_file_path": "api-reference-plugins-update-a-plugin.md"
    },
    {
      "file_path": "183-api-reference-providers-delete-a-provider.md",
      "title": "Delete a provider",
      "url": "https://docs.getbifrost.ai/api-reference/providers/delete-a-provider.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:40:31.613561779-03:00",
      "description": "> Removes a provider from the configuration.",
      "summary": "This document specifies the API endpoint for removing an AI model provider from the Bifrost gateway configuration.",
      "tags": [
        "provider-management",
        "api-gateway",
        "configuration-api",
        "delete-endpoint",
        "bifrost-api"
      ],
      "category": "api",
      "original_file_path": "api-reference-providers-delete-a-provider.md"
    },
    {
      "file_path": "185-api-reference-providers-add-a-new-provider.md",
      "title": "Add a new provider",
      "url": "https://docs.getbifrost.ai/api-reference/providers/add-a-new-provider.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:40:31.400356553-03:00",
      "description": "> Adds a new provider with the specified configuration.",
      "summary": "This document describes the API endpoint for adding and configuring a new AI model provider within the Bifrost gateway system.",
      "tags": [
        "api-management",
        "provider-configuration",
        "ai-gateway",
        "endpoint-reference",
        "infrastructure"
      ],
      "category": "api",
      "original_file_path": "api-reference-providers-add-a-new-provider.md"
    },
    {
      "file_path": "184-api-reference-providers-get-a-specific-provider.md",
      "title": "Get a specific provider",
      "url": "https://docs.getbifrost.ai/api-reference/providers/get-a-specific-provider.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:40:33.160890095-03:00",
      "description": "> Returns the configuration for a specific provider.",
      "summary": "This document defines the API endpoint for retrieving configuration details, including API keys and model settings, for a specific AI provider within the Bifrost gateway.",
      "tags": [
        "bifrost-api",
        "provider-management",
        "api-configuration",
        "ai-gateway",
        "rest-endpoint"
      ],
      "category": "api",
      "original_file_path": "api-reference-providers-get-a-specific-provider.md"
    },
    {
      "file_path": "187-api-reference-providers-list-all-providers.md",
      "title": "List all providers",
      "url": "https://docs.getbifrost.ai/api-reference/providers/list-all-providers.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:40:35.531678868-03:00",
      "description": "> Returns a list of all configured providers with their configurations and status.",
      "summary": "This document defines the API endpoint for retrieving a list of all configured AI model providers, including their specific configurations, API keys, and operational status within the Bifrost gateway.",
      "tags": [
        "api-reference",
        "provider-management",
        "ai-gateway",
        "configuration-api",
        "model-providers"
      ],
      "category": "api",
      "original_file_path": "api-reference-providers-list-all-providers.md"
    },
    {
      "file_path": "186-api-reference-providers-list-all-keys.md",
      "title": "List all keys",
      "url": "https://docs.getbifrost.ai/api-reference/providers/list-all-keys.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:40:34.204322612-03:00",
      "description": "> Returns a list of all configured API keys across all providers.",
      "summary": "Describes the API endpoint for listing all configured API keys and their associated configurations across different providers in the Bifrost gateway.",
      "tags": [
        "api-keys",
        "provider-management",
        "gateway-management",
        "api-reference"
      ],
      "category": "api",
      "original_file_path": "api-reference-providers-list-all-keys.md"
    },
    {
      "file_path": "188-api-reference-providers-list-models.md",
      "title": "List models",
      "url": "https://docs.getbifrost.ai/api-reference/providers/list-models.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:40:36.467870029-03:00",
      "description": "> Lists available models with optional filtering by query, provider, or keys.",
      "summary": "This document defines the API endpoint for listing available AI models with support for filtering by provider, query string, and access keys.",
      "tags": [
        "api-reference",
        "model-management",
        "bifrost-gateway",
        "endpoint-specification",
        "ai-models"
      ],
      "category": "api",
      "original_file_path": "api-reference-providers-list-models.md"
    },
    {
      "file_path": "182-api-reference-providers-update-a-provider.md",
      "title": "Update a provider",
      "url": "https://docs.getbifrost.ai/api-reference/providers/update-a-provider.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:40:36.693216812-03:00",
      "description": "> Updates a provider's configuration. Expects ALL fields to be provided, including both edited and non-edited fields. Partial updates are not supported.",
      "summary": "This document describes the API endpoint for updating a provider's configuration in the Bifrost gateway, requiring a full replacement of all configuration fields.",
      "tags": [
        "bifrost-api",
        "provider-management",
        "api-reference",
        "configuration-update",
        "ai-gateway"
      ],
      "category": "api",
      "original_file_path": "api-reference-providers-update-a-provider.md"
    },
    {
      "file_path": "287-api-reference-pydanticai-integration-chat-completions-pydanticai-openai-format.md",
      "title": "Chat completions (PydanticAI - OpenAI format)",
      "url": "https://docs.getbifrost.ai/api-reference/pydanticai-integration/chat-completions-pydanticai--openai-format.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:40:38.468972597-03:00",
      "description": "> Creates a chat completion using OpenAI-compatible format via PydanticAI.",
      "summary": "This document provides the OpenAPI specification for the PydanticAI-compatible chat completions endpoint, enabling OpenAI-format requests through the Bifrost gateway.",
      "tags": [
        "pydanticai",
        "chat-completions",
        "openai-compatible",
        "bifrost-api",
        "inference",
        "api-specification"
      ],
      "category": "api",
      "original_file_path": "api-reference-pydanticai-integration-chat-completions-pydanticai-openai-format.md"
    },
    {
      "file_path": "288-api-reference-pydanticai-integration-chat-with-model-pydanticai-cohere-format.md",
      "title": "Chat with model (PydanticAI - Cohere format)",
      "url": "https://docs.getbifrost.ai/api-reference/pydanticai-integration/chat-with-model-pydanticai--cohere-format.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:40:40.874434289-03:00",
      "description": "> Sends a chat request using Cohere-compatible format via PydanticAI.",
      "summary": "This document provides the API specification for performing chat completions using the Cohere-compatible format through the PydanticAI framework integration.",
      "tags": [
        "pydanticai",
        "cohere",
        "chat-completions",
        "ai-inference",
        "api-gateway",
        "bifrost"
      ],
      "category": "api",
      "original_file_path": "api-reference-pydanticai-integration-chat-with-model-pydanticai-cohere-format.md"
    },
    {
      "file_path": "291-api-reference-pydanticai-integration-create-embeddings-pydanticai-cohere-format.md",
      "title": "Create embeddings (PydanticAI - Cohere format)",
      "url": "https://docs.getbifrost.ai/api-reference/pydanticai-integration/create-embeddings-pydanticai--cohere-format.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:40:42.43505547-03:00",
      "description": "> Creates embeddings using Cohere-compatible format via PydanticAI.",
      "summary": "This document defines the API specification for generating text and multimodal embeddings using a Cohere-compatible format through the PydanticAI framework integration.",
      "tags": [
        "pydantic-ai",
        "cohere",
        "embeddings",
        "api-reference",
        "multimodal",
        "bifrost-gateway"
      ],
      "category": "api",
      "original_file_path": "api-reference-pydanticai-integration-create-embeddings-pydanticai-cohere-format.md"
    },
    {
      "file_path": "290-api-reference-pydanticai-integration-count-input-tokens-pydanticai-openai-format.md",
      "title": "Count input tokens (PydanticAI - OpenAI format)",
      "url": "https://docs.getbifrost.ai/api-reference/pydanticai-integration/count-input-tokens-pydanticai--openai-format.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:40:41.936809858-03:00",
      "description": "> Counts the number of tokens in a Responses API request via PydanticAI.",
      "summary": "This document defines the API endpoint for counting input tokens in a PydanticAI-compatible Responses request within the Bifrost gateway.",
      "tags": [
        "pydanticai",
        "token-counting",
        "openai-format",
        "api-reference",
        "bifrost-api"
      ],
      "category": "api",
      "original_file_path": "api-reference-pydanticai-integration-count-input-tokens-pydanticai-openai-format.md"
    },
    {
      "file_path": "289-api-reference-pydanticai-integration-converse-with-model-pydanticai-bedrock-format.md",
      "title": "Converse with model (PydanticAI - Bedrock format)",
      "url": "https://docs.getbifrost.ai/api-reference/pydanticai-integration/converse-with-model-pydanticai--bedrock-format.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:40:41.778725713-03:00",
      "description": "> Sends messages using AWS Bedrock Converse-compatible format via PydanticAI.",
      "summary": "This API endpoint enables model interaction by sending messages in an AWS Bedrock Converse-compatible format via the PydanticAI integration. It provides a bridge for framework-specific inference using Bedrock's native message structure through the Bifrost gateway.",
      "tags": [
        "pydanticai",
        "aws-bedrock",
        "model-inference",
        "converse-api",
        "api-integration",
        "bifrost-gateway"
      ],
      "category": "api",
      "original_file_path": "api-reference-pydanticai-integration-converse-with-model-pydanticai-bedrock-format.md"
    },
    {
      "file_path": "292-api-reference-pydanticai-integration-create-embeddings-pydanticai-openai-format.md",
      "title": "Create embeddings (PydanticAI - OpenAI format)",
      "url": "https://docs.getbifrost.ai/api-reference/pydanticai-integration/create-embeddings-pydanticai--openai-format.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:40:44.177185885-03:00",
      "description": "> Creates embeddings using OpenAI-compatible format via PydanticAI.",
      "summary": "This document specifies the API endpoint for creating text embeddings using the PydanticAI framework in an OpenAI-compatible format.",
      "tags": [
        "embeddings",
        "pydanticai",
        "openai-compatible",
        "api-endpoint",
        "text-processing"
      ],
      "category": "api",
      "original_file_path": "api-reference-pydanticai-integration-create-embeddings-pydanticai-openai-format.md"
    },
    {
      "file_path": "294-api-reference-pydanticai-integration-create-message-pydanticai-anthropic-format.md",
      "title": "Create message (PydanticAI - Anthropic format)",
      "url": "https://docs.getbifrost.ai/api-reference/pydanticai-integration/create-message-pydanticai--anthropic-format.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:40:47.009925719-03:00",
      "description": "> Creates a message using Anthropic-compatible format via PydanticAI.",
      "summary": "This document defines the API endpoint for creating messages using an Anthropic-compatible format through the PydanticAI framework integration within the Bifrost gateway.",
      "tags": [
        "pydantic-ai",
        "anthropic",
        "api-gateway",
        "message-creation",
        "ai-inference",
        "framework-integration"
      ],
      "category": "api",
      "original_file_path": "api-reference-pydanticai-integration-create-message-pydanticai-anthropic-format.md"
    },
    {
      "file_path": "298-api-reference-pydanticai-integration-create-speech-pydanticai-openai-tts.md",
      "title": "Create speech (PydanticAI - OpenAI TTS)",
      "url": "https://docs.getbifrost.ai/api-reference/pydanticai-integration/create-speech-pydanticai--openai-tts.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:40:47.813384683-03:00",
      "description": "> Generates audio from text using OpenAI TTS via PydanticAI.",
      "summary": "This document provides the OpenAPI specification for the PydanticAI-compatible endpoint used to generate audio from text via OpenAI's Text-to-Speech models. It details the required parameters, supported voices, response formats, and streaming options for the speech synthesis API.",
      "tags": [
        "pydanticai",
        "openai-tts",
        "text-to-speech",
        "api-specification",
        "audio-generation",
        "bifrost-api"
      ],
      "category": "api",
      "original_file_path": "api-reference-pydanticai-integration-create-speech-pydanticai-openai-tts.md"
    },
    {
      "file_path": "293-api-reference-pydanticai-integration-generate-content-pydanticai-gemini-format.md",
      "title": "Generate content (PydanticAI - Gemini format)",
      "url": "https://docs.getbifrost.ai/api-reference/pydanticai-integration/generate-content-pydanticai--gemini-format.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:40:49.385319218-03:00",
      "description": "> Generates content using Google Gemini-compatible format via PydanticAI.",
      "summary": "This document defines the OpenAPI specification for generating content using the Google Gemini-compatible format through the PydanticAI integration in the Bifrost API gateway.",
      "tags": [
        "pydanticai",
        "google-gemini",
        "content-generation",
        "openapi",
        "ai-inference",
        "bifrost",
        "api-specification"
      ],
      "category": "api",
      "original_file_path": "api-reference-pydanticai-integration-generate-content-pydanticai-gemini-format.md"
    },
    {
      "file_path": "303-api-reference-pydanticai-integration-create-transcription-pydanticai-openai-whisper.md",
      "title": "Create transcription (PydanticAI - OpenAI Whisper)",
      "url": "https://docs.getbifrost.ai/api-reference/pydanticai-integration/create-transcription-pydanticai--openai-whisper.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:40:48.32559737-03:00",
      "description": "> Transcribes audio into text using OpenAI Whisper via PydanticAI.",
      "summary": "This document provides the OpenAPI specification for the PydanticAI-compatible endpoint used to transcribe audio files into text using OpenAI Whisper through the Bifrost gateway.",
      "tags": [
        "pydanticai",
        "openai-whisper",
        "audio-transcription",
        "speech-to-text",
        "api-specification",
        "bifrost-gateway"
      ],
      "category": "api",
      "original_file_path": "api-reference-pydanticai-integration-create-transcription-pydanticai-openai-whisper.md"
    },
    {
      "file_path": "297-api-reference-pydanticai-integration-create-response-pydanticai-openai-responses-api.md",
      "title": "Create response (PydanticAI - OpenAI Responses API)",
      "url": "https://docs.getbifrost.ai/api-reference/pydanticai-integration/create-response-pydanticai--openai-responses-api.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:40:47.64952315-03:00",
      "description": "> Creates a response using OpenAI Responses API format via PydanticAI. Supports streaming via SSE.",
      "summary": "This document defines the API endpoint for generating AI model responses using the PydanticAI framework with compatibility for the OpenAI Responses API format and SSE streaming.",
      "tags": [
        "pydantic-ai",
        "openai-responses",
        "ai-inference",
        "api-gateway",
        "sse-streaming",
        "bifrost-api"
      ],
      "category": "api",
      "original_file_path": "api-reference-pydanticai-integration-create-response-pydanticai-openai-responses-api.md"
    },
    {
      "file_path": "295-api-reference-pydanticai-integration-list-models-pydanticai-gemini-format.md",
      "title": "List models (PydanticAI - Gemini format)",
      "url": "https://docs.getbifrost.ai/api-reference/pydanticai-integration/list-models-pydanticai--gemini-format.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:40:51.059610029-03:00",
      "description": "> Lists available models in Google Gemini API format via PydanticAI.",
      "summary": "This document specifies the API endpoint for listing available AI models through the PydanticAI framework using the Google Gemini format within the Bifrost gateway.",
      "tags": [
        "pydantic-ai",
        "google-gemini",
        "model-listing",
        "bifrost-api",
        "api-integration"
      ],
      "category": "api",
      "original_file_path": "api-reference-pydanticai-integration-list-models-pydanticai-gemini-format.md"
    },
    {
      "file_path": "296-api-reference-pydanticai-integration-list-models-pydanticai-openai-format.md",
      "title": "List models (PydanticAI - OpenAI format)",
      "url": "https://docs.getbifrost.ai/api-reference/pydanticai-integration/list-models-pydanticai--openai-format.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:40:53.904730014-03:00",
      "description": "> Lists available models using OpenAI-compatible format via PydanticAI.",
      "summary": "This document specifies the API endpoint for retrieving a list of available AI models using the PydanticAI framework in an OpenAI-compatible format.",
      "tags": [
        "pydantic-ai",
        "openai-compatible",
        "model-listing",
        "api-specification",
        "bifrost-gateway"
      ],
      "category": "api",
      "original_file_path": "api-reference-pydanticai-integration-list-models-pydanticai-openai-format.md"
    },
    {
      "file_path": "300-api-reference-pydanticai-integration-stream-generate-content-pydanticai-gemini-format.md",
      "title": "Stream generate content (PydanticAI - Gemini format)",
      "url": "https://docs.getbifrost.ai/api-reference/pydanticai-integration/stream-generate-content-pydanticai--gemini-format.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:40:54.999385717-03:00",
      "description": "> Streams content generation using Google Gemini-compatible format via PydanticAI.",
      "summary": "This document provides the OpenAPI specification for the PydanticAI integration endpoint that enables streaming content generation using the Google Gemini format.",
      "tags": [
        "openapi",
        "pydanticai",
        "gemini",
        "streaming-api",
        "ai-inference",
        "content-generation"
      ],
      "category": "api",
      "original_file_path": "api-reference-pydanticai-integration-stream-generate-content-pydanticai-gemini-format.md"
    },
    {
      "file_path": "299-api-reference-pydanticai-integration-stream-converse-with-model-pydanticai-bedrock-format.md",
      "title": "Stream converse with model (PydanticAI - Bedrock format)",
      "url": "https://docs.getbifrost.ai/api-reference/pydanticai-integration/stream-converse-with-model-pydanticai--bedrock-format.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:40:54.737861212-03:00",
      "description": "> Streams messages using AWS Bedrock Converse-compatible format via PydanticAI.",
      "summary": "This document provides the OpenAPI specification for streaming model conversations using the AWS Bedrock Converse format through PydanticAI. It details the endpoint structure, request parameters, and supported content types for multi-modal interactions.",
      "tags": [
        "pydanticai",
        "aws-bedrock",
        "streaming-api",
        "openapi-spec",
        "conversational-ai"
      ],
      "category": "api",
      "original_file_path": "api-reference-pydanticai-integration-stream-converse-with-model-pydanticai-bedrock-format.md"
    },
    {
      "file_path": "301-api-reference-pydanticai-integration-text-completions-pydanticai-openai-format.md",
      "title": "Text completions (PydanticAI - OpenAI format)",
      "url": "https://docs.getbifrost.ai/api-reference/pydanticai-integration/text-completions-pydanticai--openai-format.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:40:55.477667798-03:00",
      "description": "> Creates a text completion using OpenAI-compatible format via PydanticAI. This is the legacy completions API.",
      "summary": "This document defines the PydanticAI-compatible endpoint for generating text completions using the legacy OpenAI-compatible format.",
      "tags": [
        "pydanticai",
        "openai-compatible",
        "text-completions",
        "api-gateway",
        "legacy-api"
      ],
      "category": "api",
      "original_file_path": "api-reference-pydanticai-integration-text-completions-pydanticai-openai-format.md"
    },
    {
      "file_path": "302-api-reference-pydanticai-integration-tokenize-text-pydanticai-cohere-format.md",
      "title": "Tokenize text (PydanticAI - Cohere format)",
      "url": "https://docs.getbifrost.ai/api-reference/pydanticai-integration/tokenize-text-pydanticai--cohere-format.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:40:56.610939595-03:00",
      "description": "> Tokenizes text using Cohere v1 API format via PydanticAI.",
      "summary": "This document defines the OpenAPI specification for tokenizing text using the Cohere v1 API format through the PydanticAI framework integration.",
      "tags": [
        "pydanticai",
        "cohere",
        "tokenization",
        "api-reference",
        "bifrost-gateway"
      ],
      "category": "api",
      "original_file_path": "api-reference-pydanticai-integration-tokenize-text-pydanticai-cohere-format.md"
    },
    {
      "file_path": "140-api-reference-responses-create-a-response.md",
      "title": "Create a response",
      "url": "https://docs.getbifrost.ai/api-reference/responses/create-a-response.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:40:58.869877382-03:00",
      "description": "> Creates a response using the OpenAI Responses API format. Supports streaming via SSE.",
      "summary": "This document describes the Bifrost API endpoint for creating AI model responses using the OpenAI Responses format, supporting multiple providers and server-sent events for streaming.",
      "tags": [
        "ai-inference",
        "openai-compatibility",
        "streaming-sse",
        "bifrost-api",
        "multi-provider-gateway"
      ],
      "category": "api",
      "original_file_path": "api-reference-responses-create-a-response.md"
    },
    {
      "file_path": "191-api-reference-session-logout.md",
      "title": "Logout",
      "url": "https://docs.getbifrost.ai/api-reference/session/logout.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:40:59.66127641-03:00",
      "description": "> Logs out the current user and invalidates the session token.",
      "summary": "This document defines the API endpoint for logging out a user and invalidating their current session token within the Bifrost platform.",
      "tags": [
        "session-management",
        "authentication",
        "api-endpoint",
        "user-logout",
        "security",
        "bifrost"
      ],
      "category": "api",
      "original_file_path": "api-reference-session-logout.md"
    },
    {
      "file_path": "189-api-reference-session-check-if-authentication-is-enabled.md",
      "title": "Check if authentication is enabled",
      "url": "https://docs.getbifrost.ai/api-reference/session/check-if-authentication-is-enabled.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:40:59.048266173-03:00",
      "description": "> Returns whether authentication is enabled and if the current token is valid.",
      "summary": "This document describes an API endpoint used to verify if authentication is enabled for the Bifrost gateway and check the validity of the current session token.",
      "tags": [
        "authentication",
        "session-management",
        "api-endpoint",
        "token-validation",
        "security",
        "bifrost-gateway"
      ],
      "category": "api",
      "original_file_path": "api-reference-session-check-if-authentication-is-enabled.md"
    },
    {
      "file_path": "190-api-reference-session-login.md",
      "title": "Login",
      "url": "https://docs.getbifrost.ai/api-reference/session/login.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:40:59.506654005-03:00",
      "description": "> Authenticates a user and returns a session token. Sets a cookie with the session token for subsequent requests.",
      "summary": "This document defines the login endpoint for the Bifrost API, detailing how to authenticate users and obtain session tokens for gateway management.",
      "tags": [
        "authentication",
        "session-management",
        "bifrost-api",
        "login-endpoint",
        "security"
      ],
      "category": "api",
      "original_file_path": "api-reference-session-login.md"
    },
    {
      "file_path": "141-api-reference-text-completions-create-a-text-completion.md",
      "title": "Create a text completion",
      "url": "https://docs.getbifrost.ai/api-reference/text-completions/create-a-text-completion.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:41:01.815984663-03:00",
      "description": "> Creates a completion for the provided prompt. Supports streaming via SSE.",
      "summary": "This document provides the API specification for creating text completions via the Bifrost unified interface, supporting multiple AI providers and streaming responses.",
      "tags": [
        "text-completions",
        "ai-inference",
        "api-reference",
        "streaming-sse",
        "unified-api",
        "llm-gateway"
      ],
      "category": "api",
      "original_file_path": "api-reference-text-completions-create-a-text-completion.md"
    },
    {
      "file_path": "102-architecture-core-mcp.md",
      "title": "Model Context Protocol (MCP)",
      "url": "https://docs.getbifrost.ai/architecture/core/mcp.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:41:04.842493355-03:00",
      "description": "> Deep dive into Bifrost's Model Context Protocol (MCP) integration - how external tool discovery, execution, and integration work internally.",
      "summary": "This document provides a technical deep dive into Bifrost's Model Context Protocol (MCP) architecture, explaining how external tools are discovered, connected, and executed. It details the various connection protocols, registration workflows, and filtering mechanisms used to integrate dynamic tools with AI models.",
      "tags": [
        "mcp-architecture",
        "tool-discovery",
        "connection-protocols",
        "runtime-registration",
        "access-control",
        "model-context-protocol",
        "agentic-tools"
      ],
      "category": "concept",
      "original_file_path": "architecture-core-mcp.md"
    },
    {
      "file_path": "103-architecture-core-plugins.md",
      "title": "Plugins",
      "url": "https://docs.getbifrost.ai/architecture/core/plugins.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:41:05.363035884-03:00",
      "description": "> Deep dive into Bifrost's extensible plugin architecture - how plugins work internally, lifecycle management, execution model, and integration patterns.",
      "summary": "This document provides a detailed overview of Bifrost's plugin architecture, covering its core design principles, lifecycle states, and request/response execution pipeline.",
      "tags": [
        "plugin-architecture",
        "lifecycle-management",
        "execution-pipeline",
        "bifrost",
        "software-extensibility",
        "request-processing"
      ],
      "category": "concept",
      "original_file_path": "architecture-core-plugins.md"
    },
    {
      "file_path": "101-architecture-core-concurrency.md",
      "title": "Concurrency",
      "url": "https://docs.getbifrost.ai/architecture/core/concurrency.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:41:04.133245346-03:00",
      "description": "> Deep dive into Bifrost's advanced concurrency architecture - worker pools, goroutine management, channel-based communication, and resource isolation patterns.",
      "summary": "This document explains Bifrost's advanced concurrency architecture, detailing its use of provider-isolated worker pools, Go channels, and backpressure mechanisms to ensure fault tolerance and performance.",
      "tags": [
        "concurrency",
        "worker-pools",
        "goroutines",
        "go-channels",
        "backpressure",
        "resource-management",
        "architecture"
      ],
      "category": "concept",
      "original_file_path": "architecture-core-concurrency.md"
    },
    {
      "file_path": "105-architecture-framework-config-store.md",
      "title": "Config Store",
      "url": "https://docs.getbifrost.ai/architecture/framework/config-store.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:41:07.646983951-03:00",
      "description": "> A persistent and flexible configuration management system for Bifrost, supporting multiple database backends.",
      "summary": "This document explains the Bifrost ConfigStore, a persistent configuration management system that provides a unified API for managing gateway settings across SQLite and PostgreSQL backends. It covers architecture, initialization, data models, and transactional operations for maintaining gateway state.",
      "tags": [
        "bifrost",
        "config-store",
        "configuration-management",
        "database-backend",
        "postgresql",
        "sqlite",
        "persistence",
        "gorm"
      ],
      "category": "reference",
      "original_file_path": "architecture-framework-config-store.md"
    },
    {
      "file_path": "104-architecture-core-request-flow.md",
      "title": "Request Flow",
      "url": "https://docs.getbifrost.ai/architecture/core/request-flow.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:41:05.769872392-03:00",
      "description": "> Deep dive into Bifrost's request processing pipeline - from transport layer ingestion through provider execution to response delivery.",
      "summary": "This document provides a technical deep dive into the Bifrost request processing pipeline, detailing the stages from transport layer ingestion and provider routing to plugin execution and memory management. It explains the architectural flow and performance characteristics of how requests are handled within the system.",
      "tags": [
        "bifrost-architecture",
        "request-flow",
        "load-balancing",
        "middleware-plugins",
        "mcp-integration",
        "memory-pooling",
        "performance-optimization"
      ],
      "category": "concept",
      "original_file_path": "architecture-core-request-flow.md"
    },
    {
      "file_path": "106-architecture-framework-log-store.md",
      "title": "Log Store",
      "url": "https://docs.getbifrost.ai/architecture/framework/log-store.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:41:09.212722047-03:00",
      "description": "> A robust and queryable system for persisting API request and response logs, with support for multiple database backends.",
      "summary": "This document explains the LogStore component of the Bifrost framework, which provides a persistent and queryable system for capturing API request and response logs across multiple database backends.",
      "tags": [
        "api-logging",
        "data-persistence",
        "observability",
        "bifrost-framework",
        "postgresql",
        "sqlite",
        "log-management"
      ],
      "category": "concept",
      "original_file_path": "architecture-framework-log-store.md"
    },
    {
      "file_path": "108-architecture-framework-streaming.md",
      "title": "Streaming",
      "url": "https://docs.getbifrost.ai/architecture/framework/streaming.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:41:10.462021481-03:00",
      "description": "> Framework utility for aggregating and processing real-time stream chunks from AI providers",
      "summary": "This document explains the Streaming package utility used to aggregate and process real-time AI stream chunks into structured responses for framework plugins.",
      "tags": [
        "streaming",
        "ai-providers",
        "data-aggregation",
        "bifrost-framework",
        "stream-processing",
        "accumulator"
      ],
      "category": "concept",
      "original_file_path": "architecture-framework-streaming.md"
    },
    {
      "file_path": "109-architecture-framework-vector-store.md",
      "title": "Vector Store",
      "url": "https://docs.getbifrost.ai/architecture/framework/vector-store.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:41:12.607249024-03:00",
      "description": "> Vector database implementations for semantic search, embeddings storage, and AI-powered features in Bifrost.",
      "summary": "This document explains the Bifrost Vector Store component, which provides a unified interface for storing embeddings and performing semantic similarity searches across multiple database backends.",
      "tags": [
        "vector-store",
        "semantic-search",
        "embeddings",
        "weaviate",
        "go-sdk",
        "vector-database",
        "similarity-search"
      ],
      "category": "guide",
      "original_file_path": "architecture-framework-vector-store.md"
    },
    {
      "file_path": "110-architecture-framework-what-is-framework.md",
      "title": "What is framework?",
      "url": "https://docs.getbifrost.ai/architecture/framework/what-is-framework.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:41:13.096859879-03:00",
      "description": "> Framework is Bifrost's shared storage and utilities SDK package that provides common database interfaces and logic for the plugin ecosystem.",
      "summary": "This document introduces the Bifrost Framework, a shared SDK that provides standardized storage interfaces and utility modules like ConfigStore and VectorStore for plugin development. It explains how the framework ensures consistency, data integrity, and reduced development overhead across the Bifrost ecosystem.",
      "tags": [
        "sdk",
        "bifrost-framework",
        "plugin-development",
        "data-storage",
        "configuration-management",
        "vector-store",
        "go-programming"
      ],
      "category": "concept",
      "original_file_path": "architecture-framework-what-is-framework.md"
    },
    {
      "file_path": "107-architecture-framework-model-catalog.md",
      "title": "Model Catalog",
      "url": "https://docs.getbifrost.ai/architecture/framework/model-catalog.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:41:10.274397391-03:00",
      "description": "> A centralized system for managing model information, pricing, and capabilities across all supported AI providers.",
      "summary": "This document explains the Model Catalog, a centralized system in Bifrost for managing AI model information, automated pricing synchronization, and multi-modal cost calculations.",
      "tags": [
        "model-catalog",
        "pricing-sync",
        "cost-calculation",
        "multi-modal",
        "model-management",
        "bifrost"
      ],
      "category": "concept",
      "original_file_path": "architecture-framework-model-catalog.md"
    },
    {
      "file_path": "112-benchmarking-run-your-own-benchmarks.md",
      "title": "Run Your Own Benchmarks",
      "url": "https://docs.getbifrost.ai/benchmarking/run-your-own-benchmarks.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:41:16.838952184-03:00",
      "description": "> Step-by-step guide to benchmark Bifrost in your own environment using the official benchmarking tool.",
      "summary": "This document provides instructions for using the official Bifrost benchmarking tool to measure performance across various infrastructure and workload scenarios. It covers installation, configuration flags, specific testing scenarios, and how to interpret performance metrics for instance sizing.",
      "tags": [
        "benchmarking",
        "performance-testing",
        "bifrost",
        "load-testing",
        "latency-metrics",
        "stress-testing",
        "go-tooling",
        "infrastructure-optimization"
      ],
      "category": "guide",
      "original_file_path": "benchmarking-run-your-own-benchmarks.md"
    },
    {
      "file_path": "111-benchmarking-getting-started.md",
      "title": "Getting Started",
      "url": "https://docs.getbifrost.ai/benchmarking/getting-started.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:41:16.648774705-03:00",
      "description": "> Introduction to Bifrost's performance capabilities and how to choose the right instance size for your workload.",
      "summary": "This document provides performance benchmark results for Bifrost across different AWS EC2 instance types and offers guidance on choosing the appropriate configuration for various workloads.",
      "tags": [
        "performance-benchmarks",
        "aws-ec2",
        "instance-sizing",
        "latency",
        "scalability",
        "load-testing"
      ],
      "category": "guide",
      "original_file_path": "benchmarking-getting-started.md"
    },
    {
      "file_path": "113-benchmarking-t3.medium.md",
      "title": "t3.medium",
      "url": "https://docs.getbifrost.ai/benchmarking/t3.medium.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:41:17.410967889-03:00",
      "description": "> Detailed performance metrics and analysis for Bifrost running on AWS t3.medium instances (2 vCPUs, 4GB RAM).",
      "summary": "This document provides performance benchmarks, resource utilization metrics, and configuration tuning recommendations for running Bifrost on AWS t3.medium instances.",
      "tags": [
        "aws-t3-medium",
        "performance-benchmarks",
        "latency-analysis",
        "resource-utilization",
        "bifrost-optimization",
        "ec2-performance"
      ],
      "category": "reference",
      "original_file_path": "benchmarking-t3.medium.md"
    },
    {
      "file_path": "114-benchmarking-t3.xl.md",
      "title": "t3.xlarge",
      "url": "https://docs.getbifrost.ai/benchmarking/t3.xl.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:41:17.973344797-03:00",
      "description": "> Detailed performance metrics and analysis for Bifrost running on AWS t3.xlarge instances (4 vCPUs, 16GB RAM).",
      "summary": "This document provides detailed performance benchmarks and resource utilization analysis for running Bifrost on AWS t3.xlarge instances. It outlines optimal configuration settings and compares efficiency metrics to help users scale and tune their infrastructure.",
      "tags": [
        "aws-t3-xlarge",
        "performance-benchmarks",
        "bifrost-optimization",
        "scalability-analysis",
        "infrastructure-tuning",
        "latency-metrics"
      ],
      "category": "reference",
      "original_file_path": "benchmarking-t3.xl.md"
    },
    {
      "file_path": "389-changelogs-v1.2.21.md",
      "title": "v1.2.21",
      "url": "https://docs.getbifrost.ai/changelogs/v1.2.21.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:41:18.271782117-03:00",
      "description": "> v1.2.21 changelog",
      "summary": "This document outlines the changes in Bifrost version 1.2.21, including fixes for pricing computation with nested model names and framework upgrades across several modules.",
      "tags": [
        "bifrost",
        "changelog",
        "release-notes",
        "bug-fix",
        "pricing-module",
        "framework-upgrade"
      ],
      "category": "reference",
      "original_file_path": "changelogs-v1.2.21.md"
    },
    {
      "file_path": "387-changelogs-v1.2.23.md",
      "title": "v1.2.23",
      "url": "https://docs.getbifrost.ai/changelogs/v1.2.23.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:41:22.90052484-03:00",
      "description": "> v1.2.23 changelog",
      "summary": "This document details the release notes and changelog for version 1.2.23 of the Bifrost platform, including bug fixes and dependency updates across multiple modules.",
      "tags": [
        "changelog",
        "release-notes",
        "bifrost",
        "software-update",
        "bug-fixes",
        "version-1-2-23"
      ],
      "category": "reference",
      "original_file_path": "changelogs-v1.2.23.md"
    },
    {
      "file_path": "388-changelogs-v1.2.22.md",
      "title": "v1.2.22",
      "url": "https://docs.getbifrost.ai/changelogs/v1.2.22.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:41:22.64354558-03:00",
      "description": "> v1.2.22 changelog",
      "summary": "This document provides the release notes for Bifrost version 1.2.22, detailing bug fixes for streaming responses and UI components alongside various module dependency upgrades.",
      "tags": [
        "release-notes",
        "changelog",
        "bifrost",
        "bug-fixes",
        "version-update",
        "streaming-responses"
      ],
      "category": "other",
      "original_file_path": "changelogs-v1.2.22.md"
    },
    {
      "file_path": "385-changelogs-v1.3.0-prerelease1.md",
      "title": "v1.3.0-prerelease1",
      "url": "https://docs.getbifrost.ai/changelogs/v1.3.0-prerelease1.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:41:23.409781461-03:00",
      "description": "> v1.3.0-prerelease1 changelog",
      "summary": "This document provides the changelog for Bifrost version 1.3.0-prerelease1, detailing new features, bug fixes, and breaking changes across core modules and plugins.",
      "tags": [
        "changelog",
        "release-notes",
        "bifrost",
        "observability",
        "otlp",
        "plugin-management",
        "streaming-responses"
      ],
      "category": "reference",
      "original_file_path": "changelogs-v1.3.0-prerelease1.md"
    },
    {
      "file_path": "378-changelogs-v1.3.0.md",
      "title": "v1.3.0",
      "url": "https://docs.getbifrost.ai/changelogs/v1.3.0.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:41:23.221239883-03:00",
      "description": "> v1.3.0 changelog",
      "summary": "This document outlines the version 1.3.0 release notes for Bifrost, detailing new features like OpenTelemetry support, OpenAI-style response formats, and enterprise guardrails. It also lists various bug fixes, performance improvements, and dependency updates for the platform's core components.",
      "tags": [
        "changelog",
        "release-notes",
        "bifrost",
        "opentelemetry",
        "api-gateway",
        "version-update",
        "llm-observability"
      ],
      "category": "reference",
      "original_file_path": "changelogs-v1.3.0.md"
    },
    {
      "file_path": "384-changelogs-v1.3.0-prerelease2.md",
      "title": "v1.3.0-prerelease2",
      "url": "https://docs.getbifrost.ai/changelogs/v1.3.0-prerelease2.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:41:27.8747263-03:00",
      "description": "> v1.3.0-prerelease2 changelog",
      "summary": "This document outlines the release notes and installation instructions for Bifrost version 1.3.0-prerelease2, highlighting new features such as text completion streaming and improved error handling.",
      "tags": [
        "release-notes",
        "bifrost",
        "text-completion",
        "streaming-support",
        "error-handling",
        "changelog"
      ],
      "category": "reference",
      "original_file_path": "changelogs-v1.3.0-prerelease2.md"
    },
    {
      "file_path": "386-changelogs-v1.2.24.md",
      "title": "v1.2.24",
      "url": "https://docs.getbifrost.ai/changelogs/v1.2.24.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:41:22.897888705-03:00",
      "description": "> v1.2.24 changelog",
      "summary": "This document details the updates and bug fixes for Bifrost version 1.2.24, including component upgrades and UI improvements. It provides instructions for pulling and running the specific version via NPX and Docker.",
      "tags": [
        "release-notes",
        "changelog",
        "bifrost",
        "version-update",
        "bug-fixes",
        "docker"
      ],
      "category": "other",
      "original_file_path": "changelogs-v1.2.24.md"
    },
    {
      "file_path": "382-changelogs-v1.3.0-prerelease4.md",
      "title": "v1.3.0-prerelease4",
      "url": "https://docs.getbifrost.ai/changelogs/v1.3.0-prerelease4.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:41:29.387196149-03:00",
      "description": "> v1.3.0-prerelease4 changelog",
      "summary": "This document outlines the changes and installation steps for Bifrost version 1.3.0-prerelease4, featuring a new LiteLLM fallback for Groq and various core component upgrades.",
      "tags": [
        "bifrost",
        "changelog",
        "release-notes",
        "groq",
        "litellm",
        "version-update",
        "docker"
      ],
      "category": "reference",
      "original_file_path": "changelogs-v1.3.0-prerelease4.md"
    },
    {
      "file_path": "381-changelogs-v1.3.0-prerelease5.md",
      "title": "v1.3.0-prerelease5",
      "url": "https://docs.getbifrost.ai/changelogs/v1.3.0-prerelease5.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:41:30.864138076-03:00",
      "description": "> v1.3.0-prerelease5 changelog",
      "summary": "This document outlines the changes and updates included in the v1.3.0-prerelease5 release of Bifrost, specifically detailing bug fixes for Anthropic tool aggregation and new logging features.",
      "tags": [
        "release-notes",
        "changelog",
        "bifrost",
        "anthropic",
        "logging",
        "version-update"
      ],
      "category": "reference",
      "original_file_path": "changelogs-v1.3.0-prerelease5.md"
    },
    {
      "file_path": "383-changelogs-v1.3.0-prerelease3.md",
      "title": "v1.3.0-prerelease3",
      "url": "https://docs.getbifrost.ai/changelogs/v1.3.0-prerelease3.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:41:28.590902172-03:00",
      "description": "> v1.3.0-prerelease3 changelog",
      "summary": "This document provides the changelog for Bifrost version 1.3.0-prerelease3, detailing bug fixes for string inputs and new features for OpenAI integration.",
      "tags": [
        "bifrost",
        "release-notes",
        "changelog",
        "openai-integration",
        "bug-fixes"
      ],
      "category": "other",
      "original_file_path": "changelogs-v1.3.0-prerelease3.md"
    },
    {
      "file_path": "380-changelogs-v1.3.0-prerelease6.md",
      "title": "v1.3.0-prerelease6",
      "url": "https://docs.getbifrost.ai/changelogs/v1.3.0-prerelease6.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:41:33.285841752-03:00",
      "description": "> v1.3.0-prerelease6 changelog",
      "summary": "This document outlines the changes and new features in the v1.3.0-prerelease6 update for Bifrost, including Anthropic integration, enhanced latency metrics, and plugin interface extensions.",
      "tags": [
        "release-notes",
        "changelog",
        "bifrost",
        "anthropic-integration",
        "latency-tracking",
        "software-update"
      ],
      "category": "reference",
      "original_file_path": "changelogs-v1.3.0-prerelease6.md"
    },
    {
      "file_path": "379-changelogs-v1.3.0-prerelease7.md",
      "title": "v1.3.0-prerelease7",
      "url": "https://docs.getbifrost.ai/changelogs/v1.3.0-prerelease7.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:41:33.345502964-03:00",
      "description": "> v1.3.0-prerelease7 changelog",
      "summary": "Detailed changelog for Bifrost v1.3.0-prerelease7, highlighting new streaming capabilities, telemetry fixes, and core dependency upgrades.",
      "tags": [
        "bifrost",
        "release-notes",
        "changelog",
        "streaming",
        "telemetry",
        "bedrock"
      ],
      "category": "reference",
      "original_file_path": "changelogs-v1.3.0-prerelease7.md"
    },
    {
      "file_path": "377-changelogs-v1.3.1.md",
      "title": "v1.3.1",
      "url": "https://docs.getbifrost.ai/changelogs/v1.3.1.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:41:35.078533559-03:00",
      "description": "> v1.3.1 changelog",
      "summary": "Detailed release notes for Bifrost version 1.3.1, covering installation steps and specific updates across various core modules and dependencies.",
      "tags": [
        "bifrost",
        "changelog",
        "release-notes",
        "bug-fixes",
        "dependency-upgrades",
        "docker",
        "npx"
      ],
      "category": "other",
      "original_file_path": "changelogs-v1.3.1.md"
    },
    {
      "file_path": "367-changelogs-v1.3.11.md",
      "title": "v1.3.11",
      "url": "https://docs.getbifrost.ai/changelogs/v1.3.11.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:41:37.915508389-03:00",
      "description": "> v1.3.11 changelog",
      "summary": "This document details the release notes for Bifrost version 1.3.11, highlighting new features such as the models endpoint and core framework updates.",
      "tags": [
        "release-notes",
        "bifrost",
        "version-update",
        "api-changes",
        "deployment"
      ],
      "category": "other",
      "original_file_path": "changelogs-v1.3.11.md"
    },
    {
      "file_path": "368-changelogs-v1.3.10.md",
      "title": "v1.3.10",
      "url": "https://docs.getbifrost.ai/changelogs/v1.3.10.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:41:36.289241247-03:00",
      "description": "> v1.3.10 changelog",
      "summary": "This document provides the version 1.3.10 changelog for Bifrost, detailing new features, performance improvements, and bug fixes across core modules and provider integrations.",
      "tags": [
        "release-notes",
        "changelog",
        "bifrost",
        "otel",
        "vertex-api",
        "version-update",
        "bug-fixes"
      ],
      "category": "other",
      "original_file_path": "changelogs-v1.3.10.md"
    },
    {
      "file_path": "365-changelogs-v1.3.13.md",
      "title": "v1.3.13",
      "url": "https://docs.getbifrost.ai/changelogs/v1.3.13.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:41:40.586264176-03:00",
      "description": "> v1.3.13 changelog",
      "summary": "This document provides the release notes and changelog for Bifrost version 1.3.13, detailing new features like provider config hot reloading and environment variable support for Postgres.",
      "tags": [
        "bifrost",
        "release-notes",
        "changelog",
        "versioning",
        "deployment",
        "hot-reloading"
      ],
      "category": "reference",
      "original_file_path": "changelogs-v1.3.13.md"
    },
    {
      "file_path": "364-changelogs-v1.3.14.md",
      "title": "v1.3.14",
      "url": "https://docs.getbifrost.ai/changelogs/v1.3.14.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:41:42.335806237-03:00",
      "description": "> v1.3.14 changelog",
      "summary": "This document provides the release notes for Bifrost version 1.3.14, detailing new features such as dynamic plugins and authentication support alongside various performance improvements and bug fixes.",
      "tags": [
        "release-notes",
        "changelog",
        "bifrost",
        "software-update",
        "authentication",
        "dynamic-plugins",
        "deployment"
      ],
      "category": "reference",
      "original_file_path": "changelogs-v1.3.14.md"
    },
    {
      "file_path": "363-changelogs-v1.3.15.md",
      "title": "v1.3.15",
      "url": "https://docs.getbifrost.ai/changelogs/v1.3.15.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:41:43.402082901-03:00",
      "description": "> v1.3.15 changelog",
      "summary": "This document provides the release notes and changelog for version v1.3.15 of the Bifrost platform, detailing installation methods and module-specific updates.",
      "tags": [
        "release-notes",
        "changelog",
        "bifrost",
        "version-update",
        "docker-installation",
        "backend-framework"
      ],
      "category": "reference",
      "original_file_path": "changelogs-v1.3.15.md"
    },
    {
      "file_path": "366-changelogs-v1.3.12.md",
      "title": "v1.3.12",
      "url": "https://docs.getbifrost.ai/changelogs/v1.3.12.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:41:38.234912406-03:00",
      "description": "> v1.3.12 changelog",
      "summary": "This document provides the release notes for Bifrost version 1.3.12, detailing new features such as Azure native response support, asynchronous plugin operations, and provider-level budget management.",
      "tags": [
        "release-notes",
        "changelog",
        "bifrost-updates",
        "azure-integration",
        "async-processing",
        "rate-limiting"
      ],
      "category": "other",
      "original_file_path": "changelogs-v1.3.12.md"
    },
    {
      "file_path": "362-changelogs-v1.3.16.md",
      "title": "v1.3.16",
      "url": "https://docs.getbifrost.ai/changelogs/v1.3.16.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:41:43.944531474-03:00",
      "description": "> v1.3.16 changelog",
      "summary": "This document details the updates in version 1.3.16 of Bifrost, highlighting new provider support for Perplexity and MistralAI, and enhancements to Anthropic stream handling.",
      "tags": [
        "changelog",
        "bifrost",
        "release-notes",
        "perplexity",
        "mistralai",
        "anthropic",
        "vertex-ai"
      ],
      "category": "other",
      "original_file_path": "changelogs-v1.3.16.md"
    },
    {
      "file_path": "361-changelogs-v1.3.17.md",
      "title": "v1.3.17",
      "url": "https://docs.getbifrost.ai/changelogs/v1.3.17.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:41:46.701439006-03:00",
      "description": "> v1.3.17 changelog",
      "summary": "This document provides the release notes and installation commands for Bifrost version 1.3.17, covering bug fixes for virtual keys and framework updates.",
      "tags": [
        "changelog",
        "release-notes",
        "bifrost",
        "version-update",
        "docker",
        "npx"
      ],
      "category": "other",
      "original_file_path": "changelogs-v1.3.17.md"
    },
    {
      "file_path": "360-changelogs-v1.3.18.md",
      "title": "v1.3.18",
      "url": "https://docs.getbifrost.ai/changelogs/v1.3.18.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:41:47.903204284-03:00",
      "description": "> v1.3.18 changelog",
      "summary": "This document outlines the updates and bug fixes introduced in Bifrost version 1.3.18, including changes to the health endpoint, framework fixes, and module version updates.",
      "tags": [
        "bifrost",
        "changelog",
        "release-notes",
        "v1-3-18",
        "deployment",
        "bug-fixes"
      ],
      "category": "other",
      "original_file_path": "changelogs-v1.3.18.md"
    },
    {
      "file_path": "359-changelogs-v1.3.19.md",
      "title": "v1.3.19",
      "url": "https://docs.getbifrost.ai/changelogs/v1.3.19.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:41:48.43523629-03:00",
      "description": "> v1.3.19 changelog",
      "summary": "This document provides the release notes for Bifrost version v1.3.19, detailing new features in telemetry metrics, logging enhancements, and updates to the core framework components.",
      "tags": [
        "changelog",
        "release-notes",
        "bifrost",
        "telemetry",
        "logging",
        "mcp-client",
        "version-update"
      ],
      "category": "reference",
      "original_file_path": "changelogs-v1.3.19.md"
    },
    {
      "file_path": "376-changelogs-v1.3.2.md",
      "title": "v1.3.2",
      "url": "https://docs.getbifrost.ai/changelogs/v1.3.2.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:41:49.581166367-03:00",
      "description": "> v1.3.2 changelog",
      "summary": "This document outlines the changes in Bifrost version 1.3.2, including major refactoring of context keys, bug fixes for trace identification, and dependency updates across core modules.",
      "tags": [
        "release-notes",
        "changelog",
        "bifrost",
        "version-update",
        "bug-fix",
        "refactoring"
      ],
      "category": "reference",
      "original_file_path": "changelogs-v1.3.2.md"
    },
    {
      "file_path": "357-changelogs-v1.3.21.md",
      "title": "v1.3.21",
      "url": "https://docs.getbifrost.ai/changelogs/v1.3.21.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:41:53.402022225-03:00",
      "description": "> v1.3.21 changelog",
      "summary": "This document details the changelog and deployment commands for Bifrost version 1.3.21, including bug fixes for session handlers and new integration tests.",
      "tags": [
        "bifrost",
        "changelog",
        "version-update",
        "http-proxy",
        "bug-fix",
        "docker",
        "npx"
      ],
      "category": "reference",
      "original_file_path": "changelogs-v1.3.21.md"
    },
    {
      "file_path": "358-changelogs-v1.3.20.md",
      "title": "v1.3.20",
      "url": "https://docs.getbifrost.ai/changelogs/v1.3.20.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:41:51.641741008-03:00",
      "description": "> v1.3.20 changelog",
      "summary": "This document provides release notes and installation instructions for Bifrost version 1.3.20, including a bug fix for configuration store handling in session and plugin handlers.",
      "tags": [
        "bifrost",
        "release-notes",
        "changelog",
        "bug-fix",
        "docker",
        "npx"
      ],
      "category": "reference",
      "original_file_path": "changelogs-v1.3.20.md"
    },
    {
      "file_path": "355-changelogs-v1.3.23.md",
      "title": "v1.3.23",
      "url": "https://docs.getbifrost.ai/changelogs/v1.3.23.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:41:53.551691932-03:00",
      "description": "> v1.3.23 changelog - 2025-11-10",
      "summary": "This document outlines the release notes and changelog for version 1.3.23 of the Bifrost platform, detailing new features, breaking changes, and component updates.",
      "tags": [
        "release-notes",
        "changelog",
        "bifrost",
        "mcp-client",
        "gemini-integration",
        "software-update"
      ],
      "category": "reference",
      "original_file_path": "changelogs-v1.3.23.md"
    },
    {
      "file_path": "354-changelogs-v1.3.24.md",
      "title": "v1.3.24",
      "url": "https://docs.getbifrost.ai/changelogs/v1.3.24.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:41:55.704923706-03:00",
      "description": "> v1.3.24 changelog - 2025-11-11",
      "summary": "This document provides the changelog for Bifrost version 1.3.24, detailing core and framework updates, logging improvements, and installation instructions via NPX and Docker.",
      "tags": [
        "release-notes",
        "changelog",
        "bifrost",
        "software-update",
        "docker",
        "npx",
        "version-history"
      ],
      "category": "reference",
      "original_file_path": "changelogs-v1.3.24.md"
    },
    {
      "file_path": "356-changelogs-v1.3.22.md",
      "title": "v1.3.22",
      "url": "https://docs.getbifrost.ai/changelogs/v1.3.22.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:41:53.497802758-03:00",
      "description": "> v1.3.22 changelog - 2025-11-09",
      "summary": "This document provides the release notes for Bifrost version 1.3.22, detailing new features, breaking changes, and module updates across the platform.",
      "tags": [
        "changelog",
        "release-notes",
        "bifrost",
        "version-update",
        "software-maintenance"
      ],
      "category": "reference",
      "original_file_path": "changelogs-v1.3.22.md"
    },
    {
      "file_path": "353-changelogs-v1.3.25.md",
      "title": "v1.3.25",
      "url": "https://docs.getbifrost.ai/changelogs/v1.3.25.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:41:58.992461668-03:00",
      "description": "> v1.3.25 changelog - 2025-11-14",
      "summary": "This document provides the release notes for Bifrost version 1.3.25, detailing updates to the core engine, framework, and provider integrations such as Vertex AI and OpenRouter. Key features include unified streaming lifecycle events, pricing data in model lists, and enhanced authentication options.",
      "tags": [
        "changelog",
        "release-notes",
        "bifrost",
        "vertex-ai",
        "streaming-events",
        "api-updates"
      ],
      "category": "other",
      "original_file_path": "changelogs-v1.3.25.md"
    },
    {
      "file_path": "352-changelogs-v1.3.26.md",
      "title": "v1.3.26",
      "url": "https://docs.getbifrost.ai/changelogs/v1.3.26.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:41:59.404878292-03:00",
      "description": "> v1.3.26 changelog - 2025-11-16",
      "summary": "This document outlines the changes in version 1.3.26, featuring the addition of Elevenlabs provider support, security fixes for CORS settings, and various module dependency updates.",
      "tags": [
        "release-notes",
        "changelog",
        "elevenlabs-integration",
        "bifrost-update",
        "version-v1-3-26",
        "deployment"
      ],
      "category": "other",
      "original_file_path": "changelogs-v1.3.26.md"
    },
    {
      "file_path": "351-changelogs-v1.3.27.md",
      "title": "v1.3.27",
      "url": "https://docs.getbifrost.ai/changelogs/v1.3.27.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:42:00.494026511-03:00",
      "description": "> v1.3.27 changelog - 2025-11-17",
      "summary": "This document provides the release notes for Bifrost version 1.3.27, detailing fixes for Bedrock memory and streaming response parsing alongside dependency updates across various modules.",
      "tags": [
        "bifrost",
        "changelog",
        "release-notes",
        "bedrock",
        "bug-fixes",
        "version-update"
      ],
      "category": "other",
      "original_file_path": "changelogs-v1.3.27.md"
    },
    {
      "file_path": "350-changelogs-v1.3.28.md",
      "title": "v1.3.28",
      "url": "https://docs.getbifrost.ai/changelogs/v1.3.28.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:42:01.503364388-03:00",
      "description": "> v1.3.28 changelog - 2025-11-18",
      "summary": "This document outlines the v1.3.28 release notes for Bifrost, detailing performance optimizations for log processing on SQLite and framework updates across various internal modules.",
      "tags": [
        "changelog",
        "release-notes",
        "bifrost",
        "performance-optimization",
        "sqlite",
        "log-management",
        "version-update"
      ],
      "category": "reference",
      "original_file_path": "changelogs-v1.3.28.md"
    },
    {
      "file_path": "349-changelogs-v1.3.29.md",
      "title": "v1.3.29",
      "url": "https://docs.getbifrost.ai/changelogs/v1.3.29.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:42:02.064131779-03:00",
      "description": "> v1.3.29 changelog - 2025-11-18",
      "summary": "This document provides the release notes and changelog for version 1.3.29 of the Bifrost platform, detailing bug fixes and new features across various core components and plugins.",
      "tags": [
        "changelog",
        "release-notes",
        "bifrost",
        "metrics",
        "opentelemetry",
        "bug-fixes"
      ],
      "category": "reference",
      "original_file_path": "changelogs-v1.3.29.md"
    },
    {
      "file_path": "348-changelogs-v1.3.30.md",
      "title": "v1.3.30",
      "url": "https://docs.getbifrost.ai/changelogs/v1.3.30.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:42:05.133106241-03:00",
      "description": "> v1.3.30 changelog - 2025-11-18",
      "summary": "This document outlines the changes in version 1.3.30 of Bifrost, including database migrations for the provider column and framework updates across multiple modules.",
      "tags": [
        "changelog",
        "release-notes",
        "bifrost",
        "database-migration",
        "version-update"
      ],
      "category": "other",
      "original_file_path": "changelogs-v1.3.30.md"
    },
    {
      "file_path": "375-changelogs-v1.3.3.md",
      "title": "v1.3.3",
      "url": "https://docs.getbifrost.ai/changelogs/v1.3.3.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:42:05.11400697-03:00",
      "description": "> v1.3.3 changelog",
      "summary": "This document details the changelog for version 1.3.3 of the Bifrost platform, highlighting bug fixes for JSON serialization and core dependency updates across various modules.",
      "tags": [
        "changelog",
        "release-notes",
        "bifrost",
        "version-update",
        "bug-fix",
        "json-serialization"
      ],
      "category": "reference",
      "original_file_path": "changelogs-v1.3.3.md"
    },
    {
      "file_path": "346-changelogs-v1.3.32.md",
      "title": "v1.3.32",
      "url": "https://docs.getbifrost.ai/changelogs/v1.3.32.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:42:07.064060757-03:00",
      "description": "> v1.3.32 changelog - 2025-11-20",
      "summary": "This document outlines the version 1.3.32 changelog for Bifrost, detailing new features for Anthropic and Gemini providers alongside various bug fixes and component updates.",
      "tags": [
        "release-notes",
        "changelog",
        "bifrost",
        "anthropic-integration",
        "gemini-integration",
        "version-update",
        "bug-fixes"
      ],
      "category": "reference",
      "original_file_path": "changelogs-v1.3.32.md"
    },
    {
      "file_path": "347-changelogs-v1.3.31.md",
      "title": "v1.3.31",
      "url": "https://docs.getbifrost.ai/changelogs/v1.3.31.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:42:06.491138573-03:00",
      "description": "> v1.3.31 changelog - 2025-11-19",
      "summary": "This document outlines the release notes and update details for Bifrost version 1.3.31, including installation methods and module-specific bug fixes.",
      "tags": [
        "changelog",
        "release-notes",
        "bifrost",
        "version-update",
        "bug-fixes",
        "docker",
        "npx"
      ],
      "category": "other",
      "original_file_path": "changelogs-v1.3.31.md"
    },
    {
      "file_path": "344-changelogs-v1.3.34.md",
      "title": "v1.3.34",
      "url": "https://docs.getbifrost.ai/changelogs/v1.3.34.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:42:09.89083236-03:00",
      "description": "> v1.3.34 changelog - 2025-11-21",
      "summary": "This document outlines the release notes and changelog for Bifrost version 1.3.34, detailing feature updates, bug fixes, and dependency upgrades across various components.",
      "tags": [
        "release-notes",
        "changelog",
        "bifrost",
        "version-update",
        "software-maintenance"
      ],
      "category": "reference",
      "original_file_path": "changelogs-v1.3.34.md"
    },
    {
      "file_path": "345-changelogs-v1.3.33.md",
      "title": "v1.3.33",
      "url": "https://docs.getbifrost.ai/changelogs/v1.3.33.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:42:07.762820251-03:00",
      "description": "> v1.3.33 changelog - 2025-11-21",
      "summary": "This document outlines the updates and bug fixes in version 1.3.33 of Bifrost, including new log retention settings and improved handling of cached tokens for Anthropic and Bedrock.",
      "tags": [
        "release-notes",
        "changelog",
        "log-management",
        "token-caching",
        "bifrost"
      ],
      "category": "reference",
      "original_file_path": "changelogs-v1.3.33.md"
    },
    {
      "file_path": "343-changelogs-v1.3.35.md",
      "title": "v1.3.35",
      "url": "https://docs.getbifrost.ai/changelogs/v1.3.35.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:42:10.747706903-03:00",
      "description": "> v1.3.35 changelog - 2025-11-24",
      "summary": "This document outlines the updates and bug fixes for Bifrost version 1.3.35, including new support for Qdrant Vector Search and various streaming response improvements.",
      "tags": [
        "changelog",
        "release-notes",
        "qdrant",
        "vector-search",
        "bug-fixes",
        "streaming"
      ],
      "category": "reference",
      "original_file_path": "changelogs-v1.3.35.md"
    },
    {
      "file_path": "342-changelogs-v1.3.36.md",
      "title": "v1.3.36",
      "url": "https://docs.getbifrost.ai/changelogs/v1.3.36.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:42:11.776427035-03:00",
      "description": "> v1.3.36 changelog - 2025-11-25",
      "summary": "This document provides the changelog and release notes for Bifrost version 1.3.36, detailing new features, bug fixes, and module-specific framework updates.",
      "tags": [
        "changelog",
        "release-notes",
        "bifrost",
        "bug-fixes",
        "version-update",
        "opus-support"
      ],
      "category": "reference",
      "original_file_path": "changelogs-v1.3.36.md"
    },
    {
      "file_path": "341-changelogs-v1.3.37.md",
      "title": "v1.3.37",
      "url": "https://docs.getbifrost.ai/changelogs/v1.3.37.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:42:12.065980356-03:00",
      "description": "> v1.3.37 changelog - 2025-11-28",
      "summary": "This document details the release notes for version 1.3.37, covering new SDK support, breaking changes to plugin contexts, and various bug fixes across the Bifrost ecosystem.",
      "tags": [
        "release-notes",
        "changelog",
        "bifrost",
        "breaking-changes",
        "sdk-support",
        "version-update"
      ],
      "category": "other",
      "original_file_path": "changelogs-v1.3.37.md"
    },
    {
      "file_path": "338-changelogs-v1.3.40.md",
      "title": "v1.3.40",
      "url": "https://docs.getbifrost.ai/changelogs/v1.3.40.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:42:16.715840693-03:00",
      "description": "> v1.3.40 changelog - 2025-12-04",
      "summary": "This document outlines the release notes and update instructions for Bifrost version 1.3.40, featuring critical security patches for React and Next.js.",
      "tags": [
        "release-notes",
        "bifrost",
        "security-update",
        "docker",
        "npx",
        "v1-3-40"
      ],
      "category": "reference",
      "original_file_path": "changelogs-v1.3.40.md"
    },
    {
      "file_path": "340-changelogs-v1.3.38.md",
      "title": "v1.3.38",
      "url": "https://docs.getbifrost.ai/changelogs/v1.3.38.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:42:16.141181217-03:00",
      "description": "> v1.3.38 changelog - 2025-12-01",
      "summary": "This document provides the release notes for version 1.3.38, detailing new features like Anthropic model support in Azure and bug fixes across various system components.",
      "tags": [
        "release-notes",
        "changelog",
        "bifrost",
        "anthropic",
        "azure",
        "google-gemini",
        "bug-fixes",
        "breaking-change"
      ],
      "category": "other",
      "original_file_path": "changelogs-v1.3.38.md"
    },
    {
      "file_path": "374-changelogs-v1.3.4.md",
      "title": "v1.3.4",
      "url": "https://docs.getbifrost.ai/changelogs/v1.3.4.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:42:16.627402582-03:00",
      "description": "> v1.3.4 changelog",
      "summary": "This document provides the changelog for Bifrost version 1.3.4, detailing updates to the HTTP interface, core engine, and framework modules. Key improvements include enhanced MCP tool management, virtual key support, and updated dependency versions.",
      "tags": [
        "changelog",
        "release-notes",
        "bifrost",
        "mcp-tools",
        "dependency-update",
        "key-management"
      ],
      "category": "other",
      "original_file_path": "changelogs-v1.3.4.md"
    },
    {
      "file_path": "339-changelogs-v1.3.39.md",
      "title": "v1.3.39",
      "url": "https://docs.getbifrost.ai/changelogs/v1.3.39.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:42:16.160191749-03:00",
      "description": "> v1.3.39 changelog - 2025-12-04",
      "summary": "This document provides the release notes for Bifrost version 1.3.39, detailing improvements to streaming usage aggregation, API response updates, and bug fixes for model visibility.",
      "tags": [
        "changelog",
        "release-notes",
        "bifrost",
        "streaming-fix",
        "api-updates",
        "version-history"
      ],
      "category": "reference",
      "original_file_path": "changelogs-v1.3.39.md"
    },
    {
      "file_path": "337-changelogs-v1.3.41.md",
      "title": "v1.3.41",
      "url": "https://docs.getbifrost.ai/changelogs/v1.3.41.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:42:17.791988311-03:00",
      "description": "> v1.3.41 changelog - 2025-12-05",
      "summary": "This document provides the release notes for version 1.3.41, detailing a critical fix for Docker segmentation faults and refactored tag management for the Maxim plugin.",
      "tags": [
        "release-notes",
        "bifrost",
        "docker-fix",
        "plugin-update",
        "version-history",
        "bug-fix"
      ],
      "category": "other",
      "original_file_path": "changelogs-v1.3.41.md"
    },
    {
      "file_path": "334-changelogs-v1.3.44.md",
      "title": "v1.3.44",
      "url": "https://docs.getbifrost.ai/changelogs/v1.3.44.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:42:22.360094037-03:00",
      "description": "> v1.3.44 changelog - 2025-12-10",
      "summary": "This document provides the release notes and changelog for Bifrost version 1.3.44, detailing new features like RBAC support and various bug fixes and dependency updates.",
      "tags": [
        "changelog",
        "release-notes",
        "rbac",
        "bifrost",
        "docker",
        "deployment",
        "version-update"
      ],
      "category": "reference",
      "original_file_path": "changelogs-v1.3.44.md"
    },
    {
      "file_path": "336-changelogs-v1.3.42.md",
      "title": "v1.3.42",
      "url": "https://docs.getbifrost.ai/changelogs/v1.3.42.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:42:21.518485905-03:00",
      "description": "> v1.3.42 changelog - 2025-12-05",
      "summary": "This document provides the release notes for Bifrost version 1.3.42, detailing installation instructions via NPX and Docker along with bug fixes and dependency updates.",
      "tags": [
        "release-notes",
        "changelog",
        "bifrost",
        "version-update",
        "docker",
        "npx",
        "amazon-bedrock"
      ],
      "category": "other",
      "original_file_path": "changelogs-v1.3.42.md"
    },
    {
      "file_path": "333-changelogs-v1.3.45.md",
      "title": "v1.3.45",
      "url": "https://docs.getbifrost.ai/changelogs/v1.3.45.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:42:22.95338783-03:00",
      "description": "> v1.3.45 changelog - 2025-12-11",
      "summary": "This document details the changelog for Bifrost version 1.3.45, providing information on new features, bug fixes, and component updates across the platform.",
      "tags": [
        "changelog",
        "release-notes",
        "bifrost",
        "version-update",
        "bug-fixes",
        "deployment"
      ],
      "category": "reference",
      "original_file_path": "changelogs-v1.3.45.md"
    },
    {
      "file_path": "335-changelogs-v1.3.43.md",
      "title": "v1.3.43",
      "url": "https://docs.getbifrost.ai/changelogs/v1.3.43.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:42:22.255223739-03:00",
      "description": "> v1.3.43 changelog - 2025-12-09",
      "summary": "This document outlines the updates and new features introduced in version 1.3.43 of Bifrost, including global proxy support, Datadog integration, and enterprise plugin handling.",
      "tags": [
        "release-notes",
        "bifrost-updates",
        "docker-deployment",
        "proxy-support",
        "datadog-integration",
        "otel-plugin"
      ],
      "category": "other",
      "original_file_path": "changelogs-v1.3.43.md"
    },
    {
      "file_path": "332-changelogs-v1.3.46.md",
      "title": "v1.3.46",
      "url": "https://docs.getbifrost.ai/changelogs/v1.3.46.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:42:25.171301606-03:00",
      "description": "> v1.3.46 changelog - 2025-12-12",
      "summary": "This document provides the release notes and update instructions for Bifrost version 1.3.46, which includes critical security hotfixes for React and Next.js.",
      "tags": [
        "changelog",
        "release-notes",
        "security-patch",
        "hotfix",
        "bifrost",
        "version-update"
      ],
      "category": "reference",
      "original_file_path": "changelogs-v1.3.46.md"
    },
    {
      "file_path": "331-changelogs-v1.3.47.md",
      "title": "v1.3.47",
      "url": "https://docs.getbifrost.ai/changelogs/v1.3.47.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:42:26.979647947-03:00",
      "description": "> v1.3.47 changelog - 2025-12-12",
      "summary": "This document outlines the version 1.3.47 release notes for Bifrost, detailing new features such as raw request logging, reasoning support in chat completions, and migration to the Gemini native API.",
      "tags": [
        "changelog",
        "bifrost",
        "release-notes",
        "chat-completions",
        "api-updates",
        "logging"
      ],
      "category": "reference",
      "original_file_path": "changelogs-v1.3.47.md"
    },
    {
      "file_path": "330-changelogs-v1.3.48.md",
      "title": "v1.3.48",
      "url": "https://docs.getbifrost.ai/changelogs/v1.3.48.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:42:28.120535999-03:00",
      "description": "> v1.3.48 changelog - 2025-12-12",
      "summary": "This document outlines the release notes and deployment instructions for Bifrost version 1.3.48, featuring security patches for Next.js and React.",
      "tags": [
        "release-notes",
        "bifrost",
        "security-patch",
        "docker",
        "npx",
        "changelog"
      ],
      "category": "other",
      "original_file_path": "changelogs-v1.3.48.md"
    },
    {
      "file_path": "329-changelogs-v1.3.49.md",
      "title": "v1.3.49",
      "url": "https://docs.getbifrost.ai/changelogs/v1.3.49.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:42:28.285361725-03:00",
      "description": "> v1.3.49 changelog - 2025-12-16",
      "summary": "This document outlines the changes in Bifrost version 1.3.49, detailing new features such as batch API support and provider integrations along with various bug fixes and component updates.",
      "tags": [
        "changelog",
        "release-notes",
        "bifrost",
        "batch-api",
        "llm-providers",
        "software-update"
      ],
      "category": "reference",
      "original_file_path": "changelogs-v1.3.49.md"
    },
    {
      "file_path": "373-changelogs-v1.3.5.md",
      "title": "v1.3.5",
      "url": "https://docs.getbifrost.ai/changelogs/v1.3.5.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:42:28.346508861-03:00",
      "description": "> v1.3.5 changelog",
      "summary": "This document outlines the release notes and changelog for Bifrost version 1.3.5, detailing new features, bug fixes, and framework updates across various components.",
      "tags": [
        "changelog",
        "release-notes",
        "bifrost",
        "software-update",
        "database-migration",
        "mcp-client"
      ],
      "category": "reference",
      "original_file_path": "changelogs-v1.3.5.md"
    },
    {
      "file_path": "327-changelogs-v1.3.51.md",
      "title": "v1.3.51",
      "url": "https://docs.getbifrost.ai/changelogs/v1.3.51.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:42:31.398723788-03:00",
      "description": "> v1.3.51 changelog - 2025-12-19",
      "summary": "This document outlines the changes, bug fixes, and new features introduced in version 1.3.51 of Bifrost, including HuggingFace provider support and proxy enhancements.",
      "tags": [
        "release-notes",
        "changelog",
        "bifrost",
        "huggingface",
        "bug-fixes",
        "proxy-support",
        "mcp-tools"
      ],
      "category": "other",
      "original_file_path": "changelogs-v1.3.51.md"
    },
    {
      "file_path": "328-changelogs-v1.3.50.md",
      "title": "v1.3.50",
      "url": "https://docs.getbifrost.ai/changelogs/v1.3.50.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:42:31.142381168-03:00",
      "description": "> v1.3.50 changelog - 2025-12-17",
      "summary": "This document provides the release notes for version 1.3.50, detailing new features, bug fixes, and improvements across the Bifrost ecosystem.",
      "tags": [
        "release-notes",
        "changelog",
        "bifrost",
        "api-updates",
        "prompt-caching",
        "model-support"
      ],
      "category": "other",
      "original_file_path": "changelogs-v1.3.50.md"
    },
    {
      "file_path": "325-changelogs-v1.3.53.md",
      "title": "v1.3.53",
      "url": "https://docs.getbifrost.ai/changelogs/v1.3.53.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:42:33.691563555-03:00",
      "description": "> v1.3.53 changelog - 2025-12-23",
      "summary": "This document outlines the changes and bug fixes introduced in Bifrost version 1.3.53, including improvements to Anthropic and Bedrock provider integrations.",
      "tags": [
        "changelog",
        "release-notes",
        "bifrost",
        "bug-fixes",
        "anthropic",
        "bedrock",
        "version-update"
      ],
      "category": "other",
      "original_file_path": "changelogs-v1.3.53.md"
    },
    {
      "file_path": "326-changelogs-v1.3.52.md",
      "title": "v1.3.52",
      "url": "https://docs.getbifrost.ai/changelogs/v1.3.52.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:42:33.29272382-03:00",
      "description": "> v1.3.52 changelog - 2025-12-22",
      "summary": "This document provides the release notes for version 1.3.52 of Bifrost, detailing bug fixes, new model features for Anthropic and Gemini, and dependency updates across various modules.",
      "tags": [
        "release-notes",
        "changelog",
        "bifrost",
        "gemini",
        "anthropic",
        "software-update"
      ],
      "category": "other",
      "original_file_path": "changelogs-v1.3.52.md"
    },
    {
      "file_path": "324-changelogs-v1.3.54.md",
      "title": "v1.3.54",
      "url": "https://docs.getbifrost.ai/changelogs/v1.3.54.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:42:34.830352487-03:00",
      "description": "> v1.3.54 changelog - 2025-12-29",
      "summary": "This document outlines the changes in Bifrost version 1.3.54, highlighting new document support for AI providers and header management features.",
      "tags": [
        "release-notes",
        "changelog",
        "bifrost",
        "ai-providers",
        "header-filtering"
      ],
      "category": "other",
      "original_file_path": "changelogs-v1.3.54.md"
    },
    {
      "file_path": "323-changelogs-v1.3.56.md",
      "title": "v1.3.56",
      "url": "https://docs.getbifrost.ai/changelogs/v1.3.56.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:42:37.165503266-03:00",
      "description": "> v1.3.56 changelog - 2026-01-01",
      "summary": "This document provides the changelog for Bifrost version 1.3.56, detailing bug fixes for configuration handling, new hashing support for provider keys, and package version updates.",
      "tags": [
        "changelog",
        "release-notes",
        "bifrost",
        "version-update",
        "bug-fixes",
        "configuration-management"
      ],
      "category": "reference",
      "original_file_path": "changelogs-v1.3.56.md"
    },
    {
      "file_path": "322-changelogs-v1.3.57.md",
      "title": "v1.3.57",
      "url": "https://docs.getbifrost.ai/changelogs/v1.3.57.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:42:38.676018035-03:00",
      "description": "> v1.3.57 changelog - 2026-01-01",
      "summary": "This document details the version 1.3.57 release notes for Bifrost, including bug fixes for configuration parsing and framework upgrades across multiple service modules.",
      "tags": [
        "changelog",
        "release-notes",
        "bifrost",
        "version-update",
        "bug-fixes",
        "framework-upgrade"
      ],
      "category": "reference",
      "original_file_path": "changelogs-v1.3.57.md"
    },
    {
      "file_path": "320-changelogs-v1.3.59.md",
      "title": "v1.3.59",
      "url": "https://docs.getbifrost.ai/changelogs/v1.3.59.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:42:40.718227244-03:00",
      "description": "> v1.3.59 changelog - 2026-01-05",
      "summary": "This document outlines the changes, bug fixes, and new features introduced in Bifrost version 1.3.59, including improved structured output support for AI providers and core framework updates.",
      "tags": [
        "release-notes",
        "changelog",
        "bifrost",
        "gemini",
        "anthropic",
        "structured-outputs",
        "bug-fixes"
      ],
      "category": "reference",
      "original_file_path": "changelogs-v1.3.59.md"
    },
    {
      "file_path": "372-changelogs-v1.3.6.md",
      "title": "v1.3.6",
      "url": "https://docs.getbifrost.ai/changelogs/v1.3.6.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:42:41.645062547-03:00",
      "description": "> v1.3.6 changelog",
      "summary": "This document details the changes and updates in Bifrost version 1.3.6, including bug fixes for tool message outputs and core component version bumps. It provides installation commands for updating via NPX and Docker.",
      "tags": [
        "changelog",
        "release-notes",
        "bifrost",
        "docker",
        "version-update",
        "bug-fixes"
      ],
      "category": "reference",
      "original_file_path": "changelogs-v1.3.6.md"
    },
    {
      "file_path": "321-changelogs-v1.3.58.md",
      "title": "v1.3.58",
      "url": "https://docs.getbifrost.ai/changelogs/v1.3.58.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:42:40.820066417-03:00",
      "description": "> v1.3.58 changelog - 2026-01-02",
      "summary": "Release notes for Bifrost v1.3.58, highlighting new Azure Entra ID support and fixes for Anthropic and Gemini provider integrations.",
      "tags": [
        "changelog",
        "release-notes",
        "bifrost",
        "azure-entra-id",
        "anthropic",
        "gemini",
        "bug-fixes"
      ],
      "category": "other",
      "original_file_path": "changelogs-v1.3.58.md"
    },
    {
      "file_path": "319-changelogs-v1.3.60.md",
      "title": "v1.3.60",
      "url": "https://docs.getbifrost.ai/changelogs/v1.3.60.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:42:44.149082769-03:00",
      "description": "> v1.3.60 changelog - 2026-01-07",
      "summary": "This document outlines the version 1.3.60 release notes for the Bifrost platform, detailing updates to authentication, documentation workflows, and framework dependencies.",
      "tags": [
        "changelog",
        "release-notes",
        "bifrost",
        "version-update",
        "software-maintenance"
      ],
      "category": "other",
      "original_file_path": "changelogs-v1.3.60.md"
    },
    {
      "file_path": "316-changelogs-v1.3.63.md",
      "title": "v1.3.63",
      "url": "https://docs.getbifrost.ai/changelogs/v1.3.63.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:42:47.749549144-03:00",
      "description": "> v1.3.63 changelog - 2026-01-07",
      "summary": "This document details the changelog for version 1.3.63 of Bifrost, covering bug fixes for authentication and provider mappings alongside component updates across the framework.",
      "tags": [
        "changelog",
        "release-notes",
        "bifrost",
        "version-update",
        "bug-fixes",
        "deployment"
      ],
      "category": "reference",
      "original_file_path": "changelogs-v1.3.63.md"
    },
    {
      "file_path": "317-changelogs-v1.3.62.md",
      "title": "v1.3.62",
      "url": "https://docs.getbifrost.ai/changelogs/v1.3.62.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:42:46.430054651-03:00",
      "description": "> v1.3.62 changelog - 2026-01-07",
      "summary": "This document provides the release notes for version 1.3.62, detailing the specific version update and its historical context within the project's changelog.",
      "tags": [
        "release-notes",
        "changelog",
        "versioning",
        "software-update",
        "bifrost-ai"
      ],
      "category": "reference",
      "original_file_path": "changelogs-v1.3.62.md"
    },
    {
      "file_path": "318-changelogs-v1.3.61.md",
      "title": "v1.3.61",
      "url": "https://docs.getbifrost.ai/changelogs/v1.3.61.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:42:45.028532833-03:00",
      "description": "> v1.3.61 changelog - 2026-01-07",
      "summary": "This document outlines the updates for Bifrost version 1.3.61, including bug fixes for Gemini chat converters and various component version upgrades.",
      "tags": [
        "changelog",
        "release-notes",
        "bifrost",
        "gemini-integration",
        "version-update"
      ],
      "category": "other",
      "original_file_path": "changelogs-v1.3.61.md"
    },
    {
      "file_path": "371-changelogs-v1.3.7.md",
      "title": "v1.3.7",
      "url": "https://docs.getbifrost.ai/changelogs/v1.3.7.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:42:48.780428186-03:00",
      "description": "> v1.3.7 changelog",
      "summary": "This document provides the release notes and changelog for Bifrost version 1.3.7, detailing installation instructions and bug fixes across various system modules.",
      "tags": [
        "release-notes",
        "changelog",
        "version-update",
        "bug-fixes",
        "bifrost-deployment"
      ],
      "category": "reference",
      "original_file_path": "changelogs-v1.3.7.md"
    },
    {
      "file_path": "370-changelogs-v1.3.8.md",
      "title": "v1.3.8",
      "url": "https://docs.getbifrost.ai/changelogs/v1.3.8.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:42:49.453167878-03:00",
      "description": "> v1.3.8 changelog",
      "summary": "Detailed release notes for Bifrost version 1.3.8, highlighting bug fixes for OpenAI and Gemini providers and a breaking change regarding JSON schema fields.",
      "tags": [
        "release-notes",
        "bifrost",
        "changelog",
        "bug-fixes",
        "breaking-changes",
        "openai",
        "gemini"
      ],
      "category": "other",
      "original_file_path": "changelogs-v1.3.8.md"
    },
    {
      "file_path": "369-changelogs-v1.3.9.md",
      "title": "v1.3.9",
      "url": "https://docs.getbifrost.ai/changelogs/v1.3.9.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:42:52.077328519-03:00",
      "description": "> v1.3.9 changelog",
      "summary": "This document provides the release notes and installation instructions for Bifrost version 1.3.9, including a fix for Azure deployment form validation.",
      "tags": [
        "bifrost",
        "changelog",
        "release-notes",
        "azure",
        "deployment",
        "docker",
        "npx"
      ],
      "category": "other",
      "original_file_path": "changelogs-v1.3.9.md"
    },
    {
      "file_path": "305-changelogs-v1.4.0.md",
      "title": "v1.4.0",
      "url": "https://docs.getbifrost.ai/changelogs/v1.4.0.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:42:52.409729189-03:00",
      "description": "> v1.4.0 changelog - 2026-01-18",
      "summary": "This document outlines the version 1.4.0 changelog for Bifrost, detailing new features, bug fixes, and dependency updates across its core components and plugins.",
      "tags": [
        "changelog",
        "release-notes",
        "bifrost",
        "version-update",
        "software-maintenance"
      ],
      "category": "reference",
      "original_file_path": "changelogs-v1.4.0.md"
    },
    {
      "file_path": "315-changelogs-v1.4.0-prerelease1.md",
      "title": "v1.4.0-prerelease1",
      "url": "https://docs.getbifrost.ai/changelogs/v1.4.0-prerelease1.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:42:52.592351005-03:00",
      "description": "> v1.4.0-prerelease1 changelog - 2025-12-29",
      "summary": "Release notes for Bifrost v1.4.0-prerelease1 detailing new MCP gateway features, end-to-end tracing, and a significant breaking change in the plugin middleware interface.",
      "tags": [
        "release-notes",
        "breaking-changes",
        "bifrost",
        "middleware",
        "tracing",
        "plugin-system",
        "mcp-gateway"
      ],
      "category": "reference",
      "original_file_path": "changelogs-v1.4.0-prerelease1.md"
    },
    {
      "file_path": "306-changelogs-v1.4.0-prerelease10.md",
      "title": "v1.4.0-prerelease10",
      "url": "https://docs.getbifrost.ai/changelogs/v1.4.0-prerelease10.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:42:54.882654216-03:00",
      "description": "> v1.4.0-prerelease10 changelog - 2026-01-15",
      "summary": "This document provides the release notes for Bifrost version 1.4.0-prerelease10, detailing new features such as image generation support, web search tools, and various bug fixes across its core components.",
      "tags": [
        "release-notes",
        "bifrost",
        "changelog",
        "image-generation",
        "llm-gateway",
        "web-search"
      ],
      "category": "other",
      "original_file_path": "changelogs-v1.4.0-prerelease10.md"
    },
    {
      "file_path": "314-changelogs-v1.4.0-prerelease2.md",
      "title": "v1.4.0-prerelease2",
      "url": "https://docs.getbifrost.ai/changelogs/v1.4.0-prerelease2.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:42:56.459566334-03:00",
      "description": "> v1.4.0-prerelease2 changelog - 2025-12-30",
      "summary": "This document provides release notes for Bifrost version 1.4.0-prerelease2, detailing bug fixes for AI model integrations, distributed tracing enhancements, and core dependency updates.",
      "tags": [
        "release-notes",
        "bifrost",
        "changelog",
        "distributed-tracing",
        "bug-fixes",
        "version-update"
      ],
      "category": "reference",
      "original_file_path": "changelogs-v1.4.0-prerelease2.md"
    },
    {
      "file_path": "313-changelogs-v1.4.0-prerelease3.md",
      "title": "v1.4.0-prerelease3",
      "url": "https://docs.getbifrost.ai/changelogs/v1.4.0-prerelease3.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:42:57.155054068-03:00",
      "description": "> v1.4.0-prerelease3 changelog - 2026-01-02",
      "summary": "This document outlines the updates and bug fixes for the v1.4.0-prerelease3 release, covering provider-specific improvements and authentication enhancements across the Bifrost ecosystem.",
      "tags": [
        "changelog",
        "release-notes",
        "bifrost",
        "bug-fixes",
        "azure-entra-id",
        "anthropic",
        "gemini"
      ],
      "category": "other",
      "original_file_path": "changelogs-v1.4.0-prerelease3.md"
    },
    {
      "file_path": "311-changelogs-v1.4.0-prerelease5.md",
      "title": "v1.4.0-prerelease5",
      "url": "https://docs.getbifrost.ai/changelogs/v1.4.0-prerelease5.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:42:58.448329731-03:00",
      "description": "> v1.4.0-prerelease5 changelog - 2026-01-05",
      "summary": "This document provides the release notes for Bifrost version 1.4.0-prerelease5, detailing bug fixes for LLM integration and UI stability.",
      "tags": [
        "release-notes",
        "bifrost",
        "changelog",
        "bug-fixes",
        "installation"
      ],
      "category": "reference",
      "original_file_path": "changelogs-v1.4.0-prerelease5.md"
    },
    {
      "file_path": "309-changelogs-v1.4.0-prerelease7.md",
      "title": "v1.4.0-prerelease7",
      "url": "https://docs.getbifrost.ai/changelogs/v1.4.0-prerelease7.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:43:02.218260261-03:00",
      "description": "> v1.4.0-prerelease7 changelog - 2026-01-08",
      "summary": "This document outlines the changes in Bifrost v1.4.0-prerelease7, focusing on bug fixes for xAI provider integration, query parsing, and internal dependency updates.",
      "tags": [
        "release-notes",
        "changelog",
        "bifrost",
        "xai-integration",
        "bug-fixes",
        "version-update"
      ],
      "category": "reference",
      "original_file_path": "changelogs-v1.4.0-prerelease7.md"
    },
    {
      "file_path": "312-changelogs-v1.4.0-prerelease4.md",
      "title": "v1.4.0-prerelease4",
      "url": "https://docs.getbifrost.ai/changelogs/v1.4.0-prerelease4.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:42:57.91244843-03:00",
      "description": "> v1.4.0-prerelease4 changelog - 2026-01-05",
      "summary": "This document provides the release notes and changelog for Bifrost version 1.4.0-prerelease4, detailing new features, bug fixes, and dependency updates across multiple modules.",
      "tags": [
        "release-notes",
        "changelog",
        "bifrost",
        "gemini-integration",
        "anthropic-integration",
        "bug-fixes"
      ],
      "category": "reference",
      "original_file_path": "changelogs-v1.4.0-prerelease4.md"
    },
    {
      "file_path": "310-changelogs-v1.4.0-prerelease6.md",
      "title": "v1.4.0-prerelease6",
      "url": "https://docs.getbifrost.ai/changelogs/v1.4.0-prerelease6.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:43:02.113248487-03:00",
      "description": "> v1.4.0-prerelease6 changelog - 2026-01-07",
      "summary": "This document provides the release notes for Bifrost version 1.4.0-prerelease6, documenting various bug fixes, feature enhancements, and dependency updates across the platform's components.",
      "tags": [
        "release-notes",
        "changelog",
        "bifrost",
        "software-updates",
        "version-history"
      ],
      "category": "reference",
      "original_file_path": "changelogs-v1.4.0-prerelease6.md"
    },
    {
      "file_path": "308-changelogs-v1.4.0-prerelease8.md",
      "title": "v1.4.0-prerelease8",
      "url": "https://docs.getbifrost.ai/changelogs/v1.4.0-prerelease8.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:43:03.314061059-03:00",
      "description": "> v1.4.0-prerelease8 changelog - 2026-01-09",
      "summary": "This document details the updates and bug fixes for Bifrost version 1.4.0-prerelease8, including model enhancements for Vertex and Gemini and dependency updates across various modules.",
      "tags": [
        "release-notes",
        "changelog",
        "bifrost",
        "vertex-ai",
        "gemini",
        "telemetry",
        "version-update"
      ],
      "category": "other",
      "original_file_path": "changelogs-v1.4.0-prerelease8.md"
    },
    {
      "file_path": "307-changelogs-v1.4.0-prerelease9.md",
      "title": "v1.4.0-prerelease9",
      "url": "https://docs.getbifrost.ai/changelogs/v1.4.0-prerelease9.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:43:05.643813453-03:00",
      "description": "> v1.4.0-prerelease9 changelog - 2026-01-11",
      "summary": "This document outlines the changes in Bifrost version 1.4.0-prerelease9, focusing on fixes for streaming response timeouts and dependency updates across various internal modules.",
      "tags": [
        "release-notes",
        "changelog",
        "bifrost",
        "bug-fix",
        "streaming-responses",
        "version-update"
      ],
      "category": "other",
      "original_file_path": "changelogs-v1.4.0-prerelease9.md"
    },
    {
      "file_path": "115-contributing-adding-a-configstore.md",
      "title": "Adding config store",
      "url": "https://docs.getbifrost.ai/contributing/adding-a-configstore.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:43:07.96147708-03:00",
      "description": "> Learn how to contribute a backend for the config store in Bifrost",
      "summary": "This guide provides instructions for developers on how to extend the Bifrost config store by implementing new database backends using the ConfigStore interface and GORM.",
      "tags": [
        "bifrost",
        "config-store",
        "database-backend",
        "gorm",
        "golang",
        "extensibility"
      ],
      "category": "guide",
      "original_file_path": "contributing-adding-a-configstore.md"
    },
    {
      "file_path": "116-contributing-adding-a-logstore.md",
      "title": "Adding a log store",
      "url": "https://docs.getbifrost.ai/contributing/adding-a-logstore.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:43:08.286929862-03:00",
      "description": "> Learn how to contribute a backend for the log store in Bifrost",
      "summary": "This guide explains how to add a custom database backend for the Bifrost log store by implementing the LogStore interface or extending the relational database implementation. It details the architecture, file conventions, and specific steps required to integrate a new storage provider using GORM.",
      "tags": [
        "bifrost",
        "log-store",
        "database-backend",
        "gorm",
        "golang",
        "extensibility",
        "logging-system"
      ],
      "category": "guide",
      "original_file_path": "contributing-adding-a-logstore.md"
    },
    {
      "file_path": "118-contributing-adding-a-vectorstore.md",
      "title": "Adding a vector store",
      "url": "https://docs.getbifrost.ai/contributing/adding-a-vectorstore.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:43:10.328598843-03:00",
      "description": "> Learn how to contribute a backend for the vector store in Bifrost",
      "summary": "This guide provides instructions on how to contribute a new vector database backend to Bifrost by implementing the VectorStore interface and following specific architectural patterns.",
      "tags": [
        "bifrost",
        "vector-store",
        "database-integration",
        "backend-development",
        "vector-database",
        "contribution-guide"
      ],
      "category": "guide",
      "original_file_path": "contributing-adding-a-vectorstore.md"
    },
    {
      "file_path": "117-contributing-adding-a-provider.md",
      "title": "Adding a new provider",
      "url": "https://docs.getbifrost.ai/contributing/adding-a-provider.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:43:09.919240759-03:00",
      "description": "> Learn how to contribute a new provider to Bifrost.",
      "summary": "This guide provides a comprehensive walkthrough for adding new LLM providers to the Bifrost gateway, covering both OpenAI-compatible and custom implementations. It details the required directory structure, file conventions, and coding standards for maintaining consistency across provider integrations.",
      "tags": [
        "bifrost",
        "provider-integration",
        "golang",
        "api-gateway",
        "llm-provider",
        "open-source-contribution"
      ],
      "category": "guide",
      "original_file_path": "contributing-adding-a-provider.md"
    },
    {
      "file_path": "304-changelogs-v1.4.1.md",
      "title": "v1.4.1",
      "url": "https://docs.getbifrost.ai/changelogs/v1.4.1.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:43:07.461110878-03:00",
      "description": "> v1.4.1 changelog - 2026-01-19",
      "summary": "This document details the updates and bug fixes for Bifrost version 1.4.1, primarily addressing streaming support for Bedrock structured output and associated component upgrades.",
      "tags": [
        "release-notes",
        "changelog",
        "bifrost",
        "bedrock",
        "structured-output",
        "streaming",
        "bug-fixes"
      ],
      "category": "other",
      "original_file_path": "changelogs-v1.4.1.md"
    },
    {
      "file_path": "097-deployment-guides-helm.md",
      "title": "Helm",
      "url": "https://docs.getbifrost.ai/deployment-guides/helm.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:43:15.889873813-03:00",
      "description": "> Deploy Bifrost on Kubernetes using Helm charts with flexible configuration options",
      "summary": "This document provides instructions and configuration patterns for deploying Bifrost on Kubernetes using Helm charts, covering environments from local development to high-availability production.",
      "tags": [
        "helm",
        "kubernetes",
        "deployment",
        "devops",
        "high-availability",
        "configuration",
        "bifrost"
      ],
      "category": "guide",
      "original_file_path": "deployment-guides-helm.md"
    },
    {
      "file_path": "096-deployment-guides-fly.md",
      "title": "fly.io",
      "url": "https://docs.getbifrost.ai/deployment-guides/fly.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:43:15.294194555-03:00",
      "description": "> This guide explains how to deploy Bifrost on fly.io",
      "summary": "This document provides step-by-step instructions for deploying Bifrost to Fly.io using either a cloned repository with a custom build process or a pre-built Docker Hub image.",
      "tags": [
        "bifrost",
        "fly-io",
        "deployment",
        "docker",
        "cloud-hosting",
        "devops"
      ],
      "category": "guide",
      "original_file_path": "deployment-guides-fly.md"
    },
    {
      "file_path": "095-deployment-guides-ecs.md",
      "title": "ECS",
      "url": "https://docs.getbifrost.ai/deployment-guides/ecs.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:43:12.578518682-03:00",
      "description": "> Deploy Bifrost as a service in ECS AWS clusters",
      "summary": "This document provides instructions for deploying Bifrost to AWS ECS using Makefile automation or AWS CLI commands for both Fargate and EC2 launch types. It details network configuration, secret management with AWS Secrets Manager or SSM, and service monitoring.",
      "tags": [
        "aws-ecs",
        "bifrost-deployment",
        "fargate",
        "ec2-launch-type",
        "aws-secrets-manager",
        "cloud-infrastructure"
      ],
      "category": "guide",
      "original_file_path": "deployment-guides-ecs.md"
    },
    {
      "file_path": "119-contributing-setting-up-repo.md",
      "title": "Setting up the repository",
      "url": "https://docs.getbifrost.ai/contributing/setting-up-repo.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:43:12.56641145-03:00",
      "description": "> Complete guide to setting up the Bifrost repository for local development.",
      "summary": "This document provides a comprehensive guide for setting up the Bifrost repository for local development, covering prerequisites, installation, and repository architecture. It details the use of Make commands for building, running, and testing the application in a development environment.",
      "tags": [
        "development-setup",
        "bifrost",
        "go",
        "makefile",
        "local-environment",
        "testing"
      ],
      "category": "guide",
      "original_file_path": "contributing-setting-up-repo.md"
    },
    {
      "file_path": "098-deployment-guides-how-to-install-make.md",
      "title": "Install make command",
      "url": "https://docs.getbifrost.ai/deployment-guides/how-to/install-make.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:43:17.294141273-03:00",
      "description": "> This guide explains how to install make command.",
      "summary": "This document provides instructions for installing the make build tool across different operating systems including Windows, Ubuntu, and macOS.",
      "tags": [
        "installation",
        "make",
        "build-tools",
        "windows",
        "macos",
        "ubuntu",
        "package-managers"
      ],
      "category": "guide",
      "original_file_path": "deployment-guides-how-to-install-make.md"
    },
    {
      "file_path": "100-deployment-guides-k8s.md",
      "title": "Terraform + k8s",
      "url": "https://docs.getbifrost.ai/deployment-guides/k8s.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:43:19.216211974-03:00",
      "description": "> Deploy Bifrost as a service in Kubernetes clusters across AWS, Azure, and GCP using Terraform",
      "summary": "This document provides a comprehensive guide for deploying the Bifrost service on Kubernetes clusters using Terraform across AWS, Azure, and GCP. It details the setup of persistent volumes, configuration secrets, and deployment resources required for the service.",
      "tags": [
        "terraform",
        "kubernetes",
        "bifrost",
        "infrastructure-as-code",
        "cloud-deployment",
        "aws",
        "k8s-configuration"
      ],
      "category": "guide",
      "original_file_path": "deployment-guides-k8s.md"
    },
    {
      "file_path": "099-deployment-guides-how-to-multinode.md",
      "title": "Multinode Deployment",
      "url": "https://docs.getbifrost.ai/deployment-guides/how-to/multinode.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:43:19.019846928-03:00",
      "description": "> Deploy multiple Bifrost nodes with shared configuration for high availability in OSS deployments",
      "summary": "This document explains how to achieve high availability in Bifrost OSS deployments by using a shared configuration file across multiple nodes. It provides implementation strategies for Kubernetes and Docker Compose while highlighting the architectural differences between OSS and Enterprise clustering.",
      "tags": [
        "high-availability",
        "multinode-deployment",
        "bifrost-oss",
        "kubernetes",
        "docker-compose",
        "deployment-strategies"
      ],
      "category": "guide",
      "original_file_path": "deployment-guides-how-to-multinode.md"
    },
    {
      "file_path": "081-enterprise-adaptive-load-balancing.md",
      "title": "Adaptive Load Balancing",
      "url": "https://docs.getbifrost.ai/enterprise/adaptive-load-balancing.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:43:19.232901329-03:00",
      "description": "> Advanced load balancing algorithms with predictive scaling, health monitoring, and performance optimization for enterprise-grade traffic distribution.",
      "summary": "This document explains the technical implementation of adaptive load balancing, detailing how real-time metrics like error rates and latency are used to dynamically optimize traffic distribution across providers and keys.",
      "tags": [
        "load-balancing",
        "traffic-management",
        "performance-optimization",
        "health-monitoring",
        "circuit-breaker",
        "adaptive-routing"
      ],
      "category": "concept",
      "original_file_path": "enterprise-adaptive-load-balancing.md"
    },
    {
      "file_path": "082-enterprise-advanced-governance.md",
      "title": "Getting started",
      "url": "https://docs.getbifrost.ai/enterprise/advanced-governance.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:43:19.941031244-03:00",
      "description": "> Advanced governance features with enhanced security, compliance reporting, audit trails, and enterprise-grade access controls for large-scale deployments.",
      "summary": "This document introduces the Bifrost Enterprise Governance module, detailing its advanced security, identity management, and compliance features for large-scale deployments.",
      "tags": [
        "enterprise-governance",
        "identity-management",
        "compliance-monitoring",
        "audit-reporting",
        "role-based-access-control",
        "sso-integration",
        "user-budgeting"
      ],
      "category": "guide",
      "original_file_path": "enterprise-advanced-governance.md"
    },
    {
      "file_path": "085-enterprise-custom-plugins.md",
      "title": "Custom Plugins",
      "url": "https://docs.getbifrost.ai/enterprise/custom-plugins.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:43:23.997914023-03:00",
      "description": "> Build and deploy enterprise-specific plugins to extend Bifrost's functionality with custom business logic, integrations, and workflow automation.",
      "summary": "This document outlines Bifrost's custom plugin development services for extending the platform's LLM gateway with specialized business logic, integrations, and automated workflows.",
      "tags": [
        "custom-plugins",
        "llm-gateway",
        "workflow-automation",
        "ai-governance",
        "extensibility",
        "enterprise-integration"
      ],
      "category": "concept",
      "original_file_path": "enterprise-custom-plugins.md"
    },
    {
      "file_path": "084-enterprise-clustering.md",
      "title": "Clustering",
      "url": "https://docs.getbifrost.ai/enterprise/clustering.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:43:23.508303243-03:00",
      "description": "> Enterprise-grade high-availability clustering with automatic service discovery, intelligent traffic distribution, and gossip-based state synchronization for production deployments.",
      "summary": "This document explains the architecture and configuration of Bifrost clustering for high-availability deployments, covering peer-to-peer networking, gossip protocols, and various service discovery methods.",
      "tags": [
        "clustering",
        "high-availability",
        "service-discovery",
        "gossip-protocol",
        "kubernetes",
        "peer-to-peer",
        "infrastructure"
      ],
      "category": "guide",
      "original_file_path": "enterprise-clustering.md"
    },
    {
      "file_path": "083-enterprise-audit-logs.md",
      "title": "Audit Logs",
      "url": "https://docs.getbifrost.ai/enterprise/audit-logs.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:43:21.969396971-03:00",
      "description": "> Comprehensive security and compliance audit logging with detailed tracking of authentication, authorization, configuration changes, and data access for enterprise governance and regulatory requirements.",
      "summary": "This document outlines the Bifrost audit logging system, detailing how to track security events, configure retention policies, and integrate with external SIEM platforms for compliance.",
      "tags": [
        "audit-logs",
        "compliance",
        "security-monitoring",
        "siem-integration",
        "enterprise-governance",
        "event-tracking"
      ],
      "category": "guide",
      "original_file_path": "enterprise-audit-logs.md"
    },
    {
      "file_path": "086-enterprise-datadog-connector.md",
      "title": "Datadog",
      "url": "https://docs.getbifrost.ai/enterprise/datadog-connector.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:43:26.185333285-03:00",
      "description": "> Native Datadog integration for APM traces, LLM Observability, and metrics",
      "summary": "This document provides a guide for integrating and configuring the Datadog plugin to monitor LLM operations using APM traces, metrics, and native LLM observability. It details the setup for both agent-based and agentless deployment modes along with a complete reference of configuration parameters.",
      "tags": [
        "datadog",
        "observability",
        "apm-traces",
        "llm-monitoring",
        "metrics",
        "configuration",
        "deployment-modes"
      ],
      "category": "guide",
      "original_file_path": "enterprise-datadog-connector.md"
    },
    {
      "file_path": "087-enterprise-guardrails.md",
      "title": "Guardrails",
      "url": "https://docs.getbifrost.ai/enterprise/guardrails.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:43:26.625040685-03:00",
      "description": "> Enterprise-grade content safety and security validation with support for AWS Bedrock Guardrails, Azure Content Safety, and Patronus AI for real-time input and output protection.",
      "summary": "This document explains how to configure and implement enterprise-grade content safety guardrails in Bifrost to validate LLM inputs and outputs against security and compliance policies.",
      "tags": [
        "guardrails",
        "content-safety",
        "llm-security",
        "aws-bedrock",
        "azure-content-safety",
        "patronus-ai",
        "pii-protection",
        "prompt-injection"
      ],
      "category": "configuration",
      "original_file_path": "enterprise-guardrails.md"
    },
    {
      "file_path": "088-enterprise-invpc-deployments.md",
      "title": "In-VPC Deployments",
      "url": "https://docs.getbifrost.ai/enterprise/invpc-deployments.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:43:28.07144777-03:00",
      "description": "> Deploy Bifrost within your private cloud infrastructure with VPC isolation, custom networking, and enhanced security controls for enterprise environments.",
      "summary": "This document provides an overview and high-level instructions for deploying Bifrost within a Virtual Private Cloud (VPC), detailing security benefits, service level agreements, and infrastructure requirements.",
      "tags": [
        "vpc-deployment",
        "private-cloud",
        "security-compliance",
        "enterprise-infrastructure",
        "high-availability",
        "cloud-networking"
      ],
      "category": "guide",
      "original_file_path": "enterprise-invpc-deployments.md"
    },
    {
      "file_path": "089-enterprise-log-exports.md",
      "title": "Log Exports",
      "url": "https://docs.getbifrost.ai/enterprise/log-exports.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:43:28.495761109-03:00",
      "description": "> Export and analyze request logs, traces, and telemetry data from Bifrost with enterprise-grade data export capabilities for compliance, monitoring, and analytics.",
      "summary": "This document explains how to configure and automate log exports from Bifrost to various storage destinations and data warehouses for monitoring and compliance.",
      "tags": [
        "log-export",
        "data-retention",
        "cloud-storage",
        "telemetry-data",
        "enterprise-features",
        "data-warehouse"
      ],
      "category": "configuration",
      "original_file_path": "enterprise-log-exports.md"
    },
    {
      "file_path": "090-enterprise-mcp-with-fa.md",
      "title": "MCP with Federated Auth",
      "url": "https://docs.getbifrost.ai/enterprise/mcp-with-fa.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:43:29.916150074-03:00",
      "description": "> Transform your existing private enterprise APIs into LLM-ready MCP tools using federated authentication without writing a single line of code",
      "summary": "This document explains how to transform private enterprise APIs into LLM-ready Model Context Protocol tools using federated authentication and various import methods like OpenAPI and Postman.",
      "tags": [
        "mcp",
        "federated-authentication",
        "api-integration",
        "llm-tools",
        "openapi",
        "enterprise-security",
        "zero-trust"
      ],
      "category": "guide",
      "original_file_path": "enterprise-mcp-with-fa.md"
    },
    {
      "file_path": "093-enterprise-setting-up-okta.md",
      "title": "Setting up Okta",
      "url": "https://docs.getbifrost.ai/enterprise/setting-up-okta.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:43:32.586496326-03:00",
      "description": "> Step-by-step guide to configure Okta as your identity provider for Bifrost Enterprise SSO authentication.",
      "summary": "Step-by-step instructions for configuring Okta as an identity provider for Bifrost Enterprise to enable SSO and automated role synchronization.",
      "tags": [
        "okta",
        "sso",
        "authentication",
        "identity-provider",
        "oidc",
        "user-provisioning"
      ],
      "category": "guide",
      "original_file_path": "enterprise-setting-up-okta.md"
    },
    {
      "file_path": "092-enterprise-setting-up-entra.md",
      "title": "Setting up Microsoft Entra",
      "url": "https://docs.getbifrost.ai/enterprise/setting-up-entra.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:43:32.076679269-03:00",
      "description": "> Step-by-step guide to configure Microsoft Entra ID (Azure AD) as your identity provider for Bifrost Enterprise SSO authentication.",
      "summary": "This document provides step-by-step instructions for configuring Microsoft Entra ID as an identity provider to enable Single Sign-On (SSO) and role-based access control for Bifrost Enterprise.",
      "tags": [
        "microsoft-entra-id",
        "azure-ad",
        "sso-authentication",
        "identity-management",
        "role-mapping",
        "bifrost-enterprise"
      ],
      "category": "guide",
      "original_file_path": "enterprise-setting-up-entra.md"
    },
    {
      "file_path": "091-enterprise-rbac.md",
      "title": "Role-Based Access Control",
      "url": "https://docs.getbifrost.ai/enterprise/rbac.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:43:31.482509854-03:00",
      "description": "> Manage user access with fine-grained permissions across Bifrost resources using roles and permissions.",
      "summary": "Explains how to implement and manage Role-Based Access Control (RBAC) in Bifrost to provide fine-grained access management for users and resources.",
      "tags": [
        "rbac",
        "access-control",
        "permissions",
        "user-management",
        "governance",
        "enterprise-security"
      ],
      "category": "guide",
      "original_file_path": "enterprise-rbac.md"
    },
    {
      "file_path": "094-enterprise-vault-support.md",
      "title": "Vault Support",
      "url": "https://docs.getbifrost.ai/enterprise/vault-support.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:43:33.598781948-03:00",
      "description": "> Secure API key management with HashiCorp Vault, AWS Secrets Manager, Google Secret Manager, and Azure Key Vault integration. Store and retrieve sensitive credentials using enterprise-grade secret management.",
      "summary": "This document explains how to integrate Bifrost with enterprise secret management systems like HashiCorp Vault and cloud-based secret managers for automated API key synchronization. It outlines the configuration, synchronization process, and security practices for managing the lifecycle of sensitive credentials.",
      "tags": [
        "vault-integration",
        "secret-management",
        "api-key-security",
        "hashicorp-vault",
        "aws-secrets-manager",
        "key-synchronization",
        "credential-management"
      ],
      "category": "configuration",
      "original_file_path": "enterprise-vault-support.md"
    },
    {
      "file_path": "029-features-drop-in-replacement.md",
      "title": "Drop-in Replacement",
      "url": "https://docs.getbifrost.ai/features/drop-in-replacement.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:43:35.908770759-03:00",
      "description": "> Replace your existing AI SDK connections with Bifrost by changing just the base URL. Keep your code, gain advanced features like fallbacks, load balancing, and governance.",
      "summary": "This document explains how to integrate the Bifrost Gateway as a drop-in replacement for popular AI SDKs by simply updating the base URL. It describes how this switch enables advanced features like load balancing, failovers, and governance without requiring changes to existing application logic.",
      "tags": [
        "ai-gateway",
        "sdk-integration",
        "drop-in-replacement",
        "load-balancing",
        "failover-management",
        "openai-compatible",
        "multi-provider"
      ],
      "category": "guide",
      "original_file_path": "features-drop-in-replacement.md"
    },
    {
      "file_path": "030-features-fallbacks.md",
      "title": "Fallbacks",
      "url": "https://docs.getbifrost.ai/features/fallbacks.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:43:36.113084006-03:00",
      "description": "> Automatic failover between AI providers and models. When your primary provider fails, Bifrost seamlessly switches to backup providers without interrupting your application.",
      "summary": "This document explains how Bifrost manages automatic failover between different AI providers and models to ensure application continuity during outages or rate limiting. It details the sequential fallback process and how plugins are applied to each fallback attempt.",
      "tags": [
        "automatic-failover",
        "ai-provider-switching",
        "error-handling",
        "high-availability",
        "redundancy",
        "bifrost-gateway"
      ],
      "category": "guide",
      "original_file_path": "features-fallbacks.md"
    },
    {
      "file_path": "032-features-governance-mcp-tools.md",
      "title": "MCP Tool Filtering",
      "url": "https://docs.getbifrost.ai/features/governance/mcp-tools.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:43:37.698200487-03:00",
      "description": "> Control which MCP tools are available for each Virtual Key.",
      "summary": "This document explains how to restrict and manage access to Model Context Protocol (MCP) tools using Virtual Key configurations to ensure only authorized tools are available to AI models.",
      "tags": [
        "mcp-tools",
        "virtual-keys",
        "tool-filtering",
        "access-control",
        "governance",
        "api-security"
      ],
      "category": "configuration",
      "original_file_path": "features-governance-mcp-tools.md"
    },
    {
      "file_path": "031-features-governance-budget-and-limits.md",
      "title": "Budget and Limits",
      "url": "https://docs.getbifrost.ai/features/governance/budget-and-limits.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:43:37.072002032-03:00",
      "description": "> Enterprise-grade budget management and cost control with hierarchical budget allocation through virtual keys, teams, and customers.",
      "summary": "This document explains Bifrost's hierarchical budget management and rate-limiting system, detailing how costs and usage are controlled across customers, teams, and virtual keys.",
      "tags": [
        "budget-management",
        "cost-control",
        "rate-limiting",
        "virtual-keys",
        "governance",
        "usage-tracking"
      ],
      "category": "guide",
      "original_file_path": "features-governance-budget-and-limits.md"
    },
    {
      "file_path": "033-features-governance-routing.md",
      "title": "Routing",
      "url": "https://docs.getbifrost.ai/features/governance/routing.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:43:39.208908114-03:00",
      "description": "> Direct requests to specific AI models, providers, and keys using Virtual Keys.",
      "summary": "This document explains how to configure governance-based routing for AI models and providers using Virtual Keys to manage load balancing, failover, and access control. It details how to set up provider restrictions, weighted distribution, and automatic fallbacks to ensure application resilience and cost optimization.",
      "tags": [
        "routing",
        "virtual-keys",
        "load-balancing",
        "failover",
        "ai-governance",
        "model-management",
        "provider-configuration"
      ],
      "category": "configuration",
      "original_file_path": "features-governance-routing.md"
    },
    {
      "file_path": "034-features-governance-virtual-keys.md",
      "title": "Virtual Keys",
      "url": "https://docs.getbifrost.ai/features/governance/virtual-keys.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:43:40.329005774-03:00",
      "description": "> Virtual keys are a way to manage access to your AI models.",
      "summary": "This document explains how to use Virtual Keys as a governance entity to manage AI model access, authentication, budget controls, and rate limiting. It details configuration methods via the Web UI, API, and JSON configuration files.",
      "tags": [
        "virtual-keys",
        "access-control",
        "governance",
        "rate-limiting",
        "cost-management",
        "api-authentication"
      ],
      "category": "guide",
      "original_file_path": "features-governance-virtual-keys.md"
    },
    {
      "file_path": "036-features-litellm-compat.md",
      "title": "LiteLLM Compatibility",
      "url": "https://docs.getbifrost.ai/features/litellm-compat.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:43:42.350183441-03:00",
      "description": "> Request and response transformations for LiteLLM proxy/SDK compatibility.",
      "summary": "This document explains the LiteLLM compatibility plugin, which provides automatic text-to-chat conversion and tool call content fallbacks to ensure interoperability across different AI model providers.",
      "tags": [
        "litellm-compatibility",
        "text-to-chat",
        "tool-calls",
        "api-transformation",
        "model-interoperability",
        "gateway-configuration"
      ],
      "category": "guide",
      "original_file_path": "features-litellm-compat.md"
    },
    {
      "file_path": "035-features-keys-management.md",
      "title": "Load Balance",
      "url": "https://docs.getbifrost.ai/features/keys-management.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:43:42.126005813-03:00",
      "description": "> Intelligent API key management with weighted load balancing, model-specific filtering, and automatic failover. Distribute traffic across multiple keys for optimal performance and reliability.",
      "summary": "This document explains how to implement intelligent API key management using weighted load balancing, model-specific filtering, and deployment mappings to optimize traffic distribution and reliability.",
      "tags": [
        "load-balancing",
        "api-key-management",
        "traffic-distribution",
        "failover",
        "model-filtering",
        "bifrost",
        "deployment-mapping"
      ],
      "category": "guide",
      "original_file_path": "features-keys-management.md"
    },
    {
      "file_path": "038-features-observability-maxim.md",
      "title": "Maxim AI",
      "url": "https://docs.getbifrost.ai/features/observability/maxim.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:43:45.605424527-03:00",
      "description": "> Integrate Maxim SDK for comprehensive LLM observability, tracing, and evaluation.",
      "summary": "Explains how to integrate and configure the Maxim AI plugin with Bifrost for comprehensive LLM observability, tracing, and evaluation across Go SDK and HTTP gateway environments.",
      "tags": [
        "maxim-ai",
        "bifrost",
        "llm-observability",
        "tracing",
        "go-sdk",
        "configuration",
        "ai-monitoring"
      ],
      "category": "guide",
      "original_file_path": "features-observability-maxim.md"
    },
    {
      "file_path": "037-features-observability-default.md",
      "title": "Built-in Observability",
      "url": "https://docs.getbifrost.ai/features/observability/default.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:43:42.898539634-03:00",
      "description": "> Monitor and analyze every AI request and response in real-time. Track performance, debug issues, and gain insights into your AI application's behavior with comprehensive request tracing.",
      "summary": "This document explains Bifrost's built-in observability system, which provides real-time tracing and performance monitoring for AI requests and responses. It details what data is captured, the asynchronous logging architecture, and how to enable or disable tracing through the UI and API.",
      "tags": [
        "observability",
        "request-tracing",
        "monitoring",
        "performance-metrics",
        "logging",
        "llm-ops"
      ],
      "category": "guide",
      "original_file_path": "features-observability-default.md"
    },
    {
      "file_path": "039-features-observability-otel.md",
      "title": "OpenTelemetry (OTel)",
      "url": "https://docs.getbifrost.ai/features/observability/otel.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:43:46.454980514-03:00",
      "description": "> Integrate with OpenTelemetry collectors for enterprise observability and distributed tracing",
      "summary": "This document explains how to integrate Bifrost with OpenTelemetry collectors to enable distributed tracing and observability for LLM operations using various trace formats.",
      "tags": [
        "opentelemetry",
        "otel",
        "distributed-tracing",
        "observability",
        "monitoring",
        "tracing-plugin"
      ],
      "category": "configuration",
      "original_file_path": "features-observability-otel.md"
    },
    {
      "file_path": "041-features-plugins-mocker.md",
      "title": "Mocker",
      "url": "https://docs.getbifrost.ai/features/plugins/mocker.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:43:48.870779025-03:00",
      "description": "> Mock AI provider responses for testing, development, and simulation purposes.",
      "summary": "This document provides instructions for using the Mocker plugin to simulate AI provider responses, covering installation, configuration rules, and advanced features like latency simulation and dynamic data generation.",
      "tags": [
        "ai-mocking",
        "go",
        "bifrost",
        "testing",
        "api-simulation",
        "mocking-framework"
      ],
      "category": "guide",
      "original_file_path": "features-plugins-mocker.md"
    },
    {
      "file_path": "040-features-plugins-jsonparser.md",
      "title": "JSON Parser",
      "url": "https://docs.getbifrost.ai/features/plugins/jsonparser.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:43:48.452417044-03:00",
      "description": "> A simple Bifrost plugin that handles partial JSON chunks in streaming responses by making them valid JSON objects.",
      "summary": "This document explains the Bifrost JSON Parser plugin, which automatically repairs partial JSON chunks in streaming responses to ensure they are valid for immediate processing. It details configuration options, usage modes for global or per-request activation, and internal memory management for stale content.",
      "tags": [
        "bifrost-plugin",
        "json-parsing",
        "streaming-responses",
        "ai-integration",
        "go-library",
        "data-validation"
      ],
      "category": "guide",
      "original_file_path": "features-plugins-jsonparser.md"
    },
    {
      "file_path": "042-features-semantic-caching.md",
      "title": "Semantic Caching",
      "url": "https://docs.getbifrost.ai/features/semantic-caching.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:43:49.862371381-03:00",
      "description": "> Intelligent response caching based on semantic similarity. Reduce costs and latency by serving cached responses for semantically similar requests.",
      "summary": "This document explains how to implement semantic caching using vector similarity search to reduce AI latency and API costs. It provides detailed setup instructions for vector stores and configuration options for the semantic cache plugin.",
      "tags": [
        "semantic-caching",
        "vector-search",
        "ai-infrastructure",
        "performance-optimization",
        "weaviate",
        "embeddings"
      ],
      "category": "guide",
      "original_file_path": "features-semantic-caching.md"
    },
    {
      "file_path": "023-integrations-anthropic-sdk-files-and-batch.md",
      "title": "Files and Batch API",
      "url": "https://docs.getbifrost.ai/integrations/anthropic-sdk/files-and-batch.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:43:51.135389172-03:00",
      "description": "> Upload files and create batch jobs for asynchronous processing using the Anthropic SDK through Bifrost across multiple providers.",
      "summary": "This document explains how to utilize the Anthropic SDK with Bifrost to perform cross-provider file management and asynchronous batch processing across Anthropic, OpenAI, and Gemini.",
      "tags": [
        "anthropic-sdk",
        "batch-api",
        "files-api",
        "cross-provider-routing",
        "asynchronous-processing",
        "bifrost"
      ],
      "category": "guide",
      "original_file_path": "integrations-anthropic-sdk-files-and-batch.md"
    },
    {
      "file_path": "043-features-telemetry.md",
      "title": "Telemetry",
      "url": "https://docs.getbifrost.ai/features/telemetry.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:43:50.166894512-03:00",
      "description": "> Comprehensive Prometheus-based monitoring for Bifrost Gateway with custom metrics and labels.",
      "summary": "This document details the Prometheus-based telemetry system for Bifrost Gateway, covering HTTP transport metrics, AI provider performance tracking, and cost monitoring.",
      "tags": [
        "prometheus",
        "monitoring",
        "telemetry",
        "ai-gateway",
        "metrics",
        "observability",
        "cost-tracking"
      ],
      "category": "reference",
      "original_file_path": "features-telemetry.md"
    },
    {
      "file_path": "024-integrations-bedrock-sdk-files-and-batch.md",
      "title": "Files and Batch API",
      "url": "https://docs.getbifrost.ai/integrations/bedrock-sdk/files-and-batch.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:43:54.490838461-03:00",
      "description": "> Manage S3-based files and batch inference jobs using the AWS Bedrock SDK (boto3) through Bifrost across multiple providers.",
      "summary": "This document explains how to use the AWS Bedrock SDK (boto3) with Bifrost to manage files and batch inference jobs across multiple AI providers using cross-provider routing.",
      "tags": [
        "aws-bedrock",
        "boto3",
        "batch-inference",
        "file-management",
        "cross-provider-routing",
        "s3-api"
      ],
      "category": "guide",
      "original_file_path": "integrations-bedrock-sdk-files-and-batch.md"
    },
    {
      "file_path": "019-integrations-anthropic-sdk-overview.md",
      "title": "Overview",
      "url": "https://docs.getbifrost.ai/integrations/anthropic-sdk/overview.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:43:54.311863568-03:00",
      "description": "> Use Bifrost as a drop-in replacement for Anthropic API with full compatibility and enhanced features.",
      "summary": "This document explains how to use Bifrost as a drop-in replacement for the Anthropic API, enabling multi-provider support and advanced features while maintaining compatibility with existing Anthropic SDKs.",
      "tags": [
        "anthropic-api",
        "api-proxy",
        "multi-provider",
        "sdk-integration",
        "protocol-adaptation",
        "load-balancing"
      ],
      "category": "guide",
      "original_file_path": "integrations-anthropic-sdk-overview.md"
    },
    {
      "file_path": "020-integrations-bedrock-sdk-overview.md",
      "title": "Overview",
      "url": "https://docs.getbifrost.ai/integrations/bedrock-sdk/overview.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:43:55.633975422-03:00",
      "description": "> Use Bifrost as a Bedrock-compatible gateway for the Converse and Invoke APIs, with Bifrost features on top.",
      "summary": "This document explains how to integrate Bifrost as a Bedrock-compatible gateway using the Converse and Invoke APIs with the AWS SDK. It details setup procedures, streaming implementations, and how to apply Bifrost's governance and load-balancing features to Bedrock-based architectures.",
      "tags": [
        "aws-bedrock",
        "bifrost-gateway",
        "boto3-integration",
        "api-protocol-adaptation",
        "llm-governance",
        "streaming-api"
      ],
      "category": "guide",
      "original_file_path": "integrations-bedrock-sdk-overview.md"
    },
    {
      "file_path": "025-integrations-langchain-sdk.md",
      "title": "Langchain SDK",
      "url": "https://docs.getbifrost.ai/integrations/langchain-sdk.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:43:56.068132133-03:00",
      "description": "> Use Bifrost as a drop-in proxy for Langchain applications with zero code changes.",
      "summary": "This document provides instructions on integrating Bifrost as a drop-in proxy for Langchain applications to enable enterprise features like governance, observability, and semantic caching with minimal configuration changes.",
      "tags": [
        "langchain",
        "sdk-integration",
        "proxy-setup",
        "python",
        "javascript",
        "ai-governance",
        "multi-provider"
      ],
      "category": "guide",
      "original_file_path": "integrations-langchain-sdk.md"
    },
    {
      "file_path": "021-integrations-genai-sdk-overview.md",
      "title": "Overview",
      "url": "https://docs.getbifrost.ai/integrations/genai-sdk/overview.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:43:55.643634716-03:00",
      "description": "> Use Bifrost as a drop-in replacement for Google GenAI API with full compatibility and enhanced features.",
      "summary": "This document explains how to integrate Bifrost as a drop-in replacement for the Google GenAI API, enabling features like multi-provider support and governance through existing SDKs.",
      "tags": [
        "google-genai-api",
        "api-compatibility",
        "multi-provider",
        "bifrost-integration",
        "python-sdk",
        "javascript-sdk"
      ],
      "category": "guide",
      "original_file_path": "integrations-genai-sdk-overview.md"
    },
    {
      "file_path": "027-integrations-openai-sdk-files-and-batch.md",
      "title": "Files and Batch API",
      "url": "https://docs.getbifrost.ai/integrations/openai-sdk/files-and-batch.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:44:00.755868064-03:00",
      "description": "> Upload files and create batch jobs for asynchronous processing using the OpenAI SDK through Bifrost across multiple providers.",
      "summary": "This document explains how to use Bifrost to manage files and execute asynchronous batch jobs across multiple AI providers using the OpenAI SDK interface.",
      "tags": [
        "bifrost",
        "openai-sdk",
        "files-api",
        "batch-api",
        "cross-provider-routing",
        "asynchronous-processing"
      ],
      "category": "guide",
      "original_file_path": "integrations-openai-sdk-files-and-batch.md"
    },
    {
      "file_path": "018-integrations-what-is-an-integration.md",
      "title": "What is an integration?",
      "url": "https://docs.getbifrost.ai/integrations/what-is-an-integration.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:44:00.869237925-03:00",
      "description": "> Protocol adapters that translate between Bifrost's unified API and provider-specific API formats like OpenAI, Anthropic, and Google GenAI.",
      "summary": "This document defines Bifrost integrations as protocol adapters that translate between a unified gateway API and various AI provider formats to simplify multi-model management and migration.",
      "tags": [
        "integrations",
        "protocol-adapters",
        "api-gateway",
        "llm-providers",
        "migration-strategies",
        "multi-provider-support"
      ],
      "category": "concept",
      "original_file_path": "integrations-what-is-an-integration.md"
    },
    {
      "file_path": "026-integrations-litellm-sdk.md",
      "title": "LiteLLM SDK",
      "url": "https://docs.getbifrost.ai/integrations/litellm-sdk.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:44:00.423179844-03:00",
      "description": "> Use Bifrost as a drop-in proxy for LiteLLM applications with zero code changes.",
      "summary": "This document explains how to integrate the LiteLLM SDK with Bifrost to add enterprise features like governance and semantic caching to existing AI workflows. It provides instructions for configuring the base URL, handling multiple providers, and managing API keys through the proxy.",
      "tags": [
        "litellm-sdk",
        "bifrost-proxy",
        "multi-provider-ai",
        "api-governance",
        "semantic-caching",
        "python-integration",
        "enterprise-features"
      ],
      "category": "guide",
      "original_file_path": "integrations-litellm-sdk.md"
    },
    {
      "file_path": "022-integrations-openai-sdk-overview.md",
      "title": "Overview",
      "url": "https://docs.getbifrost.ai/integrations/openai-sdk/overview.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:44:00.861310744-03:00",
      "description": "> Use Bifrost as a drop-in replacement for OpenAI API with full compatibility and enhanced features.",
      "summary": "This document explains how to integrate Bifrost as a drop-in replacement for the OpenAI API, allowing users to leverage advanced features like multi-provider support and governance while maintaining existing SDK architectures.",
      "tags": [
        "openai-compatibility",
        "multi-provider",
        "api-gateway",
        "sdk-integration",
        "bifrost",
        "proxy-configuration"
      ],
      "category": "guide",
      "original_file_path": "integrations-openai-sdk-overview.md"
    },
    {
      "file_path": "028-integrations-pydanticai-sdk.md",
      "title": "Pydantic AI SDK",
      "url": "https://docs.getbifrost.ai/integrations/pydanticai-sdk.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:44:00.868697501-03:00",
      "description": "> Use Bifrost as a drop-in proxy for Pydantic AI agents with zero code changes.",
      "summary": "This document explains how to integrate the Pydantic AI SDK with Bifrost as a drop-in proxy to enable enterprise features like governance, observability, and semantic caching.",
      "tags": [
        "pydantic-ai",
        "bifrost",
        "python-sdk",
        "llm-agents",
        "proxy-configuration",
        "ai-governance"
      ],
      "category": "guide",
      "original_file_path": "integrations-pydanticai-sdk.md"
    },
    {
      "file_path": "046-mcp-code-mode.md",
      "title": "Code Mode",
      "url": "https://docs.getbifrost.ai/mcp/code-mode.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:44:06.698598364-03:00",
      "description": "> AI writes TypeScript to orchestrate tools. Reduces token usage by 50%+ when using multiple MCP servers.",
      "summary": "This document explains Code Mode, a feature that optimizes LLM tool orchestration by using TypeScript to manage multiple MCP servers through a sandboxed execution environment.",
      "tags": [
        "mcp-server",
        "code-mode",
        "token-optimization",
        "typescript-orchestration",
        "performance-tuning",
        "tool-management"
      ],
      "category": "concept",
      "original_file_path": "mcp-code-mode.md"
    },
    {
      "file_path": "048-mcp-filtering.md",
      "title": "Tool Filtering",
      "url": "https://docs.getbifrost.ai/mcp/filtering.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:44:07.368701557-03:00",
      "description": "> Control which MCP tools are available at the client, request, and virtual key levels.",
      "summary": "This document explains how to control MCP tool availability in Bifrost through three hierarchical levels: client configuration, request-level headers, and virtual key settings.",
      "tags": [
        "mcp",
        "tool-filtering",
        "access-control",
        "bifrost-gateway",
        "sdk-configuration",
        "virtual-keys"
      ],
      "category": "guide",
      "original_file_path": "mcp-filtering.md"
    },
    {
      "file_path": "047-mcp-connecting-to-servers.md",
      "title": "Connecting to MCP Servers",
      "url": "https://docs.getbifrost.ai/mcp/connecting-to-servers.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:44:06.904082338-03:00",
      "description": "> Connect Bifrost to external MCP servers via STDIO, HTTP, or SSE protocols.",
      "summary": "This document explains how to connect Bifrost to external MCP servers using STDIO, HTTP, and SSE protocols to discover and execute tools. It provides detailed setup instructions for both the Web UI and API, including configuration parameters and management of discovered tools.",
      "tags": [
        "mcp-server",
        "connection-protocols",
        "bifrost-gateway",
        "stdio-connection",
        "http-integration",
        "sse-streaming",
        "tool-discovery",
        "api-configuration"
      ],
      "category": "guide",
      "original_file_path": "mcp-connecting-to-servers.md"
    },
    {
      "file_path": "045-mcp-agent-mode.md",
      "title": "Agent Mode (Auto-Execution)",
      "url": "https://docs.getbifrost.ai/mcp/agent-mode.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:44:05.917996058-03:00",
      "description": "> Enable autonomous tool execution with configurable auto-approval for building AI agents.",
      "summary": "This document explains how to enable and configure Agent Mode for autonomous tool execution, allowing AI agents to run tools without manual approval within defined safety limits.",
      "tags": [
        "agent-mode",
        "autonomous-execution",
        "tool-calling",
        "mcp-gateway",
        "automation",
        "bifrost-sdk"
      ],
      "category": "guide",
      "original_file_path": "mcp-agent-mode.md"
    },
    {
      "file_path": "049-mcp-gateway-url.md",
      "title": "MCP Gateway URL",
      "url": "https://docs.getbifrost.ai/mcp/gateway-url.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:44:07.637538957-03:00",
      "description": "> Expose Bifrost as an MCP server for Claude Desktop and other MCP clients.",
      "summary": "This document explains how to expose Bifrost Gateway as an MCP server for external clients, covering JSON-RPC/SSE endpoints, authentication, and tool filtering. It also details advanced features like health monitoring and dynamic tool discovery.",
      "tags": [
        "mcp-server",
        "bifrost-gateway",
        "json-rpc",
        "sse-stream",
        "virtual-keys",
        "tool-governance",
        "health-monitoring"
      ],
      "category": "guide",
      "original_file_path": "mcp-gateway-url.md"
    },
    {
      "file_path": "053-plugins-building-dynamic-binary.md",
      "title": "Building Dynamically Linked Bifrost Binary",
      "url": "https://docs.getbifrost.ai/plugins/building-dynamic-binary.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:44:12.977153448-03:00",
      "description": "> Learn how to build a dynamically linked Bifrost binary required for custom plugin support",
      "summary": "This document explains how to compile a dynamically linked Bifrost binary to enable support for custom Go-based plugins on Linux and macOS systems.",
      "tags": [
        "bifrost",
        "dynamic-linking",
        "go-plugins",
        "compilation",
        "cgo",
        "docker-build",
        "linux-deployment"
      ],
      "category": "guide",
      "original_file_path": "plugins-building-dynamic-binary.md"
    },
    {
      "file_path": "051-mcp-tool-hosting.md",
      "title": "Tool Hosting",
      "url": "https://docs.getbifrost.ai/mcp/tool-hosting.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:44:12.782948206-03:00",
      "description": "> Register custom tools directly in your Go application without external MCP servers.",
      "summary": "This document explains how to register and host custom tools directly within a Go application using the Bifrost SDK. It covers defining tool schemas, implementing execution handlers, and registering tools to run in-process via an internal MCP server.",
      "tags": [
        "go-sdk",
        "tool-hosting",
        "mcp-server",
        "custom-tools",
        "function-calling",
        "in-process-tools"
      ],
      "category": "guide",
      "original_file_path": "mcp-tool-hosting.md"
    },
    {
      "file_path": "044-mcp-overview.md",
      "title": "Overview",
      "url": "https://docs.getbifrost.ai/mcp/overview.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:44:11.46836485-03:00",
      "description": "> Enable AI models to discover and execute external tools dynamically. Transform static chat models into action-capable agents.",
      "summary": "This document provides an overview of the Model Context Protocol (MCP) integration in Bifrost, explaining how it enables AI models to discover and execute external tools through a security-first architecture.",
      "tags": [
        "model-context-protocol",
        "mcp-server",
        "tool-execution",
        "ai-agents",
        "security-design",
        "bifrost-gateway"
      ],
      "category": "concept",
      "original_file_path": "mcp-overview.md"
    },
    {
      "file_path": "050-mcp-tool-execution.md",
      "title": "Tool Execution",
      "url": "https://docs.getbifrost.ai/mcp/tool-execution.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:44:11.938047073-03:00",
      "description": "> Execute MCP tools with full control over approval and conversation flow.",
      "summary": "Explains how to manually execute Model Context Protocol (MCP) tools within the Bifrost platform to manage approval workflows, security validation, and conversation history.",
      "tags": [
        "mcp",
        "tool-execution",
        "workflow-control",
        "bifrost",
        "api-integration",
        "go-sdk"
      ],
      "category": "guide",
      "original_file_path": "mcp-tool-execution.md"
    },
    {
      "file_path": "052-plugins-getting-started.md",
      "title": "Getting Started",
      "url": "https://docs.getbifrost.ai/plugins/getting-started.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:44:14.051990117-03:00",
      "description": "> Learn how to extend Bifrost's functionality by creating custom plugins that intercept and modify requests and responses.",
      "summary": "This document introduces Bifrost's plugin system, explaining how to extend gateway functionality by intercepting and modifying requests and responses using Go shared objects. It details the plugin architecture, building process, platform requirements, and execution lifecycle.",
      "tags": [
        "bifrost-gateway",
        "go-plugins",
        "dynamic-loading",
        "shared-objects",
        "request-lifecycle",
        "middleware",
        "plugin-architecture"
      ],
      "category": "guide",
      "original_file_path": "plugins-getting-started.md"
    },
    {
      "file_path": "058-providers-custom-providers.md",
      "title": "Custom Providers",
      "url": "https://docs.getbifrost.ai/providers/custom-providers.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:44:18.799384965-03:00",
      "description": "> Create custom provider configurations with specific request type restrictions, custom naming, and controlled access patterns.",
      "summary": "This document explains how to create and configure custom provider instances to restrict request types, customize naming, and control access patterns for base providers. It provides setup instructions using the Web UI, API, configuration files, and Go SDK.",
      "tags": [
        "custom-providers",
        "provider-configuration",
        "access-control",
        "request-type-restriction",
        "api-management",
        "sdk-configuration"
      ],
      "category": "configuration",
      "original_file_path": "providers-custom-providers.md"
    },
    {
      "file_path": "059-providers-performance.md",
      "title": "Performance Tuning",
      "url": "https://docs.getbifrost.ai/providers/performance.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:44:18.882288876-03:00",
      "description": "> Optimize Bifrost for high throughput with concurrency, buffer sizing, and memory pool configuration",
      "summary": "This document provides instructions and formulas for optimizing Bifrost performance through the configuration of concurrency, buffer sizes, and memory pools to handle high throughput.",
      "tags": [
        "performance-tuning",
        "concurrency-control",
        "buffer-management",
        "memory-optimization",
        "throughput",
        "resource-allocation",
        "bifrost-config"
      ],
      "category": "configuration",
      "original_file_path": "providers-performance.md"
    },
    {
      "file_path": "054-plugins-migration-guide.md",
      "title": "Plugin Migration Guide",
      "url": "https://docs.getbifrost.ai/plugins/migration-guide.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:44:17.779961578-03:00",
      "description": "> How to migrate your Bifrost plugins from v1.3.x to v1.4.x",
      "summary": "This document provides instructions and code examples for migrating Bifrost plugins from v1.3.x to v1.4.x, focusing on the transition from legacy transport interceptors to the new dual-hook HTTP pattern.",
      "tags": [
        "bifrost",
        "plugin-migration",
        "golang",
        "http-transport",
        "wasm-support",
        "api-update"
      ],
      "category": "guide",
      "original_file_path": "plugins-migration-guide.md"
    },
    {
      "file_path": "055-plugins-writing-go-plugin.md",
      "title": "Writing Go Plugins",
      "url": "https://docs.getbifrost.ai/plugins/writing-go-plugin.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:44:18.207588853-03:00",
      "description": "> Step-by-step guide to creating native Go plugins for Bifrost using shared object (.so) files",
      "summary": "This guide provides step-by-step instructions for developing native Go plugins for Bifrost using shared object files. It covers project initialization, interface implementation, and the lifecycle hooks required to intercept and modify traffic.",
      "tags": [
        "go-plugins",
        "bifrost",
        "shared-objects",
        "middleware",
        "plugin-development",
        "go-modules"
      ],
      "category": "guide",
      "original_file_path": "plugins-writing-go-plugin.md"
    },
    {
      "file_path": "056-plugins-writing-wasm-plugin.md",
      "title": "Writing WASM Plugins",
      "url": "https://docs.getbifrost.ai/plugins/writing-wasm-plugin.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:44:18.796435546-03:00",
      "description": "> Build cross-platform Bifrost plugins using WebAssembly with TypeScript, Go, or Rust",
      "summary": "This document explains how to build cross-platform WebAssembly plugins for the Bifrost Enterprise platform using various programming languages. It outlines the mandatory plugin interface, memory management protocols, and specific implementation workflows for TypeScript and Go.",
      "tags": [
        "webassembly",
        "wasm-plugins",
        "bifrost-enterprise",
        "plugin-development",
        "assemblyscript",
        "tinygo",
        "memory-management"
      ],
      "category": "guide",
      "original_file_path": "plugins-writing-wasm-plugin.md"
    },
    {
      "file_path": "060-providers-provider-routing.md",
      "title": "Provider Routing",
      "url": "https://docs.getbifrost.ai/providers/provider-routing.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:44:22.990722935-03:00",
      "description": "> Understand how Bifrost routes requests across AI providers using governance rules and adaptive load balancing.",
      "summary": "This document explains how Bifrost manages request routing across multiple AI providers using governance rules, adaptive load balancing, and a centralized Model Catalog. It details the logic for model discovery, provider mapping, and data synchronization between pricing sources and provider APIs.",
      "tags": [
        "provider-routing",
        "model-catalog",
        "load-balancing",
        "ai-governance",
        "request-routing",
        "multi-provider"
      ],
      "category": "concept",
      "original_file_path": "providers-provider-routing.md"
    },
    {
      "file_path": "063-providers-supported-providers-azure.md",
      "title": "Azure",
      "url": "https://docs.getbifrost.ai/providers/supported-providers/azure.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:44:23.58597792-03:00",
      "description": "> Azure OpenAI Service API conversion guide - deployment management, authentication, multi-model support",
      "summary": "This document provides a technical guide for using the Bifrost API to interface with Azure OpenAI Service, covering deployment mapping, authentication methods, and multi-model support.",
      "tags": [
        "azure-openai",
        "api-integration",
        "deployment-mapping",
        "authentication",
        "multi-model",
        "anthropic-on-azure",
        "streaming"
      ],
      "category": "guide",
      "original_file_path": "providers-supported-providers-azure.md"
    },
    {
      "file_path": "062-providers-supported-providers-anthropic.md",
      "title": "Anthropic",
      "url": "https://docs.getbifrost.ai/providers/supported-providers/anthropic.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:44:23.317291808-03:00",
      "description": "> Anthropic API conversion guide - structural differences, message handling, thinking/reasoning, and tool conversion",
      "summary": "This document outlines the technical mapping and structural transformations required to convert OpenAI-formatted requests into Anthropic-compatible API calls, including parameter renaming and message restructuring.",
      "tags": [
        "anthropic-api",
        "api-conversion",
        "message-handling",
        "parameter-mapping",
        "tool-conversion",
        "bifrost-gateway"
      ],
      "category": "guide",
      "original_file_path": "providers-supported-providers-anthropic.md"
    },
    {
      "file_path": "061-providers-reasoning.md",
      "title": "Reasoning",
      "url": "https://docs.getbifrost.ai/providers/reasoning.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:44:23.12946929-03:00",
      "description": "> Cross-provider reference for reasoning and thinking capabilities in AI models",
      "summary": "Provides a cross-provider reference for implementing reasoning and thinking capabilities in AI models through a normalized API structure.",
      "tags": [
        "reasoning-capabilities",
        "ai-providers",
        "api-normalization",
        "configuration",
        "llm-parameters"
      ],
      "category": "reference",
      "original_file_path": "providers-reasoning.md"
    },
    {
      "file_path": "064-providers-supported-providers-bedrock.md",
      "title": "AWS Bedrock",
      "url": "https://docs.getbifrost.ai/providers/supported-providers/bedrock.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:44:26.724324613-03:00",
      "description": "> AWS Bedrock API conversion guide - model families, parameter mapping, message handling, reasoning/thinking, tool conversion, and AWS authentication",
      "summary": "This document explains how to convert API requests between OpenAI formats and AWS Bedrock's specific model requirements across various model families. It covers parameter mapping, message handling, tool conversion, and authentication configurations for seamless integration.",
      "tags": [
        "aws-bedrock",
        "api-conversion",
        "parameter-mapping",
        "model-families",
        "chat-completions",
        "tool-restructuring",
        "request-signing"
      ],
      "category": "guide",
      "original_file_path": "providers-supported-providers-bedrock.md"
    },
    {
      "file_path": "066-providers-supported-providers-cohere.md",
      "title": "Cohere",
      "url": "https://docs.getbifrost.ai/providers/supported-providers/cohere.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:44:29.479126779-03:00",
      "description": "> Cohere API conversion guide - parameter mapping, message handling, reasoning/thinking, and tool conversion",
      "summary": "This document provides a technical guide for converting OpenAI-formatted API requests to Cohere's structure, detailing parameter mapping, tool conversion, and reasoning transformations.",
      "tags": [
        "cohere",
        "api-integration",
        "parameter-mapping",
        "chat-completions",
        "tool-conversion",
        "reasoning-capabilities",
        "streaming-events"
      ],
      "category": "guide",
      "original_file_path": "providers-supported-providers-cohere.md"
    },
    {
      "file_path": "067-providers-supported-providers-elevenlabs.md",
      "title": "ElevenLabs",
      "url": "https://docs.getbifrost.ai/providers/supported-providers/elevenlabs.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:44:29.530215856-03:00",
      "description": "> ElevenLabs API conversion guide - text-to-speech, speech-to-text, voice settings, and model management",
      "summary": "This document provides a technical guide for integrating ElevenLabs audio services, covering text-to-speech, speech-to-text, and advanced voice configuration parameters.",
      "tags": [
        "elevenlabs",
        "text-to-speech",
        "speech-to-text",
        "voice-settings",
        "api-integration",
        "audio-processing"
      ],
      "category": "guide",
      "original_file_path": "providers-supported-providers-elevenlabs.md"
    },
    {
      "file_path": "065-providers-supported-providers-cerebras.md",
      "title": "Cerebras",
      "url": "https://docs.getbifrost.ai/providers/supported-providers/cerebras.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:44:28.680894131-03:00",
      "description": "> Cerebras API conversion guide - OpenAI-compatible format, full feature support, streaming, tool calling, and parameter handling",
      "summary": "This document outlines the integration of the Cerebras API into an OpenAI-compatible framework, detailing supported features like chat completions, streaming, and tool calling alongside specific parameter mappings.",
      "tags": [
        "cerebras",
        "openai-compatibility",
        "chat-completions",
        "streaming",
        "tool-calling",
        "api-integration",
        "text-completions"
      ],
      "category": "reference",
      "original_file_path": "providers-supported-providers-cerebras.md"
    },
    {
      "file_path": "068-providers-supported-providers-gemini.md",
      "title": "Google Gemini",
      "url": "https://docs.getbifrost.ai/providers/supported-providers/gemini.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:44:31.421401797-03:00",
      "description": "> Google Gemini API conversion guide - request/response transformation, message conversion, tool handling, and streaming behavior",
      "summary": "This document outlines the technical mapping and conversion processes required to translate OpenAI-style API requests and responses into Google Gemini's specific architectural requirements.",
      "tags": [
        "google-gemini",
        "api-conversion",
        "message-transformation",
        "parameter-mapping",
        "tool-calling",
        "reasoning-support"
      ],
      "category": "guide",
      "original_file_path": "providers-supported-providers-gemini.md"
    },
    {
      "file_path": "069-providers-supported-providers-groq.md",
      "title": "Groq",
      "url": "https://docs.getbifrost.ai/providers/supported-providers/groq.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:44:33.932212631-03:00",
      "description": "> Groq API conversion guide - OpenAI-compatible format, parameter handling, text completion fallback, streaming, and tool support",
      "summary": "This document details the integration of Groq's OpenAI-compatible API into Bifrost, covering endpoint support, parameter handling, and fallback mechanisms for non-native features.",
      "tags": [
        "groq",
        "openai-compatibility",
        "chat-completions",
        "api-integration",
        "streaming-support",
        "tool-calling"
      ],
      "category": "guide",
      "original_file_path": "providers-supported-providers-groq.md"
    },
    {
      "file_path": "072-providers-supported-providers-nebius.md",
      "title": "Nebius",
      "url": "https://docs.getbifrost.ai/providers/supported-providers/nebius.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:44:35.530619437-03:00",
      "description": "> Nebius API conversion guide - OpenAI-compatible format, parameter handling, streaming, embeddings, and special features",
      "summary": "This document provides a technical guide for integrating with the Nebius API using OpenAI-compatible formats, detailing supported operations, parameter mappings, and specific features like project IDs.",
      "tags": [
        "nebius",
        "openai-compatible",
        "api-integration",
        "chat-completions",
        "image-generation",
        "embeddings",
        "streaming-api"
      ],
      "category": "guide",
      "original_file_path": "providers-supported-providers-nebius.md"
    },
    {
      "file_path": "070-providers-supported-providers-huggingface.md",
      "title": "Hugging Face",
      "url": "https://docs.getbifrost.ai/providers/supported-providers/huggingface.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:44:34.167556474-03:00",
      "description": "> Detailed guide on Hugging Face provider implementation specifics, including model aliases and unique request handling.",
      "summary": "This guide explains the technical implementation of the Hugging Face provider in Bifrost, detailing model aliasing, multi-provider routing logic, and specific request handling for various AI tasks.",
      "tags": [
        "hugging-face",
        "bifrost",
        "inference-providers",
        "model-aliasing",
        "api-integration",
        "request-handling"
      ],
      "category": "guide",
      "original_file_path": "providers-supported-providers-huggingface.md"
    },
    {
      "file_path": "071-providers-supported-providers-mistral.md",
      "title": "Mistral",
      "url": "https://docs.getbifrost.ai/providers/supported-providers/mistral.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:44:34.768117133-03:00",
      "description": "> Mistral API conversion guide - parameter mapping, message handling, tool support, transcription, and streaming behavior",
      "summary": "This document provides a technical guide for converting OpenAI-formatted requests to the Mistral API, detailing parameter mapping, tool support constraints, and audio transcription handling.",
      "tags": [
        "mistral-ai",
        "api-conversion",
        "openai-compatibility",
        "chat-completions",
        "tool-calling",
        "audio-transcription",
        "parameter-mapping"
      ],
      "category": "reference",
      "original_file_path": "providers-supported-providers-mistral.md"
    },
    {
      "file_path": "073-providers-supported-providers-ollama.md",
      "title": "Ollama",
      "url": "https://docs.getbifrost.ai/providers/supported-providers/ollama.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:44:38.000251192-03:00",
      "description": "> Ollama API conversion guide - local inference, OpenAI-compatible format, streaming, tool calling, and embeddings",
      "summary": "This guide explains how to integrate and configure Ollama for local model inference using its OpenAI-compatible API, covering supported features like chat completions, embeddings, and environment setup.",
      "tags": [
        "ollama",
        "openai-compatibility",
        "local-inference",
        "chat-completions",
        "embeddings",
        "self-hosted",
        "api-configuration"
      ],
      "category": "guide",
      "original_file_path": "providers-supported-providers-ollama.md"
    },
    {
      "file_path": "074-providers-supported-providers-openai.md",
      "title": "OpenAI",
      "url": "https://docs.getbifrost.ai/providers/supported-providers/openai.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:44:38.761380193-03:00",
      "description": "> OpenAI API conversion guide - what to know when using OpenAI through Bifrost",
      "summary": "This document outlines the integration of OpenAI's API with Bifrost, detailing supported operations, endpoints, and specific request parameters for chat completions.",
      "tags": [
        "openai",
        "bifrost",
        "api-reference",
        "chat-completions",
        "api-integration",
        "request-parameters"
      ],
      "category": "reference",
      "original_file_path": "providers-supported-providers-openai.md"
    },
    {
      "file_path": "075-providers-supported-providers-openrouter.md",
      "title": "OpenRouter",
      "url": "https://docs.getbifrost.ai/providers/supported-providers/openrouter.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:44:39.805010565-03:00",
      "description": "> OpenRouter API conversion guide - routing to multiple providers, reasoning support, parameter handling, and streaming",
      "summary": "This document outlines the integration and conversion logic for the OpenRouter API, detailing supported operations, reasoning model parameters, and specific handling for multi-provider routing.",
      "tags": [
        "openrouter",
        "api-integration",
        "chat-completions",
        "reasoning-models",
        "parameter-mapping",
        "llm-routing"
      ],
      "category": "guide",
      "original_file_path": "providers-supported-providers-openrouter.md"
    },
    {
      "file_path": "076-providers-supported-providers-parasail.md",
      "title": "Parasail",
      "url": "https://docs.getbifrost.ai/providers/supported-providers/parasail.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:44:40.017170008-03:00",
      "description": "> Parasail API conversion guide - OpenAI-compatible format, streaming support, tool calling, and parameter handling",
      "summary": "This document provides a technical guide on using the Parasail API, detailing its OpenAI-compatible chat completion capabilities, streaming support, and parameter handling.",
      "tags": [
        "parasail",
        "openai-compatible",
        "chat-completions",
        "api-integration",
        "streaming",
        "tool-calling"
      ],
      "category": "guide",
      "original_file_path": "providers-supported-providers-parasail.md"
    },
    {
      "file_path": "057-providers-supported-providers-overview.md",
      "title": "Overview",
      "url": "https://docs.getbifrost.ai/providers/supported-providers/overview.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:44:39.891306744-03:00",
      "description": "> Bifrost supports multiple AI providers with consistent OpenAI-compatible response formats, enabling seamless provider switching without code changes.",
      "summary": "This document provides an overview of Bifrost's unified OpenAI-compatible interface and a detailed support matrix for various AI providers and features.",
      "tags": [
        "ai-providers",
        "openai-compatibility",
        "api-gateway",
        "feature-matrix",
        "multi-model-support",
        "integrations"
      ],
      "category": "reference",
      "original_file_path": "providers-supported-providers-overview.md"
    },
    {
      "file_path": "080-providers-supported-providers-xai.md",
      "title": "xAI",
      "url": "https://docs.getbifrost.ai/providers/supported-providers/xai.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:44:45.118440949-03:00",
      "description": "> xAI API conversion guide - OpenAI-compatible format, Grok models, vision support, reasoning, and parameter handling",
      "summary": "This document provides an integration guide for the xAI API, detailing its OpenAI-compatible endpoints, supported Grok models, vision capabilities, and parameter filtering logic.",
      "tags": [
        "xai",
        "grok",
        "openai-compatible",
        "chat-completions",
        "vision-api",
        "reasoning-models",
        "api-integration"
      ],
      "category": "guide",
      "original_file_path": "providers-supported-providers-xai.md"
    },
    {
      "file_path": "078-providers-supported-providers-sgl.md",
      "title": "SGLang",
      "url": "https://docs.getbifrost.ai/providers/supported-providers/sgl.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:44:44.226930775-03:00",
      "description": "> SGL/SGLang API conversion guide - OpenAI-compatible format, parameter handling, streaming, tool support",
      "summary": "This document provides a guide for using SGLang as an OpenAI-compatible inference engine, detailing supported endpoints, parameter mapping, and configuration requirements.",
      "tags": [
        "sglang",
        "openai-compatibility",
        "inference-engine",
        "api-reference",
        "chat-completions",
        "text-embeddings"
      ],
      "category": "guide",
      "original_file_path": "providers-supported-providers-sgl.md"
    },
    {
      "file_path": "077-providers-supported-providers-perplexity.md",
      "title": "Perplexity",
      "url": "https://docs.getbifrost.ai/providers/supported-providers/perplexity.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:44:43.296823213-03:00",
      "description": "> Perplexity API conversion guide - OpenAI-compatible with web search integration, parameter mapping, and reasoning support",
      "summary": "This document provides a technical guide for integrating the Perplexity API using an OpenAI-compatible interface, focusing on web search parameters, reasoning effort mapping, and response field conversions.",
      "tags": [
        "perplexity-api",
        "openai-compatibility",
        "web-search",
        "reasoning-effort",
        "chat-completions",
        "api-integration"
      ],
      "category": "guide",
      "original_file_path": "providers-supported-providers-perplexity.md"
    },
    {
      "file_path": "079-providers-supported-providers-vertex.md",
      "title": "Vertex AI",
      "url": "https://docs.getbifrost.ai/providers/supported-providers/vertex.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:44:44.999691285-03:00",
      "description": "> Google Vertex AI API conversion guide - multi-model support, OAuth2 authentication, project/region configuration",
      "summary": "This document explains the integration and conversion logic for Google Vertex AI, detailing how to configure multi-model support, OAuth2 authentication, and request mapping for Gemini and Anthropic models.",
      "tags": [
        "vertex-ai",
        "google-cloud-platform",
        "api-integration",
        "gemini",
        "anthropic-claude",
        "oauth2",
        "model-routing"
      ],
      "category": "guide",
      "original_file_path": "providers-supported-providers-vertex.md"
    },
    {
      "file_path": "005-quickstart-gateway-cli-agents.md",
      "title": "Tools, Editors & CLI Agents",
      "url": "https://docs.getbifrost.ai/quickstart/gateway/cli-agents.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:44:46.492358246-03:00",
      "description": "> Use Bifrost with tools like LibreChat, Claude Code, Codex CLI, Gemini CLI and Qwen Code by just changing the base URL and unlock advanced features.",
      "summary": "This document provides instructions on integrating Bifrost with various AI agents and CLI tools by configuring base URLs to enable universal model access and advanced features. It covers setup procedures for popular platforms like LibreChat and Claude Code while explaining the benefits of Bifrost's compatible endpoints.",
      "tags": [
        "agent-integration",
        "cli-tools",
        "model-compatibility",
        "api-proxy",
        "mcp-tools",
        "librechat",
        "claude-code"
      ],
      "category": "guide",
      "original_file_path": "quickstart-gateway-cli-agents.md"
    },
    {
      "file_path": "008-quickstart-gateway-provider-configuration.md",
      "title": "Provider Configuration",
      "url": "https://docs.getbifrost.ai/quickstart/gateway/provider-configuration.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:44:50.405610298-03:00",
      "description": "> Configure multiple AI providers for custom concurrency, queue sizes, proxy settings, and more.",
      "summary": "This document explains how to set up and manage multiple AI model providers using the Web UI, API, or configuration files. It covers advanced settings such as weighted load balancing, network configurations, and environment variable management for API keys.",
      "tags": [
        "provider-configuration",
        "ai-models",
        "load-balancing",
        "api-keys",
        "environment-variables",
        "multi-provider"
      ],
      "category": "configuration",
      "original_file_path": "quickstart-gateway-provider-configuration.md"
    },
    {
      "file_path": "007-quickstart-gateway-multimodal.md",
      "title": "Multimodal Support",
      "url": "https://docs.getbifrost.ai/quickstart/gateway/multimodal.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:44:50.087723979-03:00",
      "description": "> Process multiple types of content including images, audio, and text with AI models. Bifrost supports vision analysis, image generation, speech synthesis, and audio transcription across various providers.",
      "summary": "This document outlines how to implement multimodal features such as vision analysis, image generation, and audio processing using the Bifrost API.",
      "tags": [
        "multimodal-ai",
        "vision-analysis",
        "image-generation",
        "speech-to-text",
        "text-to-speech",
        "audio-processing"
      ],
      "category": "guide",
      "original_file_path": "quickstart-gateway-multimodal.md"
    },
    {
      "file_path": "003-quickstart-gateway-setting-up.md",
      "title": "Setting Up",
      "url": "https://docs.getbifrost.ai/quickstart/gateway/setting-up.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:44:51.175269171-03:00",
      "description": "> Get Bifrost running as an HTTP API gateway in 30 seconds with zero configuration. Perfect for any programming language.",
      "summary": "This document provides a step-by-step guide for installing and configuring Bifrost, an HTTP API gateway for AI providers, using NPX or Docker.",
      "tags": [
        "installation",
        "docker",
        "npx",
        "api-gateway",
        "configuration",
        "openai-compatibility",
        "ai-routing"
      ],
      "category": "tutorial",
      "original_file_path": "quickstart-gateway-setting-up.md"
    },
    {
      "file_path": "006-quickstart-gateway-integrations.md",
      "title": "Integrations",
      "url": "https://docs.getbifrost.ai/quickstart/gateway/integrations.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:44:48.869997814-03:00",
      "description": "> Use Bifrost as a drop-in replacement for existing AI provider SDKs with zero code changes. Just change the base URL and unlock advanced features.",
      "summary": "This document explains how Bifrost integrations act as protocol adapters to provide drop-in compatibility with existing AI provider SDKs. It describes how users can access advanced features like governance and monitoring by simply changing their API base URL without modifying existing code.",
      "tags": [
        "ai-integrations",
        "sdk-compatibility",
        "drop-in-replacement",
        "bifrost-api",
        "protocol-adapters",
        "sdk-integration"
      ],
      "category": "guide",
      "original_file_path": "quickstart-gateway-integrations.md"
    },
    {
      "file_path": "012-quickstart-go-sdk-context-keys.md",
      "title": "Context Keys",
      "url": "https://docs.getbifrost.ai/quickstart/go-sdk/context-keys.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:44:55.967050203-03:00",
      "description": "> Use context keys to configure request behavior, pass metadata, and access response information throughout the request lifecycle.",
      "summary": "This document explains how to use Go context keys in Bifrost to configure request behavior and access response metadata during the request lifecycle. It provides a detailed reference of available keys for custom headers, API selection, tracking, and debugging.",
      "tags": [
        "go-sdk",
        "context-keys",
        "request-configuration",
        "response-metadata",
        "bifrost",
        "api-integration"
      ],
      "category": "reference",
      "original_file_path": "quickstart-go-sdk-context-keys.md"
    },
    {
      "file_path": "010-quickstart-gateway-tool-calling.md",
      "title": "Tool Calling",
      "url": "https://docs.getbifrost.ai/quickstart/gateway/tool-calling.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:44:55.513575402-03:00",
      "description": "> Enable AI models to use external functions and services by defining tool schemas or connecting to Model Context Protocol (MCP) servers. This allows AI to interact with databases, APIs, file systems, and more.",
      "summary": "This document explains how to enable AI models to interact with external services through custom function calling schemas and Model Context Protocol (MCP) server integrations.",
      "tags": [
        "tool-calling",
        "function-calling",
        "mcp-server",
        "api-integration",
        "model-context-protocol",
        "ai-tools"
      ],
      "category": "guide",
      "original_file_path": "quickstart-gateway-tool-calling.md"
    },
    {
      "file_path": "004-quickstart-gateway-setting-up-auth.md",
      "title": "Setting up auth",
      "url": "https://docs.getbifrost.ai/quickstart/gateway/setting-up-auth.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:44:54.204445132-03:00",
      "description": "> Learn how to enable basic authentication for the Bifrost dashboard to secure your admin interface and API endpoints.",
      "summary": "This document provides instructions for enabling and managing basic authentication to secure the Bifrost dashboard and administrative API endpoints.",
      "tags": [
        "bifrost-security",
        "authentication-setup",
        "dashboard-access",
        "api-security",
        "basic-auth",
        "security-configuration"
      ],
      "category": "configuration",
      "original_file_path": "quickstart-gateway-setting-up-auth.md"
    },
    {
      "file_path": "013-quickstart-go-sdk-logger.md",
      "title": "Logging",
      "url": "https://docs.getbifrost.ai/quickstart/go-sdk/logger.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:44:57.63061638-03:00",
      "description": "> Configure logging for debugging, monitoring, and troubleshooting your Bifrost integration.",
      "summary": "This document explains how to configure and customize logging within the Bifrost integration, covering the default logger, log levels, output formats, and custom logger implementations.",
      "tags": [
        "logging",
        "bifrost",
        "debugging",
        "monitoring",
        "golang",
        "structured-logging",
        "configuration"
      ],
      "category": "guide",
      "original_file_path": "quickstart-go-sdk-logger.md"
    },
    {
      "file_path": "009-quickstart-gateway-streaming.md",
      "title": "Streaming Responses",
      "url": "https://docs.getbifrost.ai/quickstart/gateway/streaming.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:44:54.655690036-03:00",
      "description": "> Receive AI responses in real-time via Server-Sent Events. Perfect for chat applications, audio processing, and real-time transcription where you want immediate results.",
      "summary": "This document explains how to implement real-time streaming for text completions, chat, and audio processing using Server-Sent Events.",
      "tags": [
        "streaming-responses",
        "server-sent-events",
        "real-time-api",
        "chat-completions",
        "text-to-speech",
        "speech-to-text"
      ],
      "category": "guide",
      "original_file_path": "quickstart-gateway-streaming.md"
    },
    {
      "file_path": "015-quickstart-go-sdk-provider-configuration.md",
      "title": "Provider Configuration",
      "url": "https://docs.getbifrost.ai/quickstart/go-sdk/provider-configuration.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:45:01.146010753-03:00",
      "description": "> Configure multiple AI providers for custom concurrency, queue sizes, proxy settings, and more.",
      "summary": "This document explains how to configure multiple AI providers, including managing API keys, weighted load balancing, custom network settings, and concurrency limits.",
      "tags": [
        "ai-providers",
        "load-balancing",
        "api-keys",
        "concurrency-control",
        "network-configuration",
        "error-handling",
        "go-sdk"
      ],
      "category": "configuration",
      "original_file_path": "quickstart-go-sdk-provider-configuration.md"
    },
    {
      "file_path": "011-quickstart-go-sdk-setting-up.md",
      "title": "Setting Up",
      "url": "https://docs.getbifrost.ai/quickstart/go-sdk/setting-up.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:45:01.293021238-03:00",
      "description": "> Get Bifrost running in your Go application in 30 seconds with minimal setup and direct code integration.",
      "summary": "This document provides a quick-start guide for integrating the Bifrost AI gateway into a Go application, covering installation, interface implementation, and basic chat completion requests.",
      "tags": [
        "go-sdk",
        "bifrost-setup",
        "quick-start",
        "ai-gateway",
        "openai-integration",
        "multi-provider"
      ],
      "category": "tutorial",
      "original_file_path": "quickstart-go-sdk-setting-up.md"
    },
    {
      "file_path": "014-quickstart-go-sdk-multimodal.md",
      "title": "Multimodal Support",
      "url": "https://docs.getbifrost.ai/quickstart/go-sdk/multimodal.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:45:00.895110894-03:00",
      "description": "> Process multiple types of content including images, audio, and text with AI models. Bifrost supports vision analysis, image generation, speech synthesis, and audio transcription across various providers.",
      "summary": "This document explains how to implement multimodal capabilities using the Bifrost SDK, including vision analysis, image generation, and audio processing. It provides instructions for integrating diverse content types into AI model workflows.",
      "tags": [
        "multimodal",
        "vision-analysis",
        "image-generation",
        "speech-to-text",
        "text-to-speech",
        "go-sdk",
        "audio-processing"
      ],
      "category": "guide",
      "original_file_path": "quickstart-go-sdk-multimodal.md"
    },
    {
      "file_path": "016-quickstart-go-sdk-streaming.md",
      "title": "Streaming Responses",
      "url": "https://docs.getbifrost.ai/quickstart/go-sdk/streaming.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:45:02.106272321-03:00",
      "description": "> Receive AI responses in real-time as they're generated. Perfect for chat applications, audio processing, and real-time transcription where you want immediate results.",
      "summary": "This document explains how to implement real-time streaming for text, chat, speech synthesis, and transcription using the Bifrost SDK. It provides Go code examples and best practices for handling incremental data chunks and managing stream lifecycle.",
      "tags": [
        "streaming-api",
        "real-time-responses",
        "go-sdk",
        "text-to-speech",
        "speech-to-text",
        "chat-completions"
      ],
      "category": "guide",
      "original_file_path": "quickstart-go-sdk-streaming.md"
    },
    {
      "file_path": "017-quickstart-go-sdk-tool-calling.md",
      "title": "Tool Calling",
      "url": "https://docs.getbifrost.ai/quickstart/go-sdk/tool-calling.md",
      "source": "llms",
      "fetched_at": "2026-01-21T19:45:04.03278844-03:00",
      "description": "> Enable AI models to use external functions and services by defining tool schemas or connecting to Model Context Protocol (MCP) servers. This allows AI to interact with databases, APIs, file systems, and more.",
      "summary": "This document explains how to enable AI models to interact with external functions and services by defining custom tool schemas or connecting to Model Context Protocol (MCP) servers.",
      "tags": [
        "tool-calling",
        "mcp",
        "function-calling",
        "go",
        "chat-completion",
        "ai-integration"
      ],
      "category": "guide",
      "original_file_path": "quickstart-go-sdk-tool-calling.md"
    },
    {
      "file_path": "002-bifrost-enterprise.md",
      "title": "Bifrost - AI Gateway",
      "url": "https://www.getmaxim.ai/bifrost/enterprise",
      "source": "llms",
      "fetched_at": "2026-01-21T19:45:06.130158499-03:00",
      "description": "High-performance AI gateway that connects multiple AI providers through a single API. Get 100% uptime with automatic failover and load balancing.",
      "summary": "This document is empty and contains no text or instructions to analyze.",
      "tags": [
        "empty-document",
        "no-content",
        "placeholder"
      ],
      "category": "other",
      "original_file_path": "bifrost-enterprise.md"
    },
    {
      "file_path": "001-bifrost-discord.md",
      "title": "Discord",
      "url": "https://getmax.im/bifrost-discord",
      "source": "llms",
      "fetched_at": "2026-01-21T19:45:05.897429572-03:00",
      "summary": "This document provides a redirection notice indicating that the content has been moved to a new location on Discord.",
      "tags": [
        "redirection",
        "http-302",
        "document-moved",
        "discord"
      ],
      "category": "other",
      "original_file_path": "bifrost-discord.md"
    }
  ],
  "organization": {
    "method": "sequential-numbering",
    "organized_at": "2026-01-22T16:14:27.791Z",
    "total_files": 389,
    "categories": [
      {
        "id": "meta",
        "name": "Meta & Resources",
        "description": "Project links and resources",
        "range": "001-002",
        "count": 2
      },
      {
        "id": "quickstart-gateway",
        "name": "Gateway Quickstart",
        "description": "Getting started with Bifrost Gateway",
        "range": "003-010",
        "count": 8
      },
      {
        "id": "quickstart-sdk",
        "name": "Go SDK Quickstart",
        "description": "Getting started with Bifrost Go SDK",
        "range": "011-017",
        "count": 7
      },
      {
        "id": "integrations",
        "name": "SDK Integrations",
        "description": "Integration with popular AI frameworks and SDKs",
        "range": "018-028",
        "count": 11
      },
      {
        "id": "features",
        "name": "Features",
        "description": "Core features and capabilities",
        "range": "029-043",
        "count": 15
      },
      {
        "id": "mcp",
        "name": "Model Context Protocol",
        "description": "MCP integration for agentic tools",
        "range": "044-051",
        "count": 8
      },
      {
        "id": "plugins",
        "name": "Plugins",
        "description": "Plugin development and management",
        "range": "052-056",
        "count": 5
      },
      {
        "id": "providers",
        "name": "Providers",
        "description": "AI provider configurations and routing",
        "range": "057-080",
        "count": 24
      },
      {
        "id": "enterprise",
        "name": "Enterprise",
        "description": "Enterprise features and security",
        "range": "081-094",
        "count": 14
      },
      {
        "id": "deployment",
        "name": "Deployment Guides",
        "description": "Installation and deployment options",
        "range": "095-100",
        "count": 6
      },
      {
        "id": "architecture",
        "name": "Architecture",
        "description": "System architecture and internals",
        "range": "101-110",
        "count": 10
      },
      {
        "id": "benchmarking",
        "name": "Benchmarking",
        "description": "Performance benchmarks and testing",
        "range": "111-114",
        "count": 4
      },
      {
        "id": "contributing",
        "name": "Contributing",
        "description": "Developer contribution guides",
        "range": "115-119",
        "count": 5
      },
      {
        "id": "api-core",
        "name": "API Reference - Core",
        "description": "Core API endpoints (chat, completions, embeddings, files)",
        "range": "120-141",
        "count": 22
      },
      {
        "id": "api-config",
        "name": "API Reference - Configuration",
        "description": "Configuration and management APIs",
        "range": "142-191",
        "count": 50
      },
      {
        "id": "api-anthropic",
        "name": "API Reference - Anthropic",
        "description": "Anthropic-compatible API endpoints",
        "range": "192-204",
        "count": 13
      },
      {
        "id": "api-openai",
        "name": "API Reference - OpenAI",
        "description": "OpenAI-compatible API endpoints",
        "range": "205-230",
        "count": 26
      },
      {
        "id": "api-bedrock",
        "name": "API Reference - Bedrock",
        "description": "AWS Bedrock-compatible API endpoints",
        "range": "231-238",
        "count": 8
      },
      {
        "id": "api-gemini",
        "name": "API Reference - Gemini",
        "description": "Google Gemini-compatible API endpoints",
        "range": "239-248",
        "count": 10
      },
      {
        "id": "api-cohere",
        "name": "API Reference - Cohere",
        "description": "Cohere-compatible API endpoints",
        "range": "249-251",
        "count": 3
      },
      {
        "id": "api-langchain",
        "name": "API Reference - LangChain",
        "description": "LangChain-compatible API endpoints",
        "range": "252-269",
        "count": 18
      },
      {
        "id": "api-litellm",
        "name": "API Reference - LiteLLM",
        "description": "LiteLLM-compatible API endpoints",
        "range": "270-286",
        "count": 17
      },
      {
        "id": "api-pydantic",
        "name": "API Reference - PydanticAI",
        "description": "PydanticAI-compatible API endpoints",
        "range": "287-303",
        "count": 17
      },
      {
        "id": "changelogs",
        "name": "Changelogs",
        "description": "Version history and release notes",
        "range": "304-389",
        "count": 86
      }
    ]
  }
}