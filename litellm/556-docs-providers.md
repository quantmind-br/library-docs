---
title: Providers | liteLLM
url: https://docs.litellm.ai/docs/providers
source: sitemap
fetched_at: 2026-01-21T19:47:44.391305908-03:00
rendered_js: false
word_count: 989
summary: This document serves as a comprehensive index of all model providers supported by LiteLLM, detailing how to integrate new OpenAI-compatible providers and configure model pricing. It provides a central directory for users to find technical documentation and setup guides for dozens of third-party AI services.
tags:
    - model-providers
    - llm-integration
    - openai-compatible
    - provider-registration
    - multi-model-api
    - litellm-support
category: reference
---

[**ğŸ“„ï¸ Integrate as a Model Provider**  
\
Quick Start for OpenAI-Compatible Providers](https://docs.litellm.ai/docs/provider_registration/)

[**ğŸ“„ï¸ Add OpenAI-Compatible Provider (JSON)**  
\
For simple OpenAI-compatible providers (like Hyperbolic, Nscale, etc.), you can add support by editing a single JSON file.](https://docs.litellm.ai/docs/contributing/adding_openai_compatible_providers)

[**ğŸ“„ï¸ Add Model Pricing & Context Window**  
\
To add pricing or context window information for a model, simply make a PR to this file:](https://docs.litellm.ai/docs/provider_registration/add_model_pricing)

[**ğŸ—ƒï¸ OpenAI**  
\
4 items](https://docs.litellm.ai/docs/providers/openai)

[**ğŸ“„ï¸ OpenAI (Text Completion)**  
\
LiteLLM supports OpenAI text completion models](https://docs.litellm.ai/docs/providers/text_completion_openai)

[**ğŸ“„ï¸ OpenAI-Compatible Endpoints**  
\
Selecting openai as the provider routes your request to an OpenAI-compatible endpoint using the upstream](https://docs.litellm.ai/docs/providers/openai_compatible)

[**ğŸ—ƒï¸ Azure OpenAI**  
\
5 items](https://docs.litellm.ai/docs/providers/azure/)

[**ğŸ—ƒï¸ Azure AI**  
\
9 items](https://docs.litellm.ai/docs/providers/azure_ai)

[**ğŸ—ƒï¸ Vertex AI**  
\
10 items](https://docs.litellm.ai/docs/providers/vertex)

[**ğŸ—ƒï¸ Google AI Studio**  
\
5 items](https://docs.litellm.ai/docs/providers/gemini)

[**ğŸ“„ï¸ Anthropic**  
\
LiteLLM supports all anthropic models.](https://docs.litellm.ai/docs/providers/anthropic)

[**ğŸ“„ï¸ AWS Sagemaker**  
\
LiteLLM supports All Sagemaker Huggingface Jumpstart Models](https://docs.litellm.ai/docs/providers/aws_sagemaker)

[**ğŸ—ƒï¸ Bedrock**  
\
11 items](https://docs.litellm.ai/docs/providers/bedrock)

[**ğŸ“„ï¸ LiteLLM Proxy (LLM Gateway)**  
\
| Property | Details |](https://docs.litellm.ai/docs/providers/litellm_proxy)

[**ğŸ“„ï¸ Abliteration**  
\
Overview](https://docs.litellm.ai/docs/providers/abliteration)

[**ğŸ“„ï¸ AI21**  
\
LiteLLM supports the following AI21 models:](https://docs.litellm.ai/docs/providers/ai21)

[**ğŸ“„ï¸ AI/ML API**  
\
https://aimlapi.com/](https://docs.litellm.ai/docs/providers/aiml)

[**ğŸ“„ï¸ Aleph Alpha**  
\
LiteLLM supports all models from Aleph Alpha.](https://docs.litellm.ai/docs/providers/aleph_alpha)

[**ğŸ“„ï¸ Amazon Nova**  
\
| Property | Details |](https://docs.litellm.ai/docs/providers/amazon_nova)

[**ğŸ“„ï¸ Anyscale**  
\
https://app.endpoints.anyscale.com/](https://docs.litellm.ai/docs/providers/anyscale)

[**ğŸ“„ï¸ Apertis AI (Stima API)**  
\
Overview](https://docs.litellm.ai/docs/providers/apertis)

[**ğŸ“„ï¸ Baseten**  
\
LiteLLM supports both Baseten Model APIs and dedicated deployments with automatic routing.](https://docs.litellm.ai/docs/providers/baseten)

[**ğŸ“„ï¸ Bytez**  
\
LiteLLM supports all chat models on Bytez!](https://docs.litellm.ai/docs/providers/bytez)

[**ğŸ“„ï¸ Cerebras**  
\
https://inference-docs.cerebras.ai/api-reference/chat-completions](https://docs.litellm.ai/docs/providers/cerebras)

[**ğŸ“„ï¸ Chutes**  
\
Overview](https://docs.litellm.ai/docs/providers/chutes)

[**ğŸ“„ï¸ Clarifai**  
\
Anthropic, OpenAI, Qwen, xAI, Gemini and most of Open soured LLMs are Supported on Clarifai.](https://docs.litellm.ai/docs/providers/clarifai)

[**ğŸ“„ï¸ Cloudflare Workers AI**  
\
https://developers.cloudflare.com/workers-ai/models/text-generation/](https://docs.litellm.ai/docs/providers/cloudflare_workers)

[**ğŸ“„ï¸ Codestral API \[Mistral AI\]**  
\
Codestral is available in select code-completion plugins but can also be queried directly. See the documentation for more details.](https://docs.litellm.ai/docs/providers/codestral)

[**ğŸ“„ï¸ Cohere**  
\
API KEYS](https://docs.litellm.ai/docs/providers/cohere)

[**ğŸ“„ï¸ CometAPI**  
\
LiteLLM supports all AI models from CometAPI. CometAPI provides access to 500+ AI models through a unified API interface, including cutting-edge models like GPT-5, Claude Opus 4.1, and various other state-of-the-art language models.](https://docs.litellm.ai/docs/providers/cometapi)

[**ğŸ“„ï¸ CompactifAI**  
\
https://docs.compactif.ai/](https://docs.litellm.ai/docs/providers/compactifai)

[**ğŸ“„ï¸ Custom API Server (Custom Format)**  
\
Call your custom torch-serve / internal LLM APIs via LiteLLM](https://docs.litellm.ai/docs/providers/custom_llm_server)

[**ğŸ“„ï¸ Dashscope (Qwen API)**  
\
https://dashscope.console.aliyun.com/](https://docs.litellm.ai/docs/providers/dashscope)

[**ğŸ“„ï¸ Databricks**  
\
LiteLLM supports all models on Databricks](https://docs.litellm.ai/docs/providers/databricks)

[**ğŸ“„ï¸ DataRobot**  
\
LiteLLM supports all models from DataRobot. Select datarobot as the provider to route your request through the datarobot OpenAI-compatible endpoint using the upstream official OpenAI Python API library.](https://docs.litellm.ai/docs/providers/datarobot)

[**ğŸ“„ï¸ Deepgram**  
\
LiteLLM supports Deepgram's /listen endpoint.](https://docs.litellm.ai/docs/providers/deepgram)

[**ğŸ“„ï¸ DeepInfra**  
\
https://deepinfra.com/](https://docs.litellm.ai/docs/providers/deepinfra)

[**ğŸ“„ï¸ Deepseek**  
\
https://deepseek.com/](https://docs.litellm.ai/docs/providers/deepseek)

[**ğŸ“„ï¸ Docker Model Runner**  
\
Overview](https://docs.litellm.ai/docs/providers/docker_model_runner)

[**ğŸ“„ï¸ ElevenLabs**  
\
ElevenLabs provides high-quality AI voice technology, including speech-to-text capabilities through their transcription API.](https://docs.litellm.ai/docs/providers/elevenlabs)

[**ğŸ“„ï¸ Fal AI**  
\
Fal AI provides fast, scalable access to state-of-the-art image generation models including FLUX, Stable Diffusion, Imagen, and more.](https://docs.litellm.ai/docs/providers/fal_ai)

[**ğŸ“„ï¸ Featherless AI**  
\
https://featherless.ai/](https://docs.litellm.ai/docs/providers/featherless_ai)

[**ğŸ“„ï¸ Fireworks AI**  
\
We support ALL Fireworks AI models, just set fireworks\_ai/ as a prefix when sending completion requests](https://docs.litellm.ai/docs/providers/fireworks_ai)

[**ğŸ“„ï¸ FriendliAI**  
\
We support ALL FriendliAI models, just set friendliai/ as a prefix when sending completion requests](https://docs.litellm.ai/docs/providers/friendliai)

[**ğŸ“„ï¸ Galadriel**  
\
https://docs.galadriel.com/api-reference/chat-completion-API](https://docs.litellm.ai/docs/providers/galadriel)

[**ğŸ“„ï¸ Github**  
\
https://github.com/marketplace/models](https://docs.litellm.ai/docs/providers/github)

[**ğŸ“„ï¸ GitHub Copilot**  
\
https://docs.github.com/en/copilot](https://docs.litellm.ai/docs/providers/github_copilot)

[**ğŸ“„ï¸ ChatGPT Subscription**  
\
Use ChatGPT Pro/Max subscription models through LiteLLM with OAuth device flow authentication.](https://docs.litellm.ai/docs/providers/chatgpt)

[**ğŸ“„ï¸ GradientAI**  
\
https://digitalocean.com/products/gradientai](https://docs.litellm.ai/docs/providers/gradient_ai)

[**ğŸ“„ï¸ Groq**  
\
https://groq.com/](https://docs.litellm.ai/docs/providers/groq)

[**ğŸ“„ï¸ Helicone**  
\
Overview](https://docs.litellm.ai/docs/providers/helicone)

[**ğŸ“„ï¸ Heroku**  
\
Provision a Model](https://docs.litellm.ai/docs/providers/heroku)

[**ğŸ—ƒï¸ HuggingFace**  
\
2 items](https://docs.litellm.ai/docs/providers/huggingface)

[**ğŸ“„ï¸ Hyperbolic**  
\
Overview](https://docs.litellm.ai/docs/providers/hyperbolic)

[**ğŸ“„ï¸ Infinity**  
\
| Property | Details |](https://docs.litellm.ai/docs/providers/infinity)

[**ğŸ“„ï¸ Jina AI**  
\
https://jina.ai/embeddings/](https://docs.litellm.ai/docs/providers/jina_ai)

[**ğŸ“„ï¸ Lambda AI**  
\
Overview](https://docs.litellm.ai/docs/providers/lambda_ai)

[**ğŸ“„ï¸ LangGraph**  
\
Call LangGraph agents through LiteLLM using the OpenAI chat completions format.](https://docs.litellm.ai/docs/providers/langgraph)

[**ğŸ“„ï¸ Lemonade**  
\
Lemonade Server is an OpenAI-compatible local language model inference provider optimized for AMD GPUs and NPUs. The lemonade litellm provider supports standard chat completions with full OpenAI API compatibility.](https://docs.litellm.ai/docs/providers/lemonade)

[**ğŸ“„ï¸ Llamafile**  
\
LiteLLM supports all models on Llamafile.](https://docs.litellm.ai/docs/providers/llamafile)

[**ğŸ“„ï¸ LlamaGate**  
\
Overview](https://docs.litellm.ai/docs/providers/llamagate)

[**ğŸ“„ï¸ LM Studio**  
\
https://lmstudio.ai/docs/basics/server](https://docs.litellm.ai/docs/providers/lm_studio)

[**ğŸ“„ï¸ Manus**  
\
Use Manus AI agents through LiteLLM's OpenAI-compatible Responses API.](https://docs.litellm.ai/docs/providers/manus)

[**ğŸ“„ï¸ Meta Llama**  
\
| Property | Details |](https://docs.litellm.ai/docs/providers/meta_llama)

[**ğŸ“„ï¸ Milvus - Vector Store**  
\
Use Milvus as a vector store for RAG.](https://docs.litellm.ai/docs/providers/milvus_vector_stores)

[**ğŸ“„ï¸ Mistral AI API**  
\
https://docs.mistral.ai/api/](https://docs.litellm.ai/docs/providers/mistral)

[**ğŸ“„ï¸ MiniMax**  
\
Overview](https://docs.litellm.ai/docs/providers/minimax)

[**ğŸ“„ï¸ Moonshot AI**  
\
Overview](https://docs.litellm.ai/docs/providers/moonshot)

[**ğŸ“„ï¸ Morph**  
\
LiteLLM supports all models on Morph](https://docs.litellm.ai/docs/providers/morph)

[**ğŸ“„ï¸ Nebius AI Studio**  
\
https://docs.nebius.com/studio/inference/quickstart](https://docs.litellm.ai/docs/providers/nebius)

[**ğŸ“„ï¸ NLP Cloud**  
\
LiteLLM supports all LLMs on NLP Cloud.](https://docs.litellm.ai/docs/providers/nlp_cloud)

[**ğŸ“„ï¸ NanoGPT**  
\
Overview](https://docs.litellm.ai/docs/providers/nano-gpt)

[**ğŸ“„ï¸ Novita AI**  
\
| Property | Details |](https://docs.litellm.ai/docs/providers/novita)

[**ğŸ“„ï¸ Nscale (EU Sovereign)**  
\
https://docs.nscale.com/docs/inference/chat](https://docs.litellm.ai/docs/providers/nscale)

[**ğŸ—ƒï¸ Nvidia NIM**  
\
2 items](https://docs.litellm.ai/docs/providers/nvidia_nim)

[**ğŸ“„ï¸ Oracle Cloud Infrastructure (OCI)**  
\
LiteLLM supports the following models for OCI on-demand GenAI API.](https://docs.litellm.ai/docs/providers/oci)

[**ğŸ“„ï¸ Ollama**  
\
LiteLLM supports all models from Ollama](https://docs.litellm.ai/docs/providers/ollama)

[**ğŸ“„ï¸ OpenRouter**  
\
LiteLLM supports all the text / chat / vision / embedding models from OpenRouter](https://docs.litellm.ai/docs/providers/openrouter)

[**ğŸ“„ï¸ ğŸ†• OVHCloud AI Endpoints**  
\
Leading French Cloud provider in Europe with data sovereignty and privacy.](https://docs.litellm.ai/docs/providers/ovhcloud)

[**ğŸ“„ï¸ Perplexity AI (pplx-api)**  
\
https://www.perplexity.ai](https://docs.litellm.ai/docs/providers/perplexity)

[**ğŸ“„ï¸ Petals**  
\
Petals//github.com/bigscience-workshop/petals](https://docs.litellm.ai/docs/providers/petals)

[**ğŸ“„ï¸ Poe**  
\
Overview](https://docs.litellm.ai/docs/providers/poe)

[**ğŸ“„ï¸ PublicAI**  
\
Overview](https://docs.litellm.ai/docs/providers/publicai)

[**ğŸ“„ï¸ Predibase**  
\
LiteLLM supports all models on Predibase](https://docs.litellm.ai/docs/providers/predibase)

[**ğŸ“„ï¸ Pydantic AI Agents**  
\
Call Pydantic AI Agents via LiteLLM's A2A Gateway.](https://docs.litellm.ai/docs/providers/pydantic_ai_agent)

[**ğŸ“„ï¸ RAGFlow**  
\
Litellm supports Ragflow's chat completions APIs](https://docs.litellm.ai/docs/providers/ragflow)

[**ğŸ“„ï¸ Recraft**  
\
https://www.recraft.ai/](https://docs.litellm.ai/docs/providers/recraft)

[**ğŸ“„ï¸ Replicate**  
\
LiteLLM supports all models on Replicate](https://docs.litellm.ai/docs/providers/replicate)

[**ğŸ—ƒï¸ RunwayML**  
\
2 items](https://docs.litellm.ai/docs/providers/runwayml/images)

[**ğŸ“„ï¸ SambaNova**  
\
https://cloud.sambanova.ai/](https://docs.litellm.ai/docs/providers/sambanova)

[**ğŸ“„ï¸ SAP Generative AI Hub**  
\
LiteLLM supports SAP Generative AI Hub's Orchestration Service.](https://docs.litellm.ai/docs/providers/sap)

[**ğŸ“„ï¸ Stability AI**  
\
https://stability.ai/](https://docs.litellm.ai/docs/providers/stability)

[**ğŸ“„ï¸ Synthetic**  
\
Overview](https://docs.litellm.ai/docs/providers/synthetic)

[**ğŸ“„ï¸ Snowflake**  
\
| Property | Details |](https://docs.litellm.ai/docs/providers/snowflake)

[**ğŸ“„ï¸ Together AI**  
\
LiteLLM supports all models on Together AI.](https://docs.litellm.ai/docs/providers/togetherai)

[**ğŸ“„ï¸ Topaz**  
\
| Property | Details |](https://docs.litellm.ai/docs/providers/topaz)

[**ğŸ“„ï¸ Triton Inference Server**  
\
LiteLLM supports Embedding Models on Triton Inference Servers](https://docs.litellm.ai/docs/providers/triton-inference-server)

[**ğŸ“„ï¸ v0**  
\
Overview](https://docs.litellm.ai/docs/providers/v0)

[**ğŸ“„ï¸ Vercel AI Gateway**  
\
Overview](https://docs.litellm.ai/docs/providers/vercel_ai_gateway)

[**ğŸ—ƒï¸ vLLM**  
\
2 items](https://docs.litellm.ai/docs/providers/vllm)

[**ğŸ“„ï¸ Volcano Engine (Volcengine)**  
\
https://www.volcengine.com/docs/82379/1263482](https://docs.litellm.ai/docs/providers/volcano)

[**ğŸ“„ï¸ Voyage AI**  
\
https://docs.voyageai.com/embeddings/](https://docs.litellm.ai/docs/providers/voyage)

[**ğŸ“„ï¸ Weights & Biases Inference**  
\
https://weave-docs.wandb.ai/quickstart-inference](https://docs.litellm.ai/docs/providers/wandb_inference)

[**ğŸ—ƒï¸ WatsonX**  
\
2 items](https://docs.litellm.ai/docs/providers/watsonx/)

[**ğŸ“„ï¸ xAI**  
\
https://docs.x.ai/docs](https://docs.litellm.ai/docs/providers/xai)

[**ğŸ“„ï¸ Xiaomi MiMo**  
\
https://platform.xiaomimimo.com/#/docs](https://docs.litellm.ai/docs/providers/xiaomi_mimo)

[**ğŸ“„ï¸ Xinference \[Xorbits Inference\]**  
\
https://inference.readthedocs.io/en/latest/index.html](https://docs.litellm.ai/docs/providers/xinference)

[**ğŸ“„ï¸ Z.AI (Zhipu AI)**  
\
https://z.ai/](https://docs.litellm.ai/docs/providers/zai)