---
title: Ollama
url: https://coolify.io/docs/services/ollama.md
source: llms
fetched_at: 2026-02-17T14:46:35.896307-03:00
rendered_js: false
word_count: 41
summary: This document introduces Ollama, a lightweight server for running large language models locally or in the cloud, featuring a web-based interface and official resource links.
tags:
    - ollama
    - llm
    - large-language-models
    - self-hosted
    - open-webui
category: concept
---

## What is Ollama?

Ollama is a lightweight and efficient server for running large language models (LLMs) on your local machine or in the cloud.

It includes OpenWebUI, a web-based interface for interacting with the models.

## Screenshots

## Links

* [The official website](https://ollama.com/?utm_source=coolify.io)
* [GitHub](https://github.com/ollama/ollama?utm_source=coolify.io)