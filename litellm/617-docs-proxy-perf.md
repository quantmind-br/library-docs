---
title: LiteLLM Proxy Performance | liteLLM
url: https://docs.litellm.ai/docs/proxy/perf
source: sitemap
fetched_at: 2026-01-21T19:53:12.748804421-03:00
rendered_js: false
word_count: 38
summary: This document provides performance benchmarks for the LiteLLM proxy, detailing its impact on throughput and latency compared to the raw OpenAI API.
tags:
    - litellm-proxy
    - benchmarks
    - throughput
    - latency
    - load-balancing
    - performance-metrics
category: reference
---

### Throughput - 30% Increase[​](#throughput---30-increase "Direct link to Throughput - 30% Increase")

LiteLLM proxy + Load Balancer gives **30% increase** in throughput compared to Raw OpenAI API

### Latency Added - 0.00325 seconds[​](#latency-added---000325-seconds "Direct link to Latency Added - 0.00325 seconds")

LiteLLM proxy adds **0.00325 seconds** latency as compared to using the Raw OpenAI API