---
title: GLM-4-32B-0414-128K
url: https://docs.z.ai/guides/llm/glm-4-32b-0414-128k.md
source: llms
fetched_at: 2026-01-24T11:23:13.927092145-03:00
rendered_js: false
word_count: 224
summary: This document provides an overview of the GLM-4-32B-0414-128K language model, detailing its technical specifications, capabilities, and quick-start implementation guides.
tags:
    - glm-4
    - large-language-model
    - llm-api
    - function-calling
    - sdk-integration
    - text-generation
    - ai-model-specs
category: guide
---

> ## Documentation Index
> Fetch the complete documentation index at: https://docs.z.ai/llms.txt
> Use this file to discover all available pages before exploring further.

# GLM-4-32B-0414-128K

## <Icon icon="rectangle-list" iconType="solid" color="#ffffff" size={36} />   Overview

GLM-4-32B-0414-128K is a highly cost-effective foundation language model. It can efficiently perform complex tasks and has significantly enhanced capabilities in tool use, online search, and code-related intelligent tasks.

<CardGroup cols={3}>
  <Card title="Price" icon="circle-dollar" color="#ffffff">
    \$0.1 per million tokens
  </Card>

  <Card title="Input Modality" icon="arrow-down-right" color="#ffffff">
    Text
  </Card>

  <Card title="Output Modality" icon="arrow-down-left" color="#ffffff">
    Text
  </Card>

  <Card title="Context Length" icon="arrow-down-arrow-up" iconType="regular">
    128K
  </Card>

  <Card title="Maximum Output Tokens" icon="maximize" iconType="regular">
    16K
  </Card>
</CardGroup>

## <Icon icon="list" iconType="solid" color="#ffffff" size={36} />   Usage

<AccordionGroup>
  <Accordion title="Intelligent Q&A Assistant">
    Supports real-time online search to retrieve the latest information, accurately parses complex queries on e-commerce product inquiries, financial service terms, education course Q\&A, and generates precise, professional answers based on enterprise knowledge bases.
  </Accordion>

  <Accordion title="Intelligent Quality Inspection">
    Accurately identifies and extracts key information and business fields from complex texts such as customer service tickets, automating analyses like sales pitch inspection and risk identification, strictly adhering to SOP processes and greatly reducing data processing time.
  </Accordion>

  <Accordion title="Financial Data Analysis">
    Real-time cleansing of financial data, automated extraction of key insights, and detection of potential trends and correlations. Supports scenarios such as bid document analysis, financial report interpretation, and market trend monitoring.
  </Accordion>

  <Accordion title="Code Generation">
    Based on intent decomposition and logical reasoning, accurately generates initial code frameworks or key functions in mainstream languages such as Python, Java, and JavaScript. Supports multi-turn contextual iterative development, intelligent comments, and rewriting functions to add clear annotations to code.
  </Accordion>

  <Accordion title="Job Market Analysis">
    Deep analysis of job descriptions and resumes using real-time job information, industry salary trends, and talent demand, providing precise talent matching recommendations for enterprises and analyzing employment trends and career development paths for job seekers.
  </Accordion>
</AccordionGroup>

## <Icon icon="bars-sort" iconType="solid" color="#ffffff" size={36} />   Resources

* [API Documentation](/api-reference/llm/caht-completion): Learn how to call the API.

## <Icon icon="arrow-down-from-line" iconType="solid" color="#ffffff" size={36} />   Introducing GLM-4-32B-0414-128K

<Steps>
  <Step icon="stars">
    GLM-4-32B-0414-128K was pre-trained on 15T of high-quality data, including abundant synthetic reasoning data to lay a solid foundation for subsequent reinforcement learning. In the post-training phase, besides aligning with human preferences in dialogue scenarios, we also applied techniques like rejection sampling and reinforcement learning to enhance instruction following, engineering code generation, and function calling, strengthening the modelâ€™s fundamental capabilities for intelligent tasks.

    The model performs comparably to much larger domestic and international mainstream models, with some benchmark indicators approaching or even exceeding models like GPT-4o and DeepSeek-V3-0324 (671B).

    <Icon icon="arrow-down-to-dotted-line" />
  </Step>
</Steps>

## <Icon icon="table-cells" iconType="solid" size={36} />   Capability

<CardGroup cols={3}>
  <Card title="Streaming Output" icon="arrow-down-from-dotted-line" iconType="solid" color="#ffffff" />

  <Card title="Structured Output" icon="arrow-down-from-line" iconType="regular" color="#ffffff" />

  <Card title="Function Calling" icon="function" iconType="regular" color="#ffffff" />

  <Card title="Knowledge Base Retrieval" icon="brain" iconType="regular" color="#ffffff" />

  <Card title="Web search" icon="magnifying-glass" iconType="regular" color="#ffffff">
    the search engine supports Jina AI, with a price of \$0.01 per use.
  </Card>
</CardGroup>

## <Icon icon="rectangle-code" iconType="solid" color="#ffffff" size={36} />    Quick Start

<Tabs>
  <Tab title="cURL">
    **Basic Call**

    ```bash  theme={null}
    curl -X POST "https://api.z.ai/api/paas/v4/chat/completions" \
         -H "Authorization: Bearer your-api-key" \
         -H "Content-Type: application/json" \
         -d '{
           "model": "glm-4-32b-0414-128k",
           "messages": [
             {
               "role": "user",
               "content": "As a marketing expert, please create an attractive slogan for my product."
             }
           ]
         }'
    ```

    **Streaming Call**

    ```bash  theme={null}
    curl -X POST "https://api.z.ai/api/paas/v4/chat/completions" \
         -H "Authorization: Bearer your-api-key" \
         -H "Content-Type: application/json" \
         -d '{
           "model": "glm-4-32b-0414-128k",
           "messages": [
             {
               "role": "user",
               "content": "As a marketing expert, please create an attractive slogan for my product."
             }
           ],
           "stream": true
         }'
    ```
  </Tab>

  <Tab title="Official Python SDK">
    **Install SDK**

    ```bash  theme={null}
    # Install latest version
    pip install zai-sdk

    # Or specify version
    pip install zai-sdk==0.1.0
    ```

    **Verify Installation**

    ```python  theme={null}
    import zai
    print(zai.__version__)
    ```

    **Basic Call**

    ```python  theme={null}
    from zai import ZaiClient

    # Initialize the client
    client = ZaiClient(api_key="your-api-key")

    # Create a chat completion request
    response = client.chat.completions.create(
        model="glm-4-32b-0414-128k",
        messages=[
            {"role": "user", "content": "As a marketing expert, please create an attractive slogan for my product."}
        ]
    )

    # Get the response
    print(response.choices[0].message.content)
    ```

    **Streaming Call**

    ```python  theme={null}
    from zai import ZaiClient

    # Initialize the client
    client = ZaiClient(api_key="your-api-key")

    # Create a streaming chat completion request
    stream = client.chat.completions.create(
        model="glm-4-32b-0414-128k",
        messages=[
            {"role": "user", "content": "As a marketing expert, please create an attractive slogan for my product."}
        ],
        stream=True
    )

    # Process streaming response
    for chunk in stream:
        if chunk.choices[0].delta.content:
            print(chunk.choices[0].delta.content, end="")
    ```
  </Tab>

  <Tab title="Official Java SDK">
    **Install SDK**

    **Maven**

    ```xml  theme={null}
    <dependency>
        <groupId>ai.z.openapi</groupId>
        <artifactId>zai-sdk</artifactId>
        <version>0.3.0</version>
    </dependency>
    ```

    **Gradle (Groovy)**

    ```groovy  theme={null}
    implementation 'ai.z.openapi:zai-sdk:0.3.0'
    ```

    **Basic Call**

    ```java  theme={null}
    import ai.z.openapi.ZaiClient;
    import ai.z.openapi.service.model.ChatCompletionCreateParams;
    import ai.z.openapi.service.model.ChatCompletionResponse;
    import ai.z.openapi.service.model.ChatMessage;
    import ai.z.openapi.service.model.ChatMessageRole;
    import java.util.Arrays;

    public class BasicChat {
        public static void main(String[] args) {
            // Initialize the client
            ZaiClient client = ZaiClient.builder().ofZAI()
                .apiKey("your-api-key")
                .build();

            // Create a chat completion request
            ChatCompletionCreateParams request = ChatCompletionCreateParams.builder()
                .model("glm-4-32b-0414-128k")
                .messages(Arrays.asList(
                    ChatMessage.builder()
                        .role(ChatMessageRole.USER.value())
                        .content("As a marketing expert, please create an attractive slogan for my product.")
                        .build()
                ))
                .build();

            // Send request
            ChatCompletionResponse response = client.chat().createChatCompletion(request);

            // Get the response
            if (response.isSuccess()) {
                Object reply = response.getData().getChoices().get(0).getMessage().getContent();
                System.out.println("AI Reply: " + reply);
            } else {
                System.err.println("Error: " + response.getMsg());
            }
        }
    }
    ```

    **Streaming Call**

    ```java  theme={null}
    import ai.z.openapi.ZaiClient;
    import ai.z.openapi.service.model.ChatCompletionCreateParams;
    import ai.z.openapi.service.model.ChatCompletionResponse;
    import ai.z.openapi.service.model.ChatMessage;
    import ai.z.openapi.service.model.ChatMessageRole;
    import ai.z.openapi.service.model.Delta;
    import java.util.Arrays;

    public class StreamingChat {
        public static void main(String[] args) {
            // Initialize the client
            ZaiClient client = ZaiClient.builder().ofZAI()
                .apiKey("your-api-key")
                .build();

            // Create a streaming chat completion request
            ChatCompletionCreateParams request = ChatCompletionCreateParams.builder()
                .model("glm-4-32b-0414-128k")
                .messages(Arrays.asList(
                    ChatMessage.builder()
                        .role(ChatMessageRole.USER.value())
                        .content("As a marketing expert, please create an attractive slogan for my product.")
                        .build()
                ))
                .stream(true)
                .build();

            ChatCompletionResponse response = client.chat().createChatCompletion(request);

            if (response.isSuccess()) {
                response.getFlowable().subscribe(
                    // Process streaming message data
                    data -> {
                        if (data.getChoices() != null && !data.getChoices().isEmpty()) {
                        Delta delta = data.getChoices().get(0).getDelta();
                        System.out.print(delta + "\n");
                    }},
                    // Process streaming response error
                    error -> System.err.println("\nStream error: " + error.getMessage()),
                    // Process streaming response completion event
                    () -> System.out.println("\nStreaming response completed")
                );
            } else {
                System.err.println("Error: " + response.getMsg());
            }
        }
    }
    ```
  </Tab>

  <Tab title="OpenAI Python SDK">
    **Install SDK**

    ```bash  theme={null}
    # Install or upgrade to latest version
    pip install --upgrade 'openai>=1.0'
    ```

    **Verify Installation**

    ```python  theme={null}
    python -c "import openai; print(openai.__version__)"
    ```

    **Usage Example**

    ```python  theme={null}
    from openai import OpenAI

    client = OpenAI(
        api_key="your-Z.AI-api-key",
        base_url="https://api.z.ai/api/paas/v4/"
    )

    completion = client.chat.completions.create(
        model="glm-4-32b-0414-128k",
        messages=[
            {"role": "system", "content": "You are a smart and creative novelist"},
            {"role": "user", "content": "Please write a short fairy tale story as a fairy tale master"}
        ]
    )

    print(completion.choices[0].message.content)
    ```
  </Tab>
</Tabs>