---
title: Supabase Tutorial | liteLLM
url: https://docs.litellm.ai/observability/supabase_integration
source: sitemap
fetched_at: 2026-01-21T19:41:11.94402682-03:00
rendered_js: false
word_count: 204
summary: This document explains how to integrate Supabase with liteLLM to log request data and track costs across multiple LLM providers using success and failure callbacks. It provides instructions for database schema setup, environment configuration, and advanced logging controls.
tags:
    - supabase
    - litellm
    - request-logging
    - cost-tracking
    - llm-monitoring
    - python
    - database-integration
category: guide
---

[Supabase](https://supabase.com/) is an open source Firebase alternative. Start your project with a Postgres database, Authentication, instant APIs, Edge Functions, Realtime subscriptions, Storage, and Vector embeddings.

## Use Supabase to log requests and see total spend across all LLM Providers (OpenAI, Azure, Anthropic, Cohere, Replicate, PaLM)[â€‹](#use-supabase-to-log-requests-and-see-total-spend-across-all-llm-providers-openai-azure-anthropic-cohere-replicate-palm "Direct link to Use Supabase to log requests and see total spend across all LLM Providers (OpenAI, Azure, Anthropic, Cohere, Replicate, PaLM)")

liteLLM provides `success_callbacks` and `failure_callbacks`, making it easy for you to send data to a particular provider depending on the status of your responses.

In this case, we want to log requests to Supabase in both scenarios - when it succeeds and fails.

### Create a supabase table[â€‹](#create-a-supabase-table "Direct link to Create a supabase table")

Go to your Supabase project &gt; go to the [Supabase SQL Editor](https://supabase.com/dashboard/projects) and create a new table with this configuration.

Note: You can change the table name. Just don't change the column names.

```
createtable
public.request_logs (
    id bigint generated bydefaultasidentity,
    created_at timestampwithtime zone nulldefaultnow(),
    model textnulldefault''::text,
    messages json nulldefault'{}'::json,
    response json nulldefault'{}'::json,
    end_user textnulldefault''::text,
    error json nulldefault'{}'::json,
    response_time realnulldefault'0'::real,
    total_cost realnull,
    additional_details json nulldefault'{}'::json,
constraint request_logs_pkey primarykey(id)
)tablespace pg_default;
```

### Use Callbacks[â€‹](#use-callbacks "Direct link to Use Callbacks")

Use just 2 lines of code, to instantly see costs and log your responses **across all providers** with Supabase:

```
litellm.success_callback=["supabase"]
litellm.failure_callback=["supabase"]
```

Complete code

```
from litellm import completion

## set env variables
### SUPABASE
os.environ["SUPABASE_URL"]="your-supabase-url"
os.environ["SUPABASE_KEY"]="your-supabase-key"

## LLM API KEY
os.environ["OPENAI_API_KEY"]=""

# set callbacks
litellm.success_callback=["supabase"]
litellm.failure_callback=["supabase"]

#openai call
response = completion(model="gpt-3.5-turbo", messages=[{"role":"user","content":"Hi ðŸ‘‹ - i'm openai"}])

#bad call
response = completion(model="chatgpt-test", messages=[{"role":"user","content":"Hi ðŸ‘‹ - i'm a bad call to test error logging"}])
```

### Additional Controls[â€‹](#additional-controls "Direct link to Additional Controls")

**Different Table name**

If you modified your table name, here's how to pass the new name.

```
litellm.modify_integration("supabase",{"table_name":"litellm_logs"})
```

**Identify end-user**

Here's how to map your llm call to an end-user

```
litellm.identify({"end_user":"krrish@berri.ai"})
```

- [Use Supabase to log requests and see total spend across all LLM Providers (OpenAI, Azure, Anthropic, Cohere, Replicate, PaLM)](#use-supabase-to-log-requests-and-see-total-spend-across-all-llm-providers-openai-azure-anthropic-cohere-replicate-palm)
  
  - [Create a supabase table](#create-a-supabase-table)
  - [Use Callbacks](#use-callbacks)
  - [Additional Controls](#additional-controls)